<ul>
  <li><strong>EcomScriptBench: A Multi-task Benchmark for E-commerce Script Planning via Step-wise Intention-Driven Product Association</strong><br><em>Weiqi Wang, Limeng Cui, Xin Liu, Sreyashi Nag, Wenju Xu, Chen Luo, Sheikh Muhammad Sarwar, Yang Li, Hansu Gu, Hui Liu, Changlong Yu, Jiaxin Bai, Yifan Gao, Haiyang Zhang, Qi He, Shuiwang Ji, Yangqiu Song</em></li>
  <li><strong>TAGExplainer: Narrating Graph Explanations for Text-Attributed Graph Learning Models</strong><br><em>Bo Pan, Zhen Xiong, Guanchen Wu, Zheng Zhang, Yifei Zhang, Yuntong Hu, Liang Zhao</em></li>
  <li><strong>M-RewardBench: Evaluating Reward Models in Multilingual Settings</strong><br><em>Srishti Gureja, Lester James Validad Miranda, Shayekh Bin Islam, Rishabh Maheshwary, Drishti Sharma, Gusti Triandi Winata, Nathan Lambert, Sebastian Ruder, Sara Hooker, Marzieh Fadaee</em></li>
  <li><strong>ELABORATION: A Comprehensive Benchmark on Human-LLM Competitive Programming</strong><br><em>Xinwei Yang, Zhaofeng Liu, Chen Huang, Jiashuai Zhang, Tong Zhang, Yifan Zhang, Wenqiang Lei</em></li>
  <li><strong>The Impossibility of Fair LLMs</strong><br><em>Jacy Reese Anthis, Kristian Lum, Michael Ekstrand, Avi Feller, Chenhao Tan</em></li>
  <li><strong>Intuitive Fine-Tuning: Towards Simplifying Alignment into a Single Process</strong><br><em>Ermo Hua, Biqing Qi, Kaiyan Zhang, Kai Tian, Xingtai Lv, Ning Ding, Bowen Zhou</em></li>
  <li><strong>Bias in Language Models: Beyond Trick Tests and Towards RUTEd Evaluation</strong><br><em>Kristian Lum, Jacy Reese Anthis, Kevin Robinson, Chirag Nagpal, Alexander Nicholas D’Amour</em></li>
  <li><strong>Sliding Windows Are Not the End: Exploring Full Ranking with Long-Context Large Language Models</strong><br><em>Wenhan Liu, Xinyu Ma, Yutao Zhu, Ziliang Zhao, Shuaiqiang Wang, Dawei Yin, Zhicheng Dou</em></li>
  <li><strong>The Impact of Auxiliary Patient Data on Automated Chest X-Ray Report Generation and How to Incorporate It</strong><br><em>Aaron Nicolson, Shengyao Zhuang, Jason Dowling, Bevan Koopman</em></li>
  <li><strong>CLEME2.0: Towards Interpretable Evaluation by Disentangling Edits for Grammatical Error Correction</strong><br><em>Jingheng Ye, Zishan Xu, Yinghui Li, Linlin Song, Qingyu Zhou, Hai-Tao Zheng, Ying Shen, Wenhao Jiang, Hong-Gee Kim, Ruitong Liu, Xin Su, Zifei Shan</em></li>
  <li><strong>Towards LLM-powered Attentive Listener: A Pragmatic Approach through Quantity Self-Repair</strong><br><em>Junlin Li, Bo Peng, Yu-Yin Hsu</em></li>
  <li><strong>StrucText-Eval: Evaluating Large Language Model’s Reasoning Ability in Structure-Rich Text</strong><br><em>Zhouhong Gu, Haoning Ye, Xingzhou Chen, Zeyang Zhou, Hongwei Feng, Yanghua Xiao</em></li>
  <li><strong>Literature Meets Data: A Synergistic Approach to Hypothesis Generation</strong><br><em>Haokun Liu, Yangqiaoyu Zhou, Mingxuan Li, Chenfei Yuan, Chenhao Tan</em></li>
  <li><strong>GAPO: Learning Preferential Prompt through Generative Adversarial Policy Optimization</strong><br><em>Zhouhong Gu, Xingzhou Chen, Xiaoran Shi, Tao Wang, Suhang Zheng, Tianyu Li, Hongwei Feng, Yanghua Xiao</em></li>
  <li><strong>Tree-of-Evolution: Tree-Structured Instruction Evolution for Code Generation in Large Language Models</strong><br><em>Ziyang Luo, Kaixin Li, Hongzhan Lin, Yuchen Tian, Mohan Kankanhalli, Jing Ma</em></li>
  <li><strong>Delving into Multilingual Ethical Bias: The MSQAD with Statistical Hypothesis Tests for Large Language Models</strong><br><em>Seunguk Yu, Juhwan Choi, YoungBin Kim</em></li>
  <li><strong>ReSCORE: Label-free Iterative Retriever Training for Multi-hop Question Answering with Relevance-Consistency Supervision</strong><br><em>Dosung Lee, Wonjun Oh, Boyoung Kim, Minyoung Kim, Joonsuk Park, Paul Hongsuck Seo</em></li>
  <li><strong>MIRAGE: Exploring How Large Language Models Perform in Complex Social Interactive Environments</strong><br><em>Yin Cai, Zhouhong Gu, Zhaohan Du, Zheyu Ye, Shaosheng Cao, Yiqian xu, Hongwei Feng, Ping Chen</em></li>
  <li><strong>FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models</strong><br><em>Hongzhan Lin, Yang Deng, Yuxuan Gu, Wenxuan Zhang, Jing Ma, See-Kiong Ng, Tat-Seng Chua</em></li>
  <li><strong>Statistical Deficiency for Task Inclusion Estimation</strong><br><em>Loïc Fosse, Frederic Bechet, Benoit Favre, Géraldine Damnati, Gwénolé Lecorvé, Maxime DARRIN, Philippe Formont, Pablo Piantanida</em></li>
  <li><strong>Towards Robust and Efficient Federated Low-Rank Adaptation with Heterogeneous Clients</strong><br><em>Jabin Koo, Minwoo Jang, Jungseul Ok</em></li>
  <li><strong>Dynamic Label Name Refinement for Few-Shot Dialogue Intent Classification</strong><br><em>Gyutae Park, Ingeol Baek, Byeongjeong Kim, Joongbo Shin, Hwanhee Lee</em></li>
  <li><strong>LLM-Powered Test Case Generation for Detecting Bugs in Plausible Programs</strong><br><em>Kaibo Liu, Zhenpeng Chen, Yiyang Liu, Jie Zhang, Mark Harman, Yudong Han, Yun Ma, Yihong Dong, Ge Li, Gang Huang</em></li>
  <li><strong>Capture the Key in Reasoning to Enhance CoT Distillation Generalization</strong><br><em>Chengwei Dai, Kun Li, Wei Zhou, Songlin Hu</em></li>
  <li><strong>How to Enable Effective Cooperation Between Humans and NLP Models: A Survey of Principles, Formalizations, and Beyond</strong><br><em>Chen Huang, Yang Deng, Wenqiang Lei, Jiancheng Lv, Tat-Seng Chua, Jimmy Huang</em></li>
  <li><strong>Enhancing Hyperbole and Metaphor Detection with Their Bidirectional Dynamic Interaction and Emotion Knowledge</strong><br><em>Li Zheng, Sihang Wang, Hao Fei, Zuquan Peng, Fei Li, Jianming Fu, Chong Teng, Donghong Ji</em></li>
  <li><strong>UniICL: An Efficient ICL Framework Unifying Compression, Selection, and Generation</strong><br><em>Jun Gao, Qi Lv, Zili Wang, Tianxiang Wu, Ziqiang Cao, Wenjie Li</em></li>
  <li><strong>BelarusianGLUE: Towards a Natural Language Understanding Benchmark for Belarusian</strong><br><em>Maksim Aparovich, Volha Harytskaya, Vladislav Poritski, Oksana Volchek, Pavel Smrz</em></li>
  <li><strong>A Survey on Foundation Language Models for Single-cell Biology</strong><br><em>Fan Zhang, Hao Chen, Zhihong Zhu, Ziheng Zhang, Zhenxi Lin, Ziyue Qiao, Yefeng Zheng, Xian Wu</em></li>
  <li><strong>RuleArena: A Benchmark for Rule-Guided Reasoning with LLMs in Real-World Scenarios</strong><br><em>Ruiwen Zhou, Wenyue Hua, Liangming Pan, Sitao Cheng, Xiaobao Wu, En Yu, William Yang Wang</em></li>
  <li><strong>Extending LLM Context Window with Adaptive Grouped Positional Encoding: A Training-Free Method</strong><br><em>Xinhao Xu, Jiaxin Li, Hui Chen, Zijia Lin, Jungong Han, Guiguang Ding</em></li>
  <li><strong>Semantic Exploration with Adaptive Gating for Efficient Problem Solving with Language Models</strong><br><em>Sungjae Lee, Hyejin Park, Jaechang Kim, Jungseul Ok</em></li>
  <li><strong>HotelMatch-LLM: Joint Multi-Task Training of Small and Large Language Models for Efficient Multimodal Hotel Retrieval</strong><br><em>Arian Askari, Emmanouil Stergiadis, Ilya Gusev, Moran Beladev</em></li>
  <li><strong>Can Multimodal Large Language Models Understand Spatial Relations?</strong><br><em>Jingping Liu, Ziyan Liu, Zhedong Cen, Yan Zhou, Yinan Zou, Weiyan Zhang, Haiyun Jiang, Tong Ruan</em></li>
  <li><strong>$S^3$ - Semantic Signal Separation</strong><br><em>Márton Kardos, Jan Kostkan, Kenneth Enevoldsen, Arnault-Quentin Vermillet, Kristoffer Nielbo, Roberta Rocca</em></li>
  <li><strong>TrimLLM: Progressive Layer Dropping for Domain-Specific LLMs</strong><br><em>Lanxiang Hu, Tajana Rosing, Hao Zhang</em></li>
  <li><strong>JuStRank: Benchmarking LLM Judges for System Ranking</strong><br><em>Ariel Gera, Odellia Boni, Yotam Perlitz, Roy Bar-Haim, Lilach Eden, Asaf Yehudai</em></li>
  <li><strong>Generating Diverse Training Samples for Relation Extraction with Large Language Models</strong><br><em>Zexuan Li, Hongliang Dai, Piji Li</em></li>
  <li><strong>MultiSocial: Multilingual Benchmark of Machine-Generated Text Detection of Social-Media Texts</strong><br><em>Dominik Macko, Jakub Kopál, Robert Moro, Ivan Srba</em></li>
  <li><strong>Efficient and Accurate Prompt Optimization: the Benefit of Memory in Exemplar-Guided Reflection</strong><br><em>Cilin Yan, Jingyun Wang, Lin Zhang, Ruihui Zhao, Xiaopu Wu, Kai Xiong, Qingsong Liu, Guoliang Kang, Yangyang Kang</em></li>
  <li><strong>Evaluation of LLM Vulnerabilities to Being Misused for Personalized Disinformation Generation</strong><br><em>Aneta Zugecova, Dominik Macko, Ivan Srba, Robert Moro, Jakub Kopál, Katarína Marcinčinová, Matúš Mesarčík</em></li>
  <li><strong>EscapeBench: Towards Advancing Creative Intelligence of Language Model Agents</strong><br><em>Cheng Qian, Peixuan Han, Qinyu Luo, Bingxiang He, Xiusi Chen, Yuji Zhang, Hongyi Du, Jiarui Yao, Xiaocheng Yang, Denghui Zhang, Yunzhu Li, Heng Ji</em></li>
  <li><strong>BPP-Search: Enhancing Tree of Thought Reasoning for Mathematical Modeling Problem Solving</strong><br><em>Teng Wang, Wing Yin YU, Zhenqi He, Zehua Liu, HaileiGong, Han Wu, Xiongwei Han, Wei Shi, Ruifeng She, Fangzhou Zhu, Tao Zhong</em></li>
  <li><strong>LACA: Improving Cross-lingual Aspect-Based Sentiment Analysis with LLM Data Augmentation</strong><br><em>Jakub Šmíd, Pavel Priban, Pavel Kral</em></li>
  <li><strong>Fusing Highly Specialized Language Models for Comprehensive Expertise</strong><br><em>Ning Ding, Yulin Chen, Ganqu Cui, Xingtai Lv, Weilin Zhao, Kaiyan Zhang, Ruobing Xie, Bowen Zhou, Zhiyuan Liu, Maosong Sun</em></li>
  <li><strong>HybGRAG: Hybrid Retrieval-Augmented Generation on Textual and Relational Knowledge Bases</strong><br><em>Meng-Chieh Lee, Qi Zhu, Costas Mavromatis, Zhen Han, Soji Adeshina, Vassilis N. Ioannidis, Huzefa Rangwala, Christos Faloutsos</em></li>
  <li><strong>Re-ranking Using Large Language Models for Mitigating Exposure to Harmful Content on Social Media Platforms</strong><br><em>Rajvardhan Oak, Muhammad Haroon, Claire Wonjeong jo, Magdalena Wojcieszak, Anshuman Chhabra</em></li>
  <li><strong>Aligning AI Research with the Needs of Clinical Coding Workflows: Eight Recommendations Based on US Data Analysis and Critical Review</strong><br><em>Yidong Gan, Maciej Rybinski, Ben Hachey, Jonathan K. Kummerfeld</em></li>
  <li><strong>MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection</strong><br><em>Ziyan Liu, Chunxiao Fan, Haoran Lou, Yuexin Wu, Kaiwei Deng</em></li>
  <li><strong>EvoWiki: Evaluating LLMs on Evolving Knowledge</strong><br><em>Wei Tang, Yixin Cao, Yang Deng, Jiahao Ying, Bo Wang, Yizhe Yang, Yuyue Zhao, Qi Zhang, Xuanjing Huang, Yu-Gang Jiang, Yong Liao</em></li>
  <li><strong>Rethinking Repetition Problems of LLMs in Code Generation</strong><br><em>Yihong Dong, Yuchen Liu, Xue Jiang, Zhi Jin, Ge Li</em></li>
  <li><strong>PunchBench: Benchmarking MLLMs in Multimodal Punchline Comprehension</strong><br><em>Kun Ouyang, Yuanxin Liu, Shicheng Li, Yi Liu, Hao Zhou, Fandong Meng, Jie Zhou, Xu Sun</em></li>
  <li><strong>ProcessBench: Identifying Process Errors in Mathematical Reasoning</strong><br><em>Chujie Zheng, Zhenru Zhang, Beichen Zhang, Runji Lin, Keming Lu, Bowen Yu, Dayiheng Liu, Jingren Zhou, Junyang Lin</em></li>
  <li><strong>Model Extrapolation Expedites Alignment</strong><br><em>Chujie Zheng, Ziqi Wang, Heng Ji, Minlie Huang, Nanyun Peng</em></li>
  <li><strong>ATLANTIS: Weak-to-Strong Learning via Importance Sampling</strong><br><em>Yi Liu, Guoyin Wang, Shicheng Li, Feifan Song, Xu Sun</em></li>
  <li><strong>MPVStance: Mitigating Hallucinations in Stance Detection with Multi-Perspective Verification</strong><br><em>ZhaoDan Zhang, Zhao Zhang, Jin Zhang, Hui Xu, Xueqi Cheng</em></li>
  <li><strong>Personality-Guided Code Generation Using Large Language Models</strong><br><em>Yaoqi Guo, Zhenpeng Chen, Jie Zhang, Yang Liu, Yun Ma</em></li>
  <li><strong>PsyDT: Using LLMs to Construct the Digital Twin of Psychological Counselor with Personalized Counseling Style for Psychological Counseling</strong><br><em>Haojie Xie, Yirong Chen, Xiaofen Xing, Jingkai Lin, Xiangmin Xu</em></li>
  <li><strong>BIPro: Zero-shot Chinese Poem Generation via Block Inverse Prompting Constrained Generation Framework</strong><br><em>Xu Zou</em></li>
  <li><strong>Rethinking KenLM: Good and Bad Model Ensembles for Efficient Text Quality Filtering in Large Web Corpora</strong><br><em>Yungi Kim, Hyunsoo Ha, Sukyung Lee, Jihoo Kim, Seonghoon Yang, Chanjun Park</em></li>
  <li><strong>Automatic detection of dyslexia based on eye movements during reading in Russian</strong><br><em>Anna Laurinavichyute, Anastasiya Lopukhina, David Robert Reich</em></li>
  <li><strong>LongDocURL: a Comprehensive Multimodal Long Document Benchmark Integrating Understanding, Reasoning, and Locating</strong><br><em>CHAO DENG, Jiale Yuan, Pi Bu, Peijie Wang, Zhong-Zhi Li, Jian Xu, Xiao-Hui Li, Yuan Gao, Jun Song, Bo Zheng, Cheng-Lin Liu</em></li>
  <li><strong>ObfusLM: Privacy-preserving Language Model Service against Embedding Inversion Attacks</strong><br><em>Yu Lin, Ruining Yang, Yunlong Mao, Qizhi Zhang, Jue Hong, Quanwei Cai, Ye Wu, Huiqi Liu, zhiyu chen, Bing Duan, Sheng Zhong</em></li>
  <li><strong>Interlocking-free Selective Rationalization Through Genetic-based Learning</strong><br><em>Federico Ruggeri, Gaetano Signorelli</em></li>
  <li><strong>Re-identification of De-identified Documents with Autoregressive Infilling</strong><br><em>Lucas Georges Gabriel Charpentier, Pierre Lison</em></li>
  <li><strong>Modeling Uncertainty in Composed Image Retrieval via Probabilistic Embedding</strong><br><em>Haomiao Tang, Jinpeng Wang, Yuang Peng, GuangHao Meng, Ruisheng Luo, Bin Chen, Long Chen, Yaowei Wang, Shu-Tao Xia</em></li>
  <li><strong>Untie the Knots: An Efficient Data Augmentation Strategy for Long-Context Pre-Training in Language Models</strong><br><em>Junfeng Tian, Da Zheng, Yang Chen, Rui Wang, colin zhang, Debing Zhang</em></li>
  <li><strong>Doc-React: Multi-page Heterogeneous Document Question-answering</strong><br><em>Junda Wu, Yu Xia, Tong Yu, Xiang Chen, Sai Sree Harsha, Akash V Maharaj, Ruiyi Zhang, Victor Bursztyn, Sungchul Kim, Ryan A. Rossi, Julian McAuley, Yunyao Li, Ritwik Sinha</em></li>
  <li><strong>CECT dataset: Overcoming Data Scarcity in Context-Aware E-Commerce MT</strong><br><em>Mikołaj Pokrywka, Wojciech Kusa, Mieszko Rutkowski, Mikołaj Koszowski</em></li>
  <li><strong>APPL: A Prompt Programming Language for Harmonious Integration of Programs and Large Language Model Prompts</strong><br><em>Honghua Dong, Qidong Su, Yubo Gao, Zhaoyu Li, Yangjun Ruan, Gennady Pekhimenko, Chris J. Maddison, Xujie Si</em></li>
  <li><strong>A Measure of the System Dependence of Automated Metrics</strong><br><em>Pius von Däniken, Jan Milan Deriu, Mark Cieliebak</em></li>
  <li><strong>Evaluating Lexical Proficiency in Neural Language Models</strong><br><em>Cristiano Ciaccio, Alessio Miaschi, Felice Dell’Orletta</em></li>
  <li><strong>Autoregressive Speech Synthesis without Vector Quantization</strong><br><em>Lingwei Meng, Long Zhou, Shujie LIU, Sanyuan Chen, Bing Han, Shujie HU, Yanqing Liu, Jinyu Li, sheng zhao, Xixin Wu, Helen M. Meng, Furu Wei</em></li>
  <li><strong>Cuckoo: An IE Free Rider Hatched by Massive Nutrition in LLM’s Nest</strong><br><em>Letian Peng, Zilong Wang, Feng Yao, Jingbo Shang</em></li>
  <li><strong>FedEx-LoRA: Exact Aggregation for Federated and Efficient Fine-Tuning of Large Language Models</strong><br><em>Raghav Singhal, Kaustubh Ponkshe, Praneeth Vepakomma</em></li>
  <li><strong>Measuring Social Biases in Masked Language Models by Proxy of Prediction Quality</strong><br><em>Rahul Zalkikar, Kanchan Chandra</em></li>
  <li><strong>Capturing Author Self Beliefs in Social Media Language</strong><br><em>Siddharth Mangalik, Adithya V Ganesan, Abigail B. Wheeler, Nicholas Kerry, Jeremy D. W. Clifton, H. Schwartz, Ryan L. Boyd</em></li>
  <li><strong>Neural Topic Modeling with Large Language Models in the Loop</strong><br><em>Xiaohao Yang, He Zhao, Weijie Xu, YUANYUAN QI, Jueqing Lu, Dinh Phung, Lan Du</em></li>
  <li><strong>HALoGEN: Fantastic LLM Hallucinations and Where to Find Them</strong><br><em>Abhilasha Ravichander, Shrusti Ghela, David Wadden, Yejin Choi</em></li>
  <li><strong>Synergizing LLMs with Global Label Propagation for Multimodal Fake News Detection</strong><br><em>Shuguo Hu, Jun Hu, Huaiwen Zhang</em></li>
  <li><strong>“Yes, My LoRD.” Guiding Language Model Extraction with Locality Reinforced Distillation</strong><br><em>Zi Liang, Qingqing Ye, Yanyun Wang, Sen Zhang, Yaxin Xiao, RongHua Li, Jianliang Xu, Haibo Hu</em></li>
  <li><strong>Jailbreak Large Vision-Language Models Through Multi-Modal Linkage</strong><br><em>Yu Wang, Xiaofei Zhou, Yichen Wang, Geyuan Zhang, Tianxing He</em></li>
  <li><strong>Wait, that’s not an option: LLMs Robustness with Incorrect Multiple-Choice Options</strong><br><em>Gracjan Góral, Emilia Wiśnios, Piotr Sankowski, Paweł Budzianowski</em></li>
  <li><strong>The Hidden Attention of Mamba Models</strong><br><em>Ameen Ali Ali, Itamar Zimerman, Lior Wolf</em></li>
  <li><strong>KV-Latent: Dimensional-level KV Cache Reduction with Frequency-aware Rotary Positional Embedding</strong><br><em>Shi Luohe, Zuchao Li, Lefei Zhang, Baoyuan Qi, Liu Guoming, hai zhao</em></li>
  <li><strong>LEANCODE: Understanding Models Better for Code Simplification of Pre-trained Large Language Models</strong><br><em>YAN WANG, Ling Ding, Tien N Nguyen, Shaohua Wang, Yanan Zheng</em></li>
  <li><strong>MARS: Benchmarking the Metaphysical Reasoning Abilities of Language Models with a Multi-task Evaluation Dataset</strong><br><em>Weiqi Wang, Yangqiu Song</em></li>
  <li><strong>Ask-Before-Detection: Identifying and Mitigating Conformity Bias in LLM-Powered Error Detector for Math Word Problem Solutions</strong><br><em>Hang Li, Tianlong Xu, Kaiqi Yang, Yucheng Chu, Yanling Chen, Yichi Song, Qingsong Wen, Hui Liu</em></li>
  <li><strong>Real-time Fake News from Adversarial Feedback</strong><br><em>Sanxing Chen, Yukun Huang, Bhuwan Dhingra</em></li>
  <li><strong>Improve Vision Language Model Chain-of-thought Reasoning</strong><br><em>Ruohong Zhang, Bowen Zhang, Yanghao Li, Haotian Zhang, Zhiqing Sun, Zhe Gan, Yinfei Yang, Ruoming Pang, Yiming Yang</em></li>
  <li><strong>On the Mutual Influence of Gender and Occupation in LLM Representations</strong><br><em>Haozhe An, Connor Baumler, Abhilasha Sancheti, Rachel Rudinger</em></li>
  <li><strong>Disentangling Memory and Reasoning Ability in Large Language Models</strong><br><em>Mingyu Jin, Weidi Luo, Sitao Cheng, Xinyi Wang, Wenyue Hua, Ruixiang Tang, William Yang Wang, Yongfeng Zhang</em></li>
  <li><strong>Open-World Attribute Mining for E-Commerce Products with Multimodal Self-Correction Instruction Tuning</strong><br><em>Jiaqi Li, Yanming Li, Xiaoli Shen, Chuanyi Zhang, Guilin Qi, Sheng Bi</em></li>
  <li><strong>Normalized AOPC: Fixing Misleading Faithfulness Metrics for Feature Attributions Explainability</strong><br><em>Joakim Edin, Andreas Geert Motzfeldt, Casper L. Christensen, Tuukka Ruotsalo, Lars Maaløe, Maria Maistro</em></li>
  <li><strong>Takin-VC: Expressive Zero-Shot Voice Conversion via Adaptive Hybrid Content Encoding and Enhanced Timbre Modeling</strong><br><em>Yang Yuguang, Yu Pan, Jixun Yao, xiang zhang, Jianhao Ye, Hongbin Zhou, Lei Xie, Lei Ma, Jianjun Zhao</em></li>
  <li><strong>LangSAMP: Language-Script Aware Multilingual Pretraining</strong><br><em>Yihong Liu, Haotian Ye, Chunlan Ma, Mingyang Wang, Hinrich Schuetze</em></li>
  <li><strong>RelationalCoder: Relational Representation of Complex Tables for Program-Based Processing and Reasoning</strong><br><em>Haoyu Dong, Yue Hu, Huailiang Peng, Yanan Cao</em></li>
  <li><strong>Algorithmic Fidelity of Large Language Models in Generating Synthetic German Public Opinions: A Case Study</strong><br><em>Bolei Ma, Berk Yoztyurk, Anna-Carolina Haensch, Xinpeng Wang, Markus Herklotz, Frauke Kreuter, Barbara Plank, Matthias Aßenmacher</em></li>
  <li><strong>TUNA: Comprehensive Fine-grained Temporal Understanding Evaluation on Dense Dynamic Videos</strong><br><em>Fanheng Kong, Jingyuan Zhang, Hongzhi Zhang, Shi Feng, Daling Wang, Linhao Yu, Xingguang Ji, Yu Tian, V. W., Fuzheng Zhang</em></li>
  <li><strong>Self-Instructed Derived Prompt Generation Meets In-Context Learning: Unlocking New Potential of Black-Box LLMs</strong><br><em>Zhuo Li, Yuhao Du, Jinpeng Hu, Xiang Wan, Anningzhe Gao</em></li>
  <li><strong>Binary Classifier Optimization for Large Language Model Alignment</strong><br><em>Seungjae Jung</em></li>
  <li><strong>UnSeenTimeQA: Time-Sensitive Question-Answering Beyond LLMs’ Memorization</strong><br><em>Md Nayem Uddin, Amir Saeidi, Divij Handa, Agastya Seth, Tran Cao Son, Eduardo Blanco, Steven Corman, Chitta Baral</em></li>
  <li><strong>From Information to Insight: Leveraging LLMs for Open Aspect-Based Educational Summarization</strong><br><em>Yang Zhong, Diane Litman</em></li>
  <li><strong>AfriMed-QA: A Pan-African, Multi-Specialty, Medical Question-Answering Benchmark Dataset</strong><br><em>Charles Nimo, Tobi Olatunji, Abraham Toluwase Owodunni, Tassallah Abdullahi, Emmanuel Ayodele, Mardhiyah Sanni, Ezinwanne C. Aka, Folafunmi Omofoye, Foutse Yuehgoh, Timothy Faniran, Bonaventure F. P. Dossou, Moshood O. Yekini, Jonas Kemp, Katherine A Heller, Jude Chidubem Omeke, Chidi Asuzu MD, Naome A Etori, Aïmérou Ndiaye, Ifeoma Okoh, Evans Doe Ocansey, Wendy Kinara, Michael Best, Irfan Essa, Stephen Edward Moore, Chris Fourie, Mercy Nyamewaa Asiedu</em></li>
  <li><strong>Root Defense Strategies: Ensuring Safety of LLM at the Decoding Level</strong><br><em>Xinyi Zeng, Yuying Shang, Jiawei Chen, Jingyuan Zhang, Yu Tian</em></li>
  <li><strong>In-the-wild Audio Spatialization with Flexible Text-guided Localization</strong><br><em>Tianrui Pan, Jie Liu, Zewen Huang, Jie Tang, Gangshan Wu</em></li>
  <li><strong>L4Q: Parameter Efficient Quantization-Aware Fine-Tuning on Large Language Models</strong><br><em>Hyesung Jeon, Yulhwa Kim, Jae-Joon Kim</em></li>
  <li><strong>Second Language (Arabic) Acquisition of LLMs via Progressive Vocabulary Expansion</strong><br><em>Jianqing Zhu, Huang Huang, Zhihang Lin, Juhao Liang, Zhengyang Tang, Khalid Almubarak, Mosen Alharthi, Bang An, Juncai He, Xiangbo Wu, Fei Yu, Junying Chen, MA Zhuoheng, Yuhao Du, He Zhang, Saied Alshahrani, Emad A. Alghamdi, Lian Zhang, Ruoyu Sun, Haizhou Li, Benyou Wang, Jinchao Xu</em></li>
  <li><strong>What Really Matters in Many-Shot Attacks? An Empirical Study of Long-Context Vulnerabilities in LLMs</strong><br><em>Sangyeop Kim, Yohan Lee, Yongwoo Song, Kimin Lee</em></li>
  <li><strong>ECERC: Evidence-Cause Attention Network for Multi-Modal Emotion Recognition in Conversation</strong><br><em>Tao Zhang, Zhenhua Tan</em></li>
  <li><strong>CompileAgent: Automated Real-World Repo-Level Compilation with Tool-Integrated LLM-based Agent System</strong><br><em>Li Hu, Guoqiang Chen, Xiuwei Shang, Shaoyin Cheng, Benlong Wu, LiGangyang, Xu Zhu, Weiming Zhang, Nenghai Yu</em></li>
  <li><strong>Beyond Demographics: Fine-tuning Large Language Models to Predict Individuals’ Subjective Text Perceptions</strong><br><em>Matthias Orlikowski, Jiaxin Pei, Paul Röttger, Philipp Cimiano, David Jurgens, Dirk Hovy</em></li>
  <li><strong>Exploring Forgetting in Large Language Model Pre-Training</strong><br><em>Chonghua Liao, Ruobing Xie, Xingwu Sun, Haowen Sun, Zhanhui Kang</em></li>
  <li><strong>Call for Rigor in Reporting Quality of Instruction Tuning Data</strong><br><em>Hyeonseok Moon, Jaehyung Seo, Heuiseok Lim</em></li>
  <li><strong>Bias in the Mirror : Are LLMs opinions robust to their own adversarial attacks</strong><br><em>Virgile Rennard, Christos Xypolopoulos, Michalis Vazirgiannis</em></li>
  <li><strong>AndroidLab: Developing and Evaluating Android Agents in A Reproducible Environment</strong><br><em>Yifan Xu, Xiao Liu, Xueqiao Sun, Siyi Cheng, Hao Yu, Hanyu Lai, Shudan Zhang, Dan Zhang, Jie Tang, Yuxiao Dong</em></li>
  <li><strong>Modular Sentence Encoders: Separating Language Specialization from Cross-Lingual Alignment</strong><br><em>Yongxin Huang, Kexin Wang, Goran Glavaš, Iryna Gurevych</em></li>
  <li><strong>Multimodal Transformers are Hierarchical Modal-wise Heterogeneous Graphs</strong><br><em>Yijie Jin, Junjie Peng, Xuanchao Lin, Haochen Yuan, Lan Wang, Cangzhi Zheng</em></li>
  <li><strong>Have We Designed Generalizable Structural Knowledge Promptings? Systematic Evaluation and Rethinking</strong><br><em>Yichi Zhang, Zhuo Chen, Lingbing Guo, yajing Xu, Shaokai Chen, Mengshu Sun, Binbin Hu, Zhiqiang Zhang, Lei Liang, Wen Zhang, Huajun Chen</em></li>
  <li><strong>LLäMmlein 🐑: Transparent, Compact and Competitive German-Only Language Models from Scratch</strong><br><em>Jan Pfister, Julia Wunderle, Andreas Hotho</em></li>
  <li><strong>Speaking Beyond Language: A Large-Scale Multimodal Dataset for Learning Nonverbal Cues from Video-Grounded Dialogues</strong><br><em>Youngmin Kim, Jiwan Chung, Jisoo Kim, sunghyun lee, Sangkyu Lee, Junhyeok Kim, Cheoljong Yang, Youngjae Yu</em></li>
  <li><strong>How Much Do Pretrained Language Models Know About Word Senses?</strong><br><em>Simone Teglia, Simone Tedeschi, Roberto Navigli</em></li>
  <li><strong>When Backdoors Speak: Understanding LLM Backdoor Attacks Through Model-Generated Explanations</strong><br><em>Huaizhi Ge, Yiming Li, Qifan Wang, Yongfeng Zhang, Ruixiang Tang</em></li>
  <li><strong>HateDay: Insights from a Global Hate Speech Dataset Representative of a Day on Twitter</strong><br><em>Manuel Tonneau, Diyi Liu, Niyati Malhotra, Scott A. Hale, Samuel Fraiberger, Victor Orozco-Olvera, Paul Röttger</em></li>
  <li><strong>LegalAgentBench: Evaluating LLM Agents in Legal Domain</strong><br><em>Haitao Li, Junjie Chen, Jingli Yang, Qingyao Ai, Wei Jia, Youfeng Liu, Kai Lin, Yueyue WU, Guozhi Yuan, Yiran HU, Wuyue Wang, Yiqun LIU, Minlie Huang</em></li>
  <li><strong>Inference Compute-Optimal Video Vision Language Models</strong><br><em>Peiqi Wang, ShengYun Peng, Xuewen Zhang, Hanchao Yu, Yibo Yang, Lifu Huang, Fujun Liu, Qifan Wang</em></li>
  <li><strong>Steering into New Embedding Spaces: Analyzing Cross-Lingual Alignment Induced by Model Interventions in Multilingual Language Models</strong><br><em>Anirudh Sundar, Sinead Williamson, Katherine Metcalf, Barry-John Theobald, Skyler Seto, Masha Fedzechkina</em></li>
  <li><strong>Digital Gatekeepers: Google’s Role in Curating Hashtags and Subreddits</strong><br><em>Amrit Poudel, Yifan Ding, Tim Weninger, Jürgen Pfeffer</em></li>
  <li><strong>Behind Closed Words: Creating and Investigating the forePLay Annotated Dataset for Polish Erotic Discourse</strong><br><em>Anna Kołos, Katarzyna Lorenc, Emilia Wiśnios, Agnieszka Karlińska</em></li>
  <li><strong>Assessment and manipulation of latent constructs in pre-trained language models using psychometric scales</strong><br><em>Maor Reuben, Ortal Slobodin, Idan-Chaim Cohen, Aviad Elyashar, Orna Braun-Lewensohn, Odeya Cohen, Rami Puzis</em></li>
  <li><strong>Did Translation Models Get More Robust Without Anyone Even Noticing?</strong><br><em>Ben Peters, Andre Martins</em></li>
  <li><strong>Transforming Common Crawl into a Refined Long-Horizon Pretraining Dataset</strong><br><em>Dan SU, Kezhi Kong, Ying Lin, Joseph Jennings, Brandon Norick, Markus Kliegl, Mostofa Patwary, Mohammad Shoeybi, Bryan Catanzaro</em></li>
  <li><strong>Hierarchical Level-Wise News Article Clustering via Multilingual Matryoshka Embeddings</strong><br><em>Hans William Alexander Hanley, Zakir Durumeric</em></li>
  <li><strong>Contrastive Perplexity for Controlled Generation: An Application in Detoxifying Large Language Models</strong><br><em>Tassilo Klein, Moin Nabi</em></li>
  <li><strong>INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks with LLM-based Agent</strong><br><em>Haohang Li, Yupeng Cao, Yangyang Yu, Shashidhar Reddy Javaji, Zhiyang Deng, Yueru He, Yuechen Jiang, Zining Zhu, K.P. Subbalakshmi, Jimin Huang, Lingfei Qian, Xueqing Peng, Jordan W. Suchow, Qianqian Xie</em></li>
  <li><strong>Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference</strong><br><em>Benjamin Warner, Antoine Chaffin, Benjamin Clavié, Orion Weller, Oskar Hallström, Said Taghadouini, Alexis Gallagher, Raja Biswas, Faisal Ladhak, Tom Aarsen, Griffin Thomas Adams, Jeremy Howard, Iacopo Poli</em></li>
  <li><strong>Gender Inclusivity Fairness Index (GIFI): A Multilevel Framework for Evaluating Gender Diversity in Large Language Models</strong><br><em>Zhengyang Shan, Emily Diana, Jiawei Zhou</em></li>
  <li><strong>D.Va: Validate Your Demonstration First Before You Use It</strong><br><em>Qi Zhang, Zhiqing Xiao, Ruixuan Xiao, Lirong Gao, Junbo Zhao</em></li>
  <li><strong>Are Any-to-Any Models More Consistent Across Modality Transfers Than Specialists?</strong><br><em>Jiwan Chung, Janghan Yoon, Junhyeong Park, Sangeyl Lee, Joowon Yang, Sooyeon Park, Youngjae Yu</em></li>
  <li><strong>MAIN-RAG: Multi-Agent Filtering Retrieval-Augmented Generation</strong><br><em>Chia-Yuan Chang, Zhimeng Jiang, Vineeth Rakesh, Menghai Pan, Chin-Chia Michael Yeh, Guanchu Wang, Mingzhi Hu, Zhichao Xu, Yan Zheng, Mahashweta Das, Na Zou</em></li>
  <li><strong>Unraveling the Mechanics of Learning-Based Demonstration Selection for In-Context Learning</strong><br><em>Hui Liu, Wenya Wang, Hao Sun, Chris XING TIAN, Chenqi Kong, Xin Dong, Haoliang Li</em></li>
  <li><strong>Direct Prompt Optimization with Continuous Representations</strong><br><em>Yangkun Wang, Zihan Wang, Jingbo Shang</em></li>
  <li><strong>uMedSum: A Unified Framework for Advancing Medical Abstractive Summarization</strong><br><em>Aishik Nagar, Yutong Liu, Andy T. Liu, Viktor Schlegel, Vijay Prakash Dwivedi, Arun-Kumar Kaliya-Perumal, GUNA PRATHEEP KALANCHIAM, Yili Tang, Robby T. Tan</em></li>
  <li><strong>GigaSpeech 2: An Evolving, Large-Scale and Multi-domain ASR Corpus for Low-Resource Languages with Automated Crawling, Transcription and Refinement</strong><br><em>Yifan Yang, Zheshu Song, Jianheng Zhuo, Mingyu Cui, Jinpeng Li, Bo Yang, Yexing Du, Ziyang Ma, Xunying Liu, Ziyuan Wang, Ke Li, Shuai Fan, Kai Yu, Wei-Qiang Zhang, Guoguo Chen, Xie Chen</em></li>
  <li><strong>Context-Aware Sentiment Forecasting via LLM-based Multi-Perspective Role-Playing Agents</strong><br><em>Fanhang Man, Huandong Wang, Jianjie Fang, Zhaoyi Deng, Baining Zhao, Xinlei Chen, Yong Li</em></li>
  <li><strong>TARGA: Targeted Synthetic Data Generation for Practical Reasoning over Structured Data</strong><br><em>Xiang Huang, Jiayu Shen, Shanshan Huang, Sitao Cheng, Xiaxia Wang, Yuzhong Qu</em></li>
  <li><strong>AndroidGen: Building an Android Language Agent under Data Scarcity</strong><br><em>Hanyu Lai, Junjie Gao, Xiao Liu, Yifan Xu, Shudan Zhang, Yuxiao Dong, Jie Tang</em></li>
  <li><strong>Prompt Candidates, then Distill: A Teacher-Student Framework for LLM-driven Data Annotation</strong><br><em>Mingxuan Xia, Haobo Wang, Yixuan Li, Zewei Yu, Jindong Wang, Junbo Zhao, Runze Wu</em></li>
  <li><strong>BQA: Body Language Question Answering Dataset for Video Large Language Models</strong><br><em>Shintaro Ozaki, Kazuki Hayashi, Miyu Oba, Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe</em></li>
  <li><strong>A Survey of Post-Training Scaling in Large Language Models</strong><br><em>Hanyu Lai, Xiao Liu, Junjie Gao, Jiale Cheng, Zehan Qi, Yifan Xu, Shuntian Yao, Dan Zhang, Jinhua Du, Zhenyu Hou, Xin Lv, Minlie Huang, Yuxiao Dong, Jie Tang</em></li>
  <li><strong>Position-aware Automatic Circuit Discovery</strong><br><em>Tal Haklay, Hadas Orgad, David Bau, Aaron Mueller, Yonatan Belinkov</em></li>
  <li><strong>HyperFM: Fact-Centric Multimodal Fusion for Link Prediction over Hyper-Relational Knowledge Graphs</strong><br><em>Yuhuan Lu, Weijian Yu, Xin Jing, Dingqi Yang</em></li>
  <li><strong>Centurio: On Drivers of Multilingual Ability of Large Vision-Language Model</strong><br><em>Gregor Geigle, Florian Schneider, Carolin Holtermann, Chris Biemann, Radu Timofte, Anne Lauscher, Goran Glavaš</em></li>
  <li><strong>Less for More: Enhanced Feedback-aligned Mixed LLMs for Molecule Caption Generation and Fine-Grained NLI Evaluation</strong><br><em>Dimitris Gkoumas, Maria Liakata</em></li>
  <li><strong>Ensemble Watermarks for Large Language Models</strong><br><em>Georg Niess, Roman Kern</em></li>
  <li><strong>$\mathsf{Con Instruction}$: Universal Jailbreaking of Multimodal Large Language Models via Non-Textual Modalities</strong><br><em>Jiahui Geng, Thy Thy Tran, Preslav Nakov, Iryna Gurevych</em></li>
  <li><strong>TRACT: Regression-Aware Fine-tuning Meets Chain-of-Thought Reasoning for LLM-as-a-Judge</strong><br><em>Cheng-Han Chiang, Hung-yi Lee, Michal Lukasik</em></li>
  <li><strong>DioR: Adaptive Cognitive Detection and Contextual Retrieval Optimization for Dynamic Retrieval-Augmented Generation</strong><br><em>Hanghui Guo, Jia Zhu, Shimin Di, Weijie Shi, Zhangze Chen, Jiajie Xu</em></li>
  <li><strong>Unveiling the Power of Source: Source-based Minimum Bayes Risk Decoding for Neural Machine Translation</strong><br><em>Boxuan Lyu, Hidetaka Kamigaito, Kotaro Funakoshi, Manabu Okumura</em></li>
  <li><strong>ToolHop: A Query-Driven Benchmark for Evaluating Large Language Models in Multi-Hop Tool Use</strong><br><em>Junjie Ye, Zhengyin Du, Xuesong Yao, Weijian Lin, Yufei Xu, Zehui Chen, Zaiyuan Wang, Sining Zhu, Zhiheng Xi, Siyu Yuan, Tao Gui, Qi Zhang, Xuanjing Huang, Jiecao Chen</em></li>
  <li><strong>Mixture of insighTful Experts (MoTE): The Synergy of Reasoning Chains and Expert Mixtures in Self-Alignment</strong><br><em>Zhili Liu, Yunhao GOU, Kai Chen, Lanqing HONG, Jiahui Gao, Fei Mi, Yu Zhang, Zhenguo Li, Xin Jiang, Qun Liu, James Kwok</em></li>
  <li><strong>MAPS: Motivation-Aware Personalized Search via LLM-Driven Consultation Alignment</strong><br><em>Weicong Qin, Yi Xu, Weijie Yu, Chenglei Shen, Ming He, Jianping Fan, Xiao Zhang, Jun Xu</em></li>
  <li><strong>Aristotle: Mastering Logical Reasoning with A Logic-Complete Decompose-Search-Resolve Framework</strong><br><em>Jundong Xu, Hao Fei, Meng Luo, Qian Liu, Liangming Pan, William Yang Wang, Preslav Nakov, Mong-Li Lee, Wynne Hsu</em></li>
  <li><strong>LADM: Long-context Training Data Selection with Attention-based Dependency Measurement for LLMs</strong><br><em>Jianghao Chen, Junhong Wu, Yangyifan Xu, Jiajun Zhang</em></li>
  <li><strong>Iron Sharpens Iron: Defending Against Attacks in Machine-Generated Text Detection with Adversarial Training</strong><br><em>Yuanfan Li, Zhaohan Zhang, Chengzhengxu Li, Chao Shen, Xiaoming Liu</em></li>
  <li><strong>Cultural Learning-Based Culture Adaptation of Language Models</strong><br><em>Chen Cecilia Liu, Anna Korhonen, Iryna Gurevych</em></li>
  <li><strong>A-TASC: Asian TED-Based Automatic Subtitling Corpus</strong><br><em>Yuhan Zhou, Naoki Yoshinaga</em></li>
  <li><strong>Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training</strong><br><em>Youliang Yuan, Wenxiang Jiao, Wenxuan Wang, Jen-tse Huang, Jiahao Xu, Tian Liang, Pinjia He, Zhaopeng Tu</em></li>
  <li><strong>Token Prepending: A Training-Free Approach for Eliciting Better Sentence Embeddings from LLMs</strong><br><em>Yuchen Fu, Zifeng Cheng, Zhiwei Jiang, Zhonghui Wang, Yafeng Yin, Zhengliang Li, Qing Gu</em></li>
  <li><strong>No Questions are Stupid, but some are Poorly Posed: Understanding Poorly-Posed Information-Seeking Questions</strong><br><em>Neha Srikanth, Rachel Rudinger, Jordan Lee Boyd-Graber</em></li>
  <li><strong>Understanding Common Ground Misalignment in Goal-Oriented Dialog: A Case-Study with Ubuntu Chat Logs</strong><br><em>Rupak Sarkar, Neha Srikanth, Taylor Hudson, Rachel Rudinger, Claire Bonial, Philip Resnik</em></li>
  <li><strong>Grounded, or a Good Guesser? A Per-Question Balanced Dataset to Separate Blind from Grounded Models for Embodied Question Answering</strong><br><em>Miles Shelton, Nate Wingerd, Kritim K Rijal, Ayush Garg, Adelina Gutic, Brett Barnes, Catherine Finegan-Dollak</em></li>
  <li><strong>Addressing Blind Guessing: Calibration of Selection Bias in Multiple-Choice Question Answering by Video Language Models</strong><br><em>Olga Loginova, Oleksandr Bezrukov, Ravi Shekhar, Alexey Kravets</em></li>
  <li><strong>Towards Reward Fairness in RLHF: From a Resource Allocation Perspective</strong><br><em>Sheng Ouyang, Yulan Hu, Ge Chen, Qingyang Li, Fuzheng Zhang, Yong Liu</em></li>
  <li><strong>Taming LLMs with Gradient Grouping</strong><br><em>Siyuan Li, Juanxi Tian, Zedong Wang, Xin Jin, Zicheng Liu, Wentao Zhang, Dan Xu</em></li>
  <li><strong>LazyReview A Dataset for Uncovering Lazy Thinking in NLP Peer Reviews</strong><br><em>Sukannya Purkayastha, Zhuang Li, Anne Lauscher, Lizhen Qu, Iryna Gurevych</em></li>
  <li><strong>Revisiting Common Assumptions about Arabic Dialects in NLP</strong><br><em>Amr Keleg, Sharon Goldwater, Walid Magdy</em></li>
  <li><strong>Retrieve to Explain: Evidence-driven Predictions for Explainable Drug Target Identification</strong><br><em>Ravi Patel, Angus Brayne, Rogier Hintzen, Daniel Jaroslawicz, Georgiana Neculae, Dane S. Corneil</em></li>
  <li><strong>Whose Boat Does it Float? Improving Personalization in Preference Tuning via Inferred User Personas</strong><br><em>Nishant Balepur, Vishakh Padmakumar, Fumeng Yang, Shi Feng, Rachel Rudinger, Jordan Lee Boyd-Graber</em></li>
  <li><strong>Which of These Best Describes Multiple Choice Evaluation with LLMs? A) Forced B) Flawed C) Fixable D) All of the Above</strong><br><em>Nishant Balepur, Rachel Rudinger, Jordan Lee Boyd-Graber</em></li>
  <li><strong>Detection of Human and Machine-Authored Fake News in Urdu</strong><br><em>Muhammad Zain Ali, Yuxia Wang, Bernhard Pfahringer, Tony C Smith</em></li>
  <li><strong>An Efficient Task-Oriented Dialogue Policy: Evolutionary Reinforcement Learning Injected by Elite Individuals.</strong><br><em>Yangyang Zhao, Ben Niu, Libo Qin, Shihan Wang</em></li>
  <li><strong>SR-LLM: Rethinking the Structured Representation in Large Language Model</strong><br><em>Jiahuan Zhang, Tianheng Wang, Ziyi Huang, Yulong Wu, HANQING WU, DongbaiChen, Linfeng Song, Yue Zhang, guozheng rao, Kaicheng Yu</em></li>
  <li><strong>Learning Sparsity for Effective and Efficient Music Performance Question Answering</strong><br><em>Xingjian Diao, Tianzhen Yang, Chunhui Zhang, Weiyi Wu, Ming Cheng, Jiang Gui</em></li>
  <li><strong>Taming Language Models for Text-attributed Graph Learning with Decoupled Aggregation</strong><br><em>Chuang Zhou, Zhu Wang, Shengyuan Chen, Jiahe Du, Qiyuan Zheng, Zhaozhuo Xu, Xiao Huang</em></li>
  <li><strong>Contrastive Prompting Enhances Sentence Embeddings in LLMs through Inference-Time Steering</strong><br><em>Zifeng Cheng, Zhonghui Wang, Yuchen Fu, Zhiwei Jiang, Yafeng Yin, Cong Wang, Qing Gu</em></li>
  <li><strong>Cracking the Code of Hallucination in LVLMs with Vision-aware Head Divergence</strong><br><em>Jinghan He, Kuan Zhu, Haiyun Guo, Junfeng Fang, Zhenglin Hua, Yuheng Jia, Ming Tang, Tat-Seng Chua, Jinqiao Wang</em></li>
  <li><strong>Hierarchical Document Refinement for Long-context Retrieval-augmented Generation</strong><br><em>Jiajie Jin, Xiaoxi Li, Guanting Dong, Yuyao Zhang, Yutao Zhu, Yongkang Wu, Zhonghua Li, YE QI, Zhicheng Dou</em></li>
  <li><strong>Comparing Moral Values in Western English-speaking societies and LLMs with Word Associations</strong><br><em>Chaoyi Xiang, Chunhua Liu, Simon De Deyne, Lea Frermann</em></li>
  <li><strong>TEACH: A Contrastive Knowledge Adaptive Distillation Framework for Ancient Chinese Understanding</strong><br><em>Yuting Wei, Qi Meng, Yuanxing Xu, Bin Wu</em></li>
  <li><strong>RAG-Critic: Leveraging Automated Critic-Guided Agentic Workflow for Retrieval Augmented Generation</strong><br><em>Guanting Dong, Jiajie Jin, Xiaoxi Li, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen</em></li>
  <li><strong>Progressive Multimodal Reasoning via Active Retrieval</strong><br><em>Guanting Dong, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen</em></li>
  <li><strong>Pre-training Distillation for Large Language Models: A Design Space Exploration</strong><br><em>Hao Peng, Xin Lv, Yushi Bai, Zijun Yao, Jiajie Zhang, Lei Hou, Juanzi Li</em></li>
  <li><strong>Teaching Vision-Language Models to Ask: Resolving Ambiguity in Visual Questions</strong><br><em>Pu Jian, Donglei Yu, Jiajun Zhang, Shuo Ren, Wen Yang</em></li>
  <li><strong>LongBench v2: Towards Deeper Understanding and Reasoning on Realistic Long-context Multitasks</strong><br><em>Yushi Bai, Shangqing Tu, Jiajie Zhang, Hao Peng, Xiaozhi Wang, Xin Lv, Shulin Cao, Jiazheng Xu, Lei Hou, Yuxiao Dong, Jie Tang, Juanzi Li</em></li>
  <li><strong>Battling against Tough Resister: Strategy Planning with Adversarial Game for Non-collaborative Dialogues</strong><br><em>Haiyang Wang, Zhiliang Tian, Yuchen Pan, Xin Song, Xin Niu, Minlie Huang, Bin Zhou</em></li>
  <li><strong>Cross-model Transferability among Large Language Models on the Platonic Representations of Concepts</strong><br><em>Youcheng Huang, Chen Huang, Duanyu Feng, Wenqiang Lei, Jiancheng Lv</em></li>
  <li><strong>FoldMoE: Efficient Long Sequence MoE Training via Attention-MoE Pipelining</strong><br><em>Guichao Zhu, Lintian Lei, Yuhao QING, Yichao Fu, Fanxin Li, Dong HUANG, Zekai Sun, Heming Cui</em></li>
  <li><strong>LongReward: Improving Long-context Large Language Models with AI Feedback</strong><br><em>Jiajie Zhang, Zhongni Hou, Xin Lv, Shulin Cao, Zhenyu Hou, Yilin Niu, Lei Hou, Yuxiao Dong, Ling Feng, Juanzi Li</em></li>
  <li><strong>Influences on LLM Calibration: A Study of Response Agreement, Loss Functions, and Prompt Styles</strong><br><em>Yuxi Xia, Pedro Henrique Luz de Araujo, Klim Zaporojets, Benjamin Roth</em></li>
  <li><strong>UTBoost: Rigorous Evaluation of Coding Agents on SWE-Bench</strong><br><em>Boxi Yu, Yuxuan Zhu, Pinjia He, Daniel Kang</em></li>
  <li><strong>Towards Better Evaluation for Generated Patent Claims</strong><br><em>Lekang Jiang, Pascal A. Scherz, Stefan Goetz</em></li>
  <li><strong>Fine-Tuning on Diverse Reasoning Chains Drives Within-Inference CoT Refinement in LLMs</strong><br><em>Haritz Puerto, Tilek Chubakov, Xiaodan Zhu, Harish Tayyar Madabushi, Iryna Gurevych</em></li>
  <li><strong>Establishing Trustworthy LLM Evaluation via Shortcut Neuron Analysis</strong><br><em>Kejian Zhu, Shangqing Tu, Zhuoran Jin, Lei Hou, Juanzi Li, Jun Zhao</em></li>
  <li><strong>Do Large Language Models have an English Accent? Evaluating and Improving the Naturalness of Multilingual LLMs</strong><br><em>Yanzhu Guo, Simone Conia, Zelin Zhou, Min Li, Saloni Potdar, Henry Xiao</em></li>
  <li><strong>Enhancing Character-Level Understanding in LLMs through Token Internal Structure Learning</strong><br><em>Zhu Xu, Zhiqiang Zhao, Zihan Zhang, Yuchi Liu, Quanwei Shen, Fei Liu, Yu Kuang, Jian He, Conglin Liu</em></li>
  <li><strong>Conformity in Large Language Models</strong><br><em>Xiaochen Zhu, Caiqi Zhang, Tom Stafford, Nigel Collier, Andreas Vlachos</em></li>
  <li><strong>Interpret and Improve In-Context Learning via the Lens of Input-Label Mappings</strong><br><em>Chenghao Sun, Zhen Huang, Yonggang Zhang, Le Lu, Houqiang Li, Xinmei Tian, Xu Shen, Jieping Ye</em></li>
  <li><strong>Positional Overload: Positional Debiasing and Context Window Extension for Large Language Models using Set Encoding</strong><br><em>Lukas Kinder, Lukas Edman, Alexander Fraser, Tobias Käfer</em></li>
  <li><strong>FR-Spec: Accelerating Large-Vocabulary Language Models via Frequency-Ranked Speculative Sampling</strong><br><em>Weilin Zhao, Tengyu Pan, Xu Han, Yudi Zhang, Sun Ao, Yuxiang Huang, Kaihuo Zhang, Weilun Zhao, Yuxuan Li, Jie Zhou, Hao Zhou, Jianyong Wang, Maosong Sun, Zhiyuan Liu</em></li>
  <li><strong>VReST: Enhancing Reasoning in Large Vision-Language Models through Tree Search and Self-Reward Mechanism</strong><br><em>Congzhi Zhang, Jiawei Peng, Zhenglin Wang, Yilong Lai, Haowen Sun, Heng Chang, Fei Ma, Weijiang Yu</em></li>
  <li><strong>Past Meets Present: Creating Historical Analogy with Large Language Models</strong><br><em>Nianqi Li, Siyu Yuan, Jiangjie Chen, Jiaqing Liang, Feng Wei, Zujie Liang, Deqing Yang, Yanghua Xiao</em></li>
  <li><strong>Meta-Reflection: A Feedback-Free Reflection Learning Framework</strong><br><em>Yaoke Wang, Yun Zhu, XintongBao, Wenqiao Zhang, Suyang Dai, kehan chen, Wenqiang Li, Gang Huang, Siliang Tang, Yueting Zhuang</em></li>
  <li><strong>Cross-Lingual Transfer of Cultural Knowledge: An Asymmetric Phenomenon</strong><br><em>Chen Zhang, Zhiyuan Liao, Yansong Feng</em></li>
  <li><strong>Read it in Two Steps: Translating Extremely Low-Resource Languages with Code-Augmented Grammar Books</strong><br><em>Chen Zhang, Jiuheng Lin, Xiao Liu, Zekai Zhang, Yansong Feng</em></li>
  <li><strong>Confidence v.s. Critique: A Decomposition of Self-Correction Capability for LLMs</strong><br><em>Zhe Yang, Yichang Zhang, Yudong Wang, Ziyao Xu, Junyang Lin, Zhifang Sui</em></li>
  <li><strong>Automating Legal Concept Interpretation with LLMs: Retrieval, Generation, and Evaluation</strong><br><em>Kangcheng Luo, Quzhe Huang, Cong Jiang, Yansong Feng</em></li>
  <li><strong>Visual Evidence Prompting Mitigates Hallucinations in Large Vision-Language Models</strong><br><em>Wei Li, Zhen Huang, Houqiang Li, Le Lu, Yang Lu, Xinmei Tian, Xu Shen, Jieping Ye</em></li>
  <li><strong>Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration</strong><br><em>Shao Zhang, Xihuai Wang, Wenhao Zhang, Chaoran Li, Junru Song, Tingyu Li, Lin Qiu, Xuezhi Cao, Xunliang Cai, Wen Yao, Weinan Zhang, Xinbing Wang, Ying Wen</em></li>
  <li><strong>TokAlign: Efficient Vocabulary Adaptation via Token Alignment</strong><br><em>Chong Li, Jiajun Zhang, Chengqing Zong</em></li>
  <li><strong>AceEdit: Advancing Continuous Knowledge Editing For Large Language Models</strong><br><em>Qi Li, Xiaowen Chu</em></li>
  <li><strong>The Impact of Token Granularity on the Predictive Power of Language Model Surprisal</strong><br><em>Byung-Doh Oh, William Schuler</em></li>
  <li><strong>Segment-Level Diffusion: A Framework for Controllable Long-Form Generation with Diffusion Language Models</strong><br><em>Xiaochen Zhu, Georgi Karadzhov, Chenxi Whitehouse, Andreas Vlachos</em></li>
  <li><strong>BELLE: A Bi-Level Multi-Agent Reasoning Framework for Multi-Hop Question Answering</strong><br><em>Taolin Zhang, Dongyang Li, Qizhou Chen, Chengyu Wang, Xiaofeng He</em></li>
  <li><strong>Dynamic and Generalizable Process Reward Modeling</strong><br><em>Zhangyue Yin, Qiushi Sun, Zhiyuan Zeng, Qinyuan Cheng, Xipeng Qiu, Xuanjing Huang</em></li>
  <li><strong>AdamMeme: Adaptively Probe the Reasoning Capacity of Multimodal Large Language Models on Harmfulness</strong><br><em>Zixin Chen, Hongzhan Lin, Kaixin Li, Ziyang Luo, Zhen Ye, Guang Chen, Zhiyong Huang, Jing Ma</em></li>
  <li><strong>Towards Text-Image Interleaved Retrieval</strong><br><em>Xin Zhang, Ziqi Dai, Yongqi Li, Yanzhao Zhang, Dingkun Long, Pengjun Xie, Meishan Zhang, Jun Yu, Wenjie Li, Min Zhang</em></li>
  <li><strong>Large Margin Representation Learning for Robust Cross-lingual Named Entity Recognition</strong><br><em>Guangcheng Zhu, Ruixuan Xiao, Zhen Zhu, Gengyu Lyu, Junbo Zhao, Haobo Wang</em></li>
  <li><strong>An Efficient and Precise Training Data Construction Framework for Process-supervised Reward Model in Mathematical Reasoning</strong><br><em>Wei Sun, Qianlong Du, Fuwei Cui, Jiajun Zhang</em></li>
  <li><strong>QAEncoder: Towards Aligned Representation Learning in Question Answering Systems</strong><br><em>Zhengren Wang, Qinhan Yu, Shida Wei, Zhiyu li, Feiyu Xiong, Xiaoxing Wang, Simin Niu, Hao Liang, Wentao Zhang</em></li>
  <li><strong>Game Development as Human-LLM Interaction</strong><br><em>Jiale Hong, Hongqiu Wu, hai zhao</em></li>
  <li><strong>Can LLMs Simulate L2-English Dialogue? An Information-Theoretic Analysis of L1-Dependent Biases</strong><br><em>Rena Wei Gao, Xuetong Wu, Tatsuki Kuribayashi, Mingrui Ye, Siya Qi, Carsten Roever, Yuanxing Liu, Zheng Yuan, Jey Han Lau</em></li>
  <li><strong>DeepSolution: Boosting Complex Engineering Solution Design via Tree-based Exploration and Bi-point Thinking</strong><br><em>Zhuoqun Li, Haiyang Yu, Xuanang Chen, Hongyu Lin, Yaojie Lu, Fei Huang, Xianpei Han, Yongbin Li, Le Sun</em></li>
  <li><strong>Leveraging Human Production-Interpretation Asymmetries to Test LLM Cognitive Plausibility</strong><br><em>Suet-Ying Lam, Qingcheng Zeng, Jingyi Wu, Rob Voigt</em></li>
  <li><strong>SurveyPilot: an Agentic Framework for Automated Human Opinion Collection from Social Media</strong><br><em>Viet Thanh Pham, Lizhen Qu, Zhuang Li, Suraj Sharma, Gholamreza Haffari</em></li>
  <li><strong>Sharper and Faster mean Better: Towards More Efficient Vision-Language Model for Hour-scale Long Video Understanding</strong><br><em>Daoze Zhang, Yuze Zhao, Jintao Huang, Yingda Chen</em></li>
  <li><strong>Auto-Arena: Automating LLM Evaluations with Agent Peer Battles and Committee Discussions</strong><br><em>Ruochen Zhao, Wenxuan Zhang, Yew Ken Chia, Weiwen Xu, Deli Zhao, Lidong Bing</em></li>
  <li><strong>How Humans and LLMs Organize Conceptual Knowledge: Exploring Subordinate Categories in Italian</strong><br><em>Andrea Pedrotti, Giulia Rambelli, Caterina Villani, Marianna Bolognesi</em></li>
  <li><strong>PTQ1.61: Push the Real Limit of Extremely Low-Bit Post-Training Quantization Methods for Large Language Models</strong><br><em>Jiaqi Zhao, Miao Zhang, Ming Wang, Yuzhang Shang, Kaihao Zhang, Weili Guan, Yaowei Wang, Min Zhang</em></li>
  <li><strong>ProtoLens: Advancing Prototype Learning for Fine-Grained Interpretability in Text Classification</strong><br><em>Bowen Wei, Ziwei Zhu</em></li>
  <li><strong>Fine-grained Video Dubbing Duration Alignment with Segment Supervised Preference Optimization</strong><br><em>Chaoqun Cui, Liangbin Huang, Shijing Wang, Zhe Tong, Zhaolong Huang, Xiao Zeng, Xiaofeng Liu</em></li>
  <li><strong>Sparse Latents Steer Retrieval-Augmented Generation</strong><br><em>Chunlei Xin, Shuheng Zhou, Huijia Zhu, Weiqiang Wang, Xuanang Chen, Xinyan Guan, Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun</em></li>
  <li><strong>Improving the Calibration of Confidence Scores in Text Generation Using the Output Distribution’s Characteristics</strong><br><em>Lorenzo Jaime Yu Flores, Ori Ernst, Jackie CK Cheung</em></li>
  <li><strong>Unveiling Language-Specific Features in Large Language Models via Sparse Autoencoders</strong><br><em>Boyi Deng, Yu Wan, Baosong Yang, Yidan Zhang, Fuli Feng</em></li>
  <li><strong>SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of Large Language Model</strong><br><em>Xun Liang, Simin Niu, Zhiyu li, Sensen Zhang, Hanyu Wang, Feiyu Xiong, Zhaoxin Fan, Bo Tang, Jihao Zhao, Jiawei Yang, Shichao Song, Mengwei Wang</em></li>
  <li><strong>AnRe: Analogical Replay for Temporal Knowledge Graph Forecasting</strong><br><em>Guo Tang, Zheng Chu, Wenxiang Zheng, Junjia Xiang, Yizhuo Li, Weihao Zhang, Ming Liu, Bing Qin</em></li>
  <li><strong>Revisiting the Test-Time Scaling of o1-like Models: Do they Truly Possess Test-Time Scaling Capabilities?</strong><br><em>Zhiyuan Zeng, Qinyuan Cheng, Zhangyue Yin, Yunhua Zhou, Xipeng Qiu</em></li>
  <li><strong>Text is All You Need: LLM-enhanced Incremental Social Event Detection</strong><br><em>Zitai Qiu, Congbo Ma, Jia Wu, Jian Yang</em></li>
  <li><strong>Multimodal Pragmatic Jailbreak on Text-to-image Models</strong><br><em>Tong Liu, Zhixin Lai, Jiawen Wang, Gengyuan Zhang, Shuo Chen, Philip Torr, Vera Demberg, Volker Tresp, Jindong Gu</em></li>
  <li><strong>Principled Understanding of Generalization for Generative Transformer Models in Arithmetic Reasoning Tasks</strong><br><em>Xingcheng Xu, Zibo Zhao, Haipeng Zhang, Yanqing Yang</em></li>
  <li><strong>Discourse Relation-Enhanced Neural Coherence Modeling</strong><br><em>Wei Liu, Michael Strube</em></li>
  <li><strong>Benchmarking Open-ended Audio Dialogue Understanding for Large Audio-Language Models</strong><br><em>Kuofeng Gao, Shu-Tao Xia, Ke Xu, Philip Torr, Jindong Gu</em></li>
  <li><strong>from Benign import Toxic: Jailbreaking the Language Model via Adversarial Metaphors</strong><br><em>Yu Yan, Sheng Sun, Zenghao Duan, Teli Liu, Min Liu, Zhiyi yin, Qi Li, LeiJingyu</em></li>
  <li><strong>ShifCon: Enhancing Non-Dominant Language Capabilities with a Shift-based Contrastive Framework</strong><br><em>Hengyuan Zhang, Chenming Shang, Sizhe Wang, Dongdong Zhang, Feng Yao, Renliang Sun, Yiyao Yu, Yujiu Yang, Furu Wei</em></li>
  <li><strong>MorphMark: Flexible Adaptive Watermarking for Large Language Models</strong><br><em>Zongqi Wang, Tianle Gu, Baoyuan Wu, Yujiu Yang</em></li>
  <li><strong>A Silver Bullet or a Compromise for Full Attention? A Comprehensive Study of Gist Token-based Context Compression</strong><br><em>Chenlong Deng, Zhisong Zhang, Kelong Mao, Shuaiyi Li, Xinting Huang, Dong Yu, Zhicheng Dou</em></li>
  <li><strong>On the Limit of Language Models as Planning Formalizers</strong><br><em>Cassie Huang, Li Zhang</em></li>
  <li><strong>Learning to Generate Structured Output with Schema Reinforcement Learning</strong><br><em>Yaxi Lu, Haolun Li, Xin Cong, Zhong Zhang, Yesai Wu, Yankai Lin, Zhiyuan Liu, Fangming Liu, Maosong Sun</em></li>
  <li><strong>On the Robustness of RAG Systems in Educational Question Answering under Knowledge Discrepancies</strong><br><em>Tianshi Zheng, Weihan Li, Jiaxin Bai, Weiqi Wang, Yangqiu Song</em></li>
  <li><strong>Enhancing Unsupervised Sentence Embeddings via Knowledge-Driven Data Augmentation and Gaussian-Decayed Contrastive Learning</strong><br><em>Peichao Lai, Zhengfeng Zhang, Wentao Zhang, Fangcheng Fu, Bin CUI</em></li>
  <li><strong>Improve Safety Training of Large Language Models with Safety-Critical Singular Vectors Localization</strong><br><em>Peijian Gu, Quan Wang, Zhendong Mao</em></li>
  <li><strong>WarriorCoder: Learning from Expert Battles to Augment Code Large Language Models</strong><br><em>Huawen Feng, Pu Zhao, Qingfeng Sun, Can Xu, Fangkai Yang, Lu Wang, Qianli Ma, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang</em></li>
  <li><strong>A Triple-View Framework for Fine-Grained Emotion Classification with Clustering-Guided Contrastive Learning</strong><br><em>Junqing Gong, Binhan Yang, Wei Shen</em></li>
  <li><strong>Quantification of Large Language Model Distillation</strong><br><em>Sunbowen Lee, Junting Zhou, Chang Ao, Kaige Li, Xeron Du, Sirui He, Haihong Wu, Tianci Liu, Jiaheng Liu, Hamid Alinejad-Rokny, Min Yang, Yitao Liang, Zhoufutu Wen, Shiwen Ni</em></li>
  <li><strong>Demons in the Detail: On Implementing Load Balancing Loss for Training Specialized Mixture-of-Expert Models</strong><br><em>Zihan Qiu, Zeyu Huang, Bo Zheng, Kaiyue Wen, Zekun Wang, Rui Men, Ivan Titov, Dayiheng Liu, Jingren Zhou, Junyang Lin</em></li>
  <li><strong>Pandora’s Box or Aladdin’s Lamp: A Comprehensive Analysis Revealing the Role of RAG Noise in Large Language Models</strong><br><em>Jinyang Wu, Shuai Zhang, Feihu Che, Mingkuan Feng, Pengpeng Shao, Jianhua Tao</em></li>
  <li><strong>Stepwise Reasoning Disruption Attack of LLMs</strong><br><em>Jingyu Peng, Maolin Wang, Xiangyu Zhao, Kai Zhang, Wanyu Wang, Pengyue Jia, Qidong Liu, Ruocheng Guo, Qi Liu</em></li>
  <li><strong>Crowd Comparative Reasoning: Unlocking Comprehensive Evaluations for LLM-as-a-Judge</strong><br><em>Qiyuan Zhang, Yufei Wang, Yuxin Jiang, Liangyou Li, Chuhan Wu, Yasheng Wang, Xin Jiang, Lifeng Shang, Ruiming Tang, Fuyuan Lyu, Chen Ma</em></li>
  <li><strong>Lost in Multilinguality: Dissecting Cross-lingual Factual Inconsistency in Transformer Language Models</strong><br><em>Mingyang Wang, Heike Adel, Lukas Lange, Yihong Liu, Ercong Nie, Jannik Strötgen, Hinrich Schuetze</em></li>
  <li><strong>Optimizing Decomposition for Optimal Claim Verification</strong><br><em>Yining Lu, Noah Ziems, Hy Dang, Meng Jiang</em></li>
  <li><strong>GradOT: Training-free Gradient-persevering Offsite-tuning for Large Language Models</strong><br><em>Kai Yao, Zhaorui Tan, Penglei Gao, Lichun Li, Kaixin Wu, Yinggui Wang, Yuan Zhao, Yixin Ji, Jianke Zhu, Wei Wang</em></li>
  <li><strong>Knowledge Boundary of Large Language Models: A Survey</strong><br><em>Moxin Li, Yong Zhao, Wenxuan Zhang, Shuaiyi Li, Wenya Xie, See-Kiong Ng, Tat-Seng Chua, Yang Deng</em></li>
  <li><strong>Mitigating Visual Forgetting via Take-along Visual Conditioning for Multi-modal Long CoT Reasoning</strong><br><em>Hai-Long Sun, Zhun Sun, Houwen Peng, Han-Jia Ye</em></li>
  <li><strong>MoC: Mixtures of Text Chunking Learners for Retrieval-Augmented Generation System</strong><br><em>Jihao Zhao, Zhiyuan Ji, Zhaoxin Fan, Hanyu Wang, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu li</em></li>
  <li><strong>Mitigating Selection Bias with Node Pruning and Auxiliary Options</strong><br><em>Hyeong Kyu Choi, Weijie Xu, Chi Xue, Stephanie Eckman, Chandan K. Reddy</em></li>
  <li><strong>Dually Self-Improved Counterfactual Data Augmentation Using Large Language Model</strong><br><em>Luhao Zhang, Xinyu Zhang, Linmei Hu, Dandan Song, Liqiang Nie</em></li>
  <li><strong>RPO: Retrieval Preference Optimization for Robust Retrieval-Augmented Generation</strong><br><em>Shi-Qi Yan, Quan Liu, Zhen-Hua Ling</em></li>
  <li><strong>Improving Parallel Sentence Mining for Low-Resource and Endangered Languages</strong><br><em>Shu Okabe, Katharina Hämmerl, Alexander Fraser</em></li>
  <li><strong>Learning to Reason from Feedback at Test-Time</strong><br><em>Yanyang Li, Michael Lyu, Liwei Wang</em></li>
  <li><strong>$\textit{L-CiteEval}$: A Suite for Evaluating Fidelity of Long-context Models</strong><br><em>Zecheng Tang, Keyan Zhou, Juntao Li, Baibei Ji, jianye hou, Min Zhang</em></li>
  <li><strong>$SECRET$: Semi-supervised Clinical Trial Document Similarity Search</strong><br><em>Trisha Das, Afrah Shafquat, Mandis Beigi, Jacob Aptekar, Jimeng Sun</em></li>
  <li><strong>Revisiting Epistemic Markers in Confidence Estimation: Can Markers Accurately Reflect Large Language Models’ Uncertainty?</strong><br><em>Jiayu Liu, Qing Zong, Weiqi Wang, Yangqiu Song</em></li>
  <li><strong>Geometric Signatures of Compositionality Across a Language Model’s Lifetime</strong><br><em>Jin Hwa Lee, Thomas Jiralerspong, Lei Yu, Yoshua Bengio, Emily Cheng</em></li>
  <li><strong>Pattern Recognition or Medical Knowledge? The Problem with Multiple-Choice Questions in Medicine</strong><br><em>Maxime Griot, Jean Vanderdonckt, Demet YUKSEL, Coralie Hemptinne</em></li>
  <li><strong>People who frequently use ChatGPT for writing tasks are accurate and robust detectors of AI-generated text</strong><br><em>Jenna Russell, Marzena Karpinska, Mohit Iyyer</em></li>
  <li><strong>YuLan-Mini: Pushing the Limits of Open Data-efficient Language Model</strong><br><em>Hu Yiwen, Song Huatong, Jie Chen, Jia Deng, jiapeng wang, Kun Zhou, Yutao Zhu, Jinhao Jiang, zican Dong, YANG LU, Xu Miao, Xin Zhao, Ji-Rong Wen</em></li>
  <li><strong>Your Model is Overconfident, and Other Lies We Tell Ourselves</strong><br><em>Timothee Mickus, Aman Sinha, Raúl Vázquez</em></li>
  <li><strong>Bridging the Language Gaps in Large Language Models with Inference-Time Cross-Lingual Intervention</strong><br><em>Weixuan Wang, Minghao Wu, Barry Haddow, Alexandra Birch</em></li>
  <li><strong>Plug-in and Fine-tuning: Bridging the Gap between Small Language Models and Large Language Models</strong><br><em>Kyeonghyun Kim, Jinhee Jang, Juhwan Choi, Yoonji Lee, Kyohoon Jin, YoungBin Kim</em></li>
  <li><strong>What is Stigma Attributed to? A Theory-Grounded, Expert-Annotated Interview Corpus for Demystifying Mental-Health Stigma</strong><br><em>Han Meng, Yancan Chen, Yunan Li, YITIAN YANG, Jungup Lee, Renwen Zhang, Yi-Chieh Lee</em></li>
  <li><strong>ATRI: Mitigating Multilingual Audio Text Retrieval Inconsistencies by Reducing Data Distribution Errors</strong><br><em>Yuguo Yin, Yuxin Xie, Wenyuan Yang, Dongchao Yang, Jinghan Ru, Xianwei Zhuang, Liming Liang, Yuexian Zou</em></li>
  <li><strong>Enhancing Transformers for Generalizable First-Order Logical Entailment</strong><br><em>Tianshi Zheng, Jiazheng Wang, Zihao Wang, Jiaxin Bai, Hang Yin, Zheye Deng, Yangqiu Song, Jianxin Li</em></li>
  <li><strong>Self-Taught Agentic Long Context Understanding</strong><br><em>Yufan Zhuang, Xiaodong Yu, Jialian Wu, Ximeng Sun, Ze Wang, Jiang Liu, Yusheng Su, Jingbo Shang, Zicheng Liu, Emad Barsoum</em></li>
  <li><strong>Hallucination Detox: Sensitivity Dropout (SenD) for Large Language Model Training</strong><br><em>Shahrad Mohammadzadeh, Juan David Guerra, Marco Bonizzato, Reihaneh Rabbany, Golnoosh Farnadi</em></li>
  <li><strong>OS-Genesis: Automating GUI Agent Trajectory Construction via Reverse Task Synthesis</strong><br><em>Qiushi Sun, Kanzhi Cheng, Zichen Ding, Chuanyang Jin, Yian Wang, Fangzhi Xu, Zhenyu Wu, Chengyou Jia, Liheng Chen, Zhoumianze Liu, Ben Kao, Guohao Li, Junxian He, Yu Qiao, Zhiyong Wu</em></li>
  <li><strong>CORAL: Learning Consistent Representations across Multi-step Training with Lighter Speculative Drafter</strong><br><em>Yepeng Weng, Dianwen Mei, Huishi Qiu, Xujie Chen, Li Liu, Jiang Tian, Zhongchao Shi</em></li>
  <li><strong>ConSim: Measuring Concept-Based Explanations’ Effectiveness with Automated Simulatability</strong><br><em>Antonin Poché, Alon Jacovi, Agustin Martin Picard, Victor Boutin, Fanny Jourdan</em></li>
  <li><strong>Decoding Reading Goals from Eye Movements</strong><br><em>Omer Shubi, Cfir Avraham Hadar, Yevgeni Berzak</em></li>
  <li><strong>Uncovering Visual-Semantic Psycholinguistic Properties from the Distributional Structure of Text Embedding Space</strong><br><em>Si Wu, Sebastian Bruch</em></li>
  <li><strong>GUI-explorer: Autonomous Exploration and Mining of Transition-aware Knowledge for GUI Agent</strong><br><em>Bin Xie, Rui Shao, Gongwei Chen, Kaiwen Zhou, Yinchuan Li, Jie Liu, Min Zhang, Liqiang Nie</em></li>
  <li><strong>P$^2$ Law: Scaling Law for Post-Training After Model Pruning</strong><br><em>Xiaodong Chen, Yuxuan Hu, Xiaokang Zhang, Yanling Wang, Cuiping Li, Hong Chen, Jing Zhang</em></li>
  <li><strong>Making FETCH! Happen: Finding Emergent Dog Whistles Through Common Habitats</strong><br><em>Kuleen Sasse, Carlos Alejandro Aguirre, Isabel Cachola, Sharon Levy, Mark Dredze</em></li>
  <li><strong>Lost in the Context: Insufficient and Distracted Attention to Contexts in Preference Modeling</strong><br><em>Shihan Dou, Jiayi Chen, Chenhao Huang, Feng Chen, Wei Chengzhi, Huiyuan Zheng, Shichun Liu, Yan Liu, Chenxiao Liu, Chao Xin, Lin Yan, Zongzhang Zhang, Tao Gui, Qi Zhang, Xuanjing Huang</em></li>
  <li><strong>Entailment-Preserving First-order Logic Representations in Natural Language Entailment</strong><br><em>Jinu Lee, Qi Liu, Runzhi Ma, Vincent Han, Ziqi Wang, Heng Ji, Julia Hockenmaier</em></li>
  <li><strong>Enhancing Multimodal Continual Instruction Tuning with BranchLoRA</strong><br><em>Duzhen Zhang, Yong Ren, Zhong-Zhi Li, Yahan Yu, Jiahua Dong, Chenxing Li, Zhilong Ji, Jinfeng Bai</em></li>
  <li><strong>Enhancing Automated Interpretability with Output-Centric Feature Descriptions</strong><br><em>Yoav Gur-Arieh, Roy Mayan, Chen Agassy, Atticus Geiger, Mor Geva</em></li>
  <li><strong>Towards Effective and Efficient Continual Pre-training of Large Language Models</strong><br><em>Jie Chen, Zhipeng Chen, jiapeng wang, Kun Zhou, Yutao Zhu, Jinhao Jiang, Yingqian Min, Xin Zhao, Zhicheng Dou, Jiaxin Mao, Yankai Lin, Ruihua Song, Jun Xu, Xu Chen, Rui Yan, Zhewei Wei, Di Hu, Wenbing Huang, Ji-Rong Wen</em></li>
  <li><strong>Efficient Universal Goal Hijacking with Semantics-guided Prompt Organization</strong><br><em>Yihao Huang, Chong Wang, Xiaojun Jia, Qing Guo, Felix Juefei-Xu, Jian Zhang, Yang Liu, Geguang Pu</em></li>
  <li><strong>mPLUG-DocOwl2: High-resolution Compressing for OCR-free Multi-page Document Understanding</strong><br><em>Anwen Hu, Haiyang Xu, Liang Zhang, Jiabo Ye, Ming Yan, Ji Zhang, Qin Jin, Fei Huang, Jingren Zhou</em></li>
  <li><strong>What Makes a Good Natural Language Prompt?</strong><br><em>Do Xuan Long, Duy Dinh, Ngoc-Hai Nguyen, Kenji Kawaguchi, Nancy F. Chen, Shafiq Joty, Min-Yen Kan</em></li>
  <li><strong>Limited-Resource Adapters Are Regularizers, Not Linguists</strong><br><em>Marcell Fekete, Nathaniel Romney Robinson, Ernests Lavrinovics, Djeride Jean-Baptise, Raj Dabre, Johannes Bjerva, Heather Lent</em></li>
  <li><strong>X-TURING: Towards an Enhanced and Efficient Turing Test for Long-Term Dialogue Agents</strong><br><em>Weiqi Wu, Hongqiu Wu, hai zhao</em></li>
  <li><strong>Are Rules Meant to be Broken? Understanding Multilingual Moral Reasoning as a Computational Pipeline with UniMoral</strong><br><em>Shivani Kumar, David Jurgens</em></li>
  <li><strong>Modality-Aware Neuron Pruning for Unlearning in Multimodal Large Language Models</strong><br><em>Zheyuan Liu, Guangyao Dou, Xiangchi Yuan, Chunhui Zhang, Zhaoxuan Tan, Meng Jiang</em></li>
  <li><strong>NGQA: A Nutritional Graph Question Answering Benchmark for Personalized Health-aware Nutritional Reasoning</strong><br><em>Zheyuan Zhang, Yiyang Li, Nhi Ha Lan Le, Zehong Wang, Tianyi Ma, Vincent Galassi, Keerthiram Murugesan, Nuno Moniz, Werner Geyer, Nitesh V Chawla, Chuxu Zhang, Yanfang Ye</em></li>
  <li><strong>ReLearn: Unlearning via Learning for Large Language Models</strong><br><em>Haoming Xu, Ningyuan Zhao, Liming Yang, Sendong Zhao, Shumin Deng, Mengru Wang, Bryan Hooi, Nay Oo, Huajun Chen, Ningyu Zhang</em></li>
  <li><strong>Understanding Cross-Domain Adaptation in Low-Resource Topic Modeling</strong><br><em>Pritom Saha Akash, Kevin Chen-Chuan Chang</em></li>
  <li><strong>UAlign: Leveraging Uncertainty Estimations for Factuality Alignment on Large Language Models</strong><br><em>Boyang XUE, Fei Mi, Qi Zhu, Hongru WANG, Rui Wang, Sheng Wang, Erxin Yu, Xuming Hu, Kam-Fai Wong</em></li>
  <li><strong>CoT-Valve: Length-Compressible Chain-of-Thought Tuning</strong><br><em>Xinyin Ma, Guangnian Wan, Runpeng Yu, Gongfan Fang, Xinchao Wang</em></li>
  <li><strong>HoH: A Dynamic Benchmark for Evaluating the Impact of Outdated Information on Retrieval-Augmented Generation</strong><br><em>Jie Ouyang, Tingyue Pan, Mingyue Cheng, Ruiran Yan, Yucong Luo, Jiaying Lin, Qi Liu</em></li>
  <li><strong>Uncertainty Propagation on LLM Agent</strong><br><em>Qiwei Zhao, Dong Li, Yanchi Liu, Wei Cheng, Yiyou Sun, Mika Oishi, Takao Osaki, Katsushi Matsuda, Huaxiu Yao, Chen Zhao, Haifeng Chen, Xujiang Zhao</em></li>
  <li><strong>Beyond Position: the emergence of wavelet-like properties in Transformers</strong><br><em>Valeria Ruscio, Umberto Nanni, Fabrizio Silvestri</em></li>
  <li><strong>Are the Hidden States Hiding Something? Testing the Limits of Factuality-Encoding Capabilities in LLMs</strong><br><em>Giovanni Servedio, Alessandro De Bellis, Dario Di Palma, Vito Walter Anelli, Tommaso Di Noia</em></li>
  <li><strong>Disentangling Biased Knowledge from Reasoning in Large Language Models via Machine Unlearning</strong><br><em>Zheyuan Liu, Suraj Maharjan, Fanyou Wu, Rahil Parikh, Belhassen Bayar, Srinivasan H. Sengamedu, Meng Jiang</em></li>
  <li><strong>LLaMAs Have Feelings Too: Unveiling Sentiment and Emotion Representations in LLaMA Models Through Probing</strong><br><em>Dario Di Palma, Alessandro De Bellis, Giovanni Servedio, Vito Walter Anelli, Fedelucio Narducci, Tommaso Di Noia</em></li>
  <li><strong>CxGGEC: Construction-Guided Grammatical Error Correction</strong><br><em>Yayu Cao, Tianxiang Wang, Lvxiaowei Xu, Zhenyao Wang, Ming Cai</em></li>
  <li><strong>Beyond Sequences: Two-dimensional Representation and Dependency Encoding for Code Generation</strong><br><em>Xiangyu Zhang, Yu Zhou, Guang Yang, Wei Cheng, Taolue Chen</em></li>
  <li><strong>HD-NDEs: Neural Differential Equations for Hallucination Detection in LLMs</strong><br><em>Qing Li, Jiahui Geng, Zongxiong Chen, Derui Zhu, Yuxia Wang, Congbo Ma, Chenyang Lyu, Fakhri Karray</em></li>
  <li><strong>What Is That Talk About? A Video-to-Text Summarization Dataset for Scientific Presentations</strong><br><em>Dongqi Liu, Chenxi Whitehouse, Xi Yu, Louis Mahon, Rohit Saxena, Zheng Zhao, Yifu QIU, Mirella Lapata, Vera Demberg</em></li>
  <li><strong>NeuSym-RAG: Hybrid Neural Symbolic Retrieval with Multiview Structuring for PDF Question Answering</strong><br><em>Ruisheng Cao, Hanchong Zhang, Tiancheng Huang, Zhangyi Kang, Yuxin Zhang, Liangtai Sun, Hanqi Li, Yuxun Miao, Shuai Fan, Lu Chen, Kai Yu</em></li>
  <li><strong>ProvBench: A Benchmark of Legal Provision Recommendation for Contract Auto-Reviewing</strong><br><em>Xiuxuan Shen, Zhongyuan Jiang, Junsan Zhang, Junxiao Han, Yao Wan, Chengjie Guo, Bingcheng Liu, Jie Wu, Renxiang Li, Philip S. Yu</em></li>
  <li><strong>F5-TTS: A Fairytaler that Fakes Fluent and Faithful Speech with Flow Matching</strong><br><em>Yushen CHEN, Zhikang Niu, Ziyang Ma, Keqi Deng, Chunhui Wang, JianZhao, Kai Yu, Xie Chen</em></li>
  <li><strong>LLMs instead of Human Judges? A Large Scale Empirical Study across 20 NLP Evaluation Tasks</strong><br><em>Anna Bavaresco, Raffaella Bernardi, Leonardo Bertolazzi, Desmond Elliott, Raquel Fernández, Albert Gatt, Esam Ghaleb, Mario Giulianelli, Michael Hanna, Alexander Koller, Andre Martins, Philipp Mondorf, Vera Neplenbroek, Sandro Pezzelle, Barbara Plank, David Schlangen, Alessandro Suglia, Aditya K Surikuchi, Ece Takmaz, Alberto Testoni</em></li>
  <li><strong>AutoMedEval: Harnessing Language Models for Automatic Medical Capability Evaluation</strong><br><em>Xiechi Zhang, Zetian Ouyang, Linlin Wang, Gerard de Melo, Zhu Cao, Xiaoling Wang, Ya Zhang, Yanfeng Wang, Liang He</em></li>
  <li><strong>CoT-based Synthesizer: Enhancing LLM Performance through Answer Synthesis</strong><br><em>Bohan Zhang, Xiaokang Zhang, Jing Zhang, Jifan Yu, Sijia Luo, Jie Tang</em></li>
  <li><strong>Efficiently Identifying Watermarked Segments in Mixed-Source Texts</strong><br><em>Xuandong Zhao, Chenwen Liao, Yu-Xiang Wang, Lei Li</em></li>
  <li><strong>FocalPO: Enhancing Preference Optimizing by Focusing on Correct Preference Rankings</strong><br><em>Tong Liu, Xiao Yu, Wenxuan Zhou, Jindong Gu, Volker Tresp</em></li>
  <li><strong>Assessing Dialect Fairness and Robustness of Large Language Models in Reasoning Tasks</strong><br><em>Fangru Lin, Shaoguang Mao, Emanuele La Malfa, Valentin Hofmann, Adrian de Wynter, Xun Wang, Si-Qing Chen, Michael J. Wooldridge, Janet B. Pierrehumbert, Furu Wei</em></li>
  <li><strong>Towards a More Generalized Approach in Open Relation Extraction</strong><br><em>Qing Wang, Yuepei Li, Qiao Qiao, Kang Zhou, Qi Li</em></li>
  <li><strong>Adaptive Retrieval Without Self-Knowledge? Bringing Uncertainty Back Home</strong><br><em>Viktor Moskvoretskii, Maria Marina, Mikhail Salnikov, Nikolay Ivanov, Sergey Pletenev, Daria Galimzianova, Nikita Krayko, Vasily Konovalov, Irina Nikishina, Alexander Panchenko</em></li>
  <li><strong>Evaluating Language Models as Synthetic Data Generators</strong><br><em>Seungone Kim, Juyoung Suk, Xiang Yue, Vijay Viswanathan, Seongyun Lee, Yizhong Wang, Kiril Gashteovski, Carolin Lawrence, Sean Welleck, Graham Neubig</em></li>
  <li><strong>Can Graph Descriptive Order Affect Solving Graph Problems with LLMs?</strong><br><em>Yuyao Ge, Shenghua Liu, Baolong Bi, Yiwei Wang, Lingrui Mei, Wenjie Feng, Lizhe Chen, Xueqi Cheng</em></li>
  <li><strong>Learning to Rewrite: Generalized LLM-Generated Text Detection</strong><br><em>Wei Hao, Ran Li, Weiliang Zhao, Junfeng Yang, Chengzhi Mao</em></li>
  <li><strong>Evaluating Multimodal Large Language Models on Video Captioning via Monte Carlo Tree Search</strong><br><em>Linhao Yu, Xingguang Ji, Yahui Liu, Fanheng Kong, Chenxi Sun, Jingyuan Zhang, Hongzhi Zhang, V. W., Fuzheng Zhang, Deyi Xiong</em></li>
  <li><strong>GIFT-SW: Gaussian noise Injected Fine-Tuning of Salient Weights for LLMs</strong><br><em>Maxim Zhelnin, Viktor Moskvoretskii, Egor Shvetsov, Maria Krylova, Venediktov Egor, Zuev Aleksandr, Evgeny Burnaev</em></li>
  <li><strong>Quaff: Quantized Parameter-Efficient Fine-Tuning under Outlier Spatial Stability Hypothesis</strong><br><em>Hong Huang, Dapeng Wu</em></li>
  <li><strong>Unsolvable Problem Detection: Robust Understanding Evaluation for Large Multimodal Models</strong><br><em>Atsuyuki Miyai, Jingkang Yang, Jingyang Zhang, Yifei Ming, Qing Yu, Go Irie, Yixuan Li, Hai Helen Li, Ziwei Liu, Kiyoharu Aizawa</em></li>
  <li><strong>AlignMMBench: Evaluating Chinese Multimodal Alignment in Large Vision-Language Models</strong><br><em>Yuhang Wu, Wenmeng Yu, Yean Cheng, Yan Wang, Xiaohan Zhang, Jiazheng Xu, Ming Ding, Yuxiao Dong</em></li>
  <li><strong>Biased LLMs can Influence Political Decision-Making</strong><br><em>Jillian Fisher, Shangbin Feng, Robert Aron, Thomas Richardson, Yejin Choi, Daniel W Fisher, Jennifer Pan, Yulia Tsvetkov, Katharina Reinecke</em></li>
  <li><strong>LexTempus: Enhancing Temporal Generalizability of Legal Language Models Through Dynamic Mixture of Experts</strong><br><em>Santosh T.Y.S.S, Tuan-Quang Vuong</em></li>
  <li><strong>That is Unacceptable: the Moral Foundations of Canceling</strong><br><em>Soda Marem Lo, Oscar Araque, Rajesh Sharma, Marco Antonio Stranisci</em></li>
  <li><strong>FloorPlan-LLaMa: Aligning Architects’ Feedback and Domain Knowledge in Architectural Floor Plan Generation</strong><br><em>Jun Yin, Pengyu Zeng, Haoyuan Sun, Yuqin Dai, Han Zheng, Miao Zhang, Yachao Zhang, Shuai Lu</em></li>
  <li><strong>TheoremExplainAgent: Towards Video-based Multimodal Explanations for LLM Theorem Understanding</strong><br><em>Max Ku, Thomas Chong, Jonathan Leung, Krish Shah, Alvin Yu, Wenhu Chen</em></li>
  <li><strong>FineReason: Evaluating and Improving LLMs’ Deliberate Reasoning through Reflective Puzzle Solving</strong><br><em>Guizhen Chen, Weiwen Xu, Hao Zhang, Hou Pong Chan, Chaoqun Liu, Lidong Bing, Deli Zhao, Anh Tuan Luu, Yu Rong</em></li>
  <li><strong>The TIP of the Iceberg: Revealing a Hidden Class of Task-in-Prompt Adversarial Attacks on LLMs</strong><br><em>Sergey Berezin, Reza Farahbakhsh, Noel Crespi</em></li>
  <li><strong>Identifying Reliable Evaluation Metrics for Scientific Text Revision</strong><br><em>Leane Jourdan, Nicolas Hernandez, Florian Boudin, Richard Dufour</em></li>
  <li><strong>Can Language Models Reason about Individualistic Human Values and Preferences?</strong><br><em>Liwei Jiang, Taylor Sorensen, Sydney Levine, Yejin Choi</em></li>
  <li><strong>BERT-like Models for Slavic Morpheme Segmentation</strong><br><em>Dmitry Morozov, Lizaveta Astapenka, Anna Glazkova, Timur Garipov, Olga Lyashevskaya</em></li>
  <li><strong>Turning Trash into Treasure: Accelerating Inference of Large Language Models with Token Recycling</strong><br><em>Xianzhen Luo, Yixuan Wang, Qingfu Zhu, Zhiming Zhang, Xuanyu Zhang, Qing Yang, Dongliang Xu</em></li>
  <li><strong>Unlocking General Long Chain-of-Thought Reasoning Capabilities of Large Language Models via Representation Engineering</strong><br><em>Xinyu Tang, Xiaolei Wang, Zhihao Lv, Yingqian Min, Xin Zhao, Binbin Hu, Ziqi Liu, Zhiqiang Zhang</em></li>
  <li><strong>Drift: Enhancing LLM Faithfulness in Rationale Generation via Dual-Reward Probabilistic Inference</strong><br><em>Jiazheng Li, Hanqi Yan, Yulan He</em></li>
  <li><strong>Fairness through Difference Awareness: Measuring $\textit{Desired}$ Group Discrimination in LLMs</strong><br><em>Angelina Wang, Michelle Phan, Daniel E. Ho, Sanmi Koyejo</em></li>
  <li><strong>MergePrint: Merge-Resistant Fingerprints for Robust Black-box Ownership Verification of Large Language Models</strong><br><em>Shojiro Yamabe, Futa Kai Waseda, Tsubasa Takahashi, Koki Wataoka</em></li>
  <li><strong>Dynamic Scaling of Unit Tests for Code Reward Modeling</strong><br><em>Zeyao Ma, Xiaokang Zhang, Jing Zhang, Jifan Yu, Sijia Luo, Jie Tang</em></li>
  <li><strong>UniConv: Unifying Retrieval and Response Generation for Large Language Model in Conversation</strong><br><em>Fengran Mo, Yifan Gao, Chuan Meng, Xin Liu, Zhuofeng Wu, Kelong Mao, Zhengyang Wang, Pei Chen, Zheng Li, Xian Li, Bing Yin, Meng Jiang</em></li>
  <li><strong>Tracking Life’s Ups and Downs: Mining Life Events from Social Media Posts for Mental Health Analysis</strong><br><em>Minghao Lv, Siyuan Chen, Haoan Jin, Minghao Yuan, Qianqian Ju, Yujia Peng, Kenny Q. Zhu, Mengyue Wu</em></li>
  <li><strong>Towards Simultaneous and Independent Zero-shot Speaker Cloning and Zero-shot Language Style Control</strong><br><em>Shengpeng Ji, Qian Chen, Wen Wang, Jialong Zuo, Minghui Fang, Ziyue Jiang, Hai Huang, Zehan Wang, Xize Cheng, Siqi Zheng, Zhou Zhao</em></li>
  <li><strong>PIC: Unlocking Long-Form Text Generation Capabilities of Large Language Models via Position ID Compression</strong><br><em>Haoran Que, Wenge Rong</em></li>
  <li><strong>Towards Effective Extraction and Evaluation of Factual Claims</strong><br><em>Dasha Metropolitansky, Jonathan Larson</em></li>
  <li><strong>Beyond Facts: Evaluating Intent Hallucination in Large Language Models</strong><br><em>Yijie Hao, Haofei Yu, Jiaxuan You</em></li>
  <li><strong>A Systematic Study of Compositional Syntactic Transformer Language Models</strong><br><em>Yida Zhao, Hao Xve, Xiang Hu, Kewei Tu</em></li>
  <li><strong>M-MAD: Multidimensional Multi-Agent Debate for Advanced Machine Translation Evaluation</strong><br><em>Zhaopeng Feng, Jiayuan Su, Jiamei Zheng, Jiahan Ren, Yan Zhang, Jian Wu, Hongwei Wang, Zuozhu Liu</em></li>
  <li><strong>SongComposer: A Large Language Model for Lyric and Melody Generation in Song Composition</strong><br><em>Shuangrui Ding, Zihan Liu, Xiaoyi Dong, Pan Zhang, Rui Qian, Junhao Huang, Conghui He, Dahua Lin, Jiaqi Wang</em></li>
  <li><strong>Personalized Text Generation with Contrastive Activation Steering</strong><br><em>Jinghao Zhang, Yuting Liu, Wenjie Wang, Qiang Liu, Shu Wu, Liang Wang, Tat-Seng Chua</em></li>
  <li><strong>Gumbel Reranking: Differentiable End-to-End Reranker Optimization</strong><br><em>Siyuan Huang, Zhiyuan Ma, Jintao Du, Changhua Meng, Weiqiang Wang, Jingwen Leng, Minyi Guo, Zhouhan Lin</em></li>
  <li><strong>Hybrid Preferences: Learning to Route Instances for Human vs. AI Feedback</strong><br><em>Lester James Validad Miranda, Yizhong Wang, Yanai Elazar, Sachin Kumar, Valentina Pyatkin, Faeze Brahman, Noah A. Smith, Hannaneh Hajishirzi, Pradeep Dasigi</em></li>
  <li><strong>SEOE: A Scalable and Reliable Semantic Evaluation Framework for Open Domain Event Detection</strong><br><em>Yi-Fan Lu, Xian-Ling Mao, Tian Lan, Tong Zhang, Yu-Shi Zhu, Heyan Huang</em></li>
  <li><strong>The UD-NewsCrawl Treebank: Reflections and Challenges from a Large-scale Tagalog Syntactic Annotation Project</strong><br><em>Angelina Aspra Aquino, Lester James Validad Miranda, Elsie Marie T. Or</em></li>
  <li><strong>DRAG: Distilling RAG for SLMs from LLMs to Transfer Knowledge and Mitigate Hallucination via Evidence and Graph-based Distillation</strong><br><em>Jennifer Chen, Aidar Myrzakhan, Yaxin Luo, Hassaan Muhammad Khan, Sondos Mahmoud Bsharat, Zhiqiang Shen</em></li>
  <li><strong>G-Safeguard: A Topology-Guided Security Lens and Treatment on LLM-based Multi-agent Systems</strong><br><em>Shilong Wang, Guibin Zhang, Miao Yu, Guancheng Wan, Fanci Meng, chongye guo, Kun Wang, Yang Wang</em></li>
  <li><strong>Deontological Keyword Bias: The Impact of Modal Verbs on Normative Judgments of Language Models</strong><br><em>Bumjin Park, Leejinsil, Jaesik Choi</em></li>
  <li><strong>LegalReasoner: Step-wised Verification-Correction for Legal Judgment Reasoning</strong><br><em>Weijie Shi, Han Zhu, Jiaming Ji, Mengze Li, Jipeng Zhang, Ruiyuan Zhang, Jia Zhu, Jiajie Xu, Sirui Han, Yike Guo</em></li>
  <li><strong>Rolling the DICE on Idiomaticity: How LLMs Fail to Grasp Context</strong><br><em>Maggie Mi, Aline Villavicencio, Nafise Sadat Moosavi</em></li>
  <li><strong>ChartCoder: Advancing Multimodal Large Language Model for Chart-to-Code Generation</strong><br><em>Xuanle Zhao, Xianzhen Luo, Qi Shi, Chi Chen, Shuo Wang, Zhiyuan Liu, Maosong Sun</em></li>
  <li><strong>The Cross-linguistic Role of Animacy in Grammar Structures</strong><br><em>Nina Gregorio, Matteo Gay, Sharon Goldwater, Edoardo Ponti</em></li>
  <li><strong>LexGen: Domain-aware Multilingual Lexicon Generation</strong><br><em>Ayush Maheshwari, Atul Kumar Singh, N J Karthika, Krishnakant Bhatt, Preethi Jyothi, Ganesh Ramakrishnan</em></li>
  <li><strong>How to Train Long-Context Language Models (Effectively)</strong><br><em>Tianyu Gao, Alexander Wettig, Howard Yen, Danqi Chen</em></li>
  <li><strong>MathFusion: Enhancing Mathematical Problem-solving of LLM through Instruction Fusion</strong><br><em>Qizhi Pei, Lijun Wu, Zhuoshi Pan, Yu Li, Honglin Lin, Chenlin Ming, Xin Gao, Conghui He, Rui Yan</em></li>
  <li><strong>Mining Complex Patterns of Argumentative Reasoning in Natural Language Dialogue</strong><br><em>Ramon Ruiz-Dolz, Zlata Kikteva, John Lawrence</em></li>
  <li><strong>OS Agents: A Survey on MLLM-based Agents for Computer, Phone and Browser Use</strong><br><em>Xueyu Hu, Tao Xiong, Biao Yi, Ruixuan Xiao, Zishu Wei, Yurun Chen, Jiasheng Ye, Meiling Tao, Xiangxin Zhou, Ziyu Zhao, Yuhuai Li, Shengze Xu, Shenzhi Wang, Xinchen Xu, Shuofei Qiao, Zhaokai Wang, Kun Kuang, Tieyong Zeng, Liang Wang, Jiwei Li, Yuchen Eleanor Jiang, Wangchunshu Zhou, Guoyin Wang, Keting Yin, Zhou Zhao, Hongxia Yang, Fan Wu, Shengyu Zhang, Fei Wu</em></li>
  <li><strong>Data Quality Issues in Multilingual Speech Datasets: The Need for Sociolinguistic Awareness and Proactive Language Planning</strong><br><em>Mingfei Lau, Qian Chen, Yeming Fang, Tingting Xu, Tongzhou Chen, Pavel Golik</em></li>
  <li><strong>LLM as a Broken Telephone: Iterative Generation Distorts Information</strong><br><em>Amr Mohamed, Mingmeng Geng, Michalis Vazirgiannis, Guokan Shang</em></li>
  <li><strong>VLM2-Bench: A Closer Look at How Well VLMs Implicitly Link Explicit Matching Visual Cues</strong><br><em>Jianshu Zhang, Dongyu Yao, Renjie Pi, Paul Pu Liang, Yi R. Fung</em></li>
  <li><strong>Alleviating Distribution Shift in Synthetic Data for Machine Translation Quality Estimation</strong><br><em>Xiang Geng, Zhejian Lai, Jiajun Chen, Hao Yang, Shujian Huang</em></li>
  <li><strong>Combining Domain and Alignment Vectors Provides Better Knowledge-Safety Trade-offs in LLMs</strong><br><em>Megh Thakkar, Quentin Fournier, Matthew Riemer, Pin-Yu Chen, Amal Zouaq, Payel Das, Sarath Chandar</em></li>
  <li><strong>Can Uniform Meaning Representation Help GPT-4 Translate from Indigenous Languages?</strong><br><em>Shira Wein</em></li>
  <li><strong>Evaluation Agent: Efficient and Promptable Evaluation Framework for Visual Generative Models</strong><br><em>Fan Zhang, Shulin Tian, Ziqi Huang, Yu Qiao, Ziwei Liu</em></li>
  <li><strong>LLMs Struggle to Describe the Haystack without Human Help: A Social Science-Inspired Evaluation of Topic Models</strong><br><em>Zongxia Li, Lorena Calvo-Bartolomé, Alexander Miserlis Hoyle, Paiheng Xu, Daniel Kofi Stephens, Juan Francisco Fung, Alden Dima, Jordan Lee Boyd-Graber</em></li>
  <li><strong>ActiView: Evaluating Active Perception Ability for Multimodal Large Language Models</strong><br><em>Ziyue Wang, Chi Chen, Fuwen Luo, Yurui Dong, Yuanchi Zhang, Yuzhuang Xu, Xiaolong Wang, Peng Li, Yang Liu</em></li>
  <li><strong>Enough Coin Flips Can Make LLMs Act Bayesian</strong><br><em>Ritwik Gupta, Rodolfo Corona, Jiaxin Ge, Eric Wang, Dan Klein, Trevor Darrell, David M. Chan</em></li>
  <li><strong>Beyond Outcomes: Transparent Assessment of LLM Reasoning in Games</strong><br><em>Wenye Lin, Jonathan Roberts, Yunhan Yang, Samuel Albanie, Zongqing Lu, Kai Han</em></li>
  <li><strong>A Text is Worth Several Tokens: Text Embedding from LLMs Secretly Aligns Well with The Key Tokens</strong><br><em>Zhijie Nie, Richong Zhang, Zhanyu Wu</em></li>
  <li><strong>Commonsense Reasoning in Arab Culture</strong><br><em>Abdelrahman Sadallah, Junior Cedric Tonga, Khalid Almubarak, Saeed Almheiri, Farah Atif, Chatrine Qwaider, Karima Kadaoui, Sara Shatnawi, Yaser Alesh, Fajri Koto</em></li>
  <li><strong>AXIS: Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents</strong><br><em>Junting Lu, Zhiyang Zhang, Fangkai Yang, Jue Zhang, Lu Wang, Chao Du, Qingwei Lin, Saravan Rajmohan, Dongmei Zhang, Qi Zhang</em></li>
  <li><strong>Translation and Fusion Improves Cross-lingual Information Extraction</strong><br><em>Yang Chen, Vedaant Shah, Alan Ritter</em></li>
  <li><strong>Conditional Dichotomy Quantification via Geometric Embedding</strong><br><em>Shaobo Cui, Wenqing Liu, Yiyang Feng, Jiawei Zhou, Boi Faltings</em></li>
  <li><strong>Aligning Large Language Models with Implicit Preferences from User-Generated Content</strong><br><em>Zhaoxuan Tan, Zheng Li, Tianyi Liu, Haodong Wang, Hyokun Yun, Ming Zeng, Pei Chen, Zhihan Zhang, Yifan Gao, Ruijie Wang, Priyanka Nigam, Bing Yin, Meng Jiang</em></li>
  <li><strong>VQAGuider: Guiding Multimodal Large Language Models to Answer Complex Video Questions</strong><br><em>Yuyan Chen, Jiyuan Jia, Jiaxin Lu, Siyue Li, Yu Guan, Ming Yang, Qingpei Guo</em></li>
  <li><strong>Large Language Models are Good Relational Learners</strong><br><em>Fang Wu, Vijay Prakash Dwivedi, Jure Leskovec</em></li>
  <li><strong>SpaRE: Enhancing Spatial Reasoning in Vision-Language Models with Synthetic Data</strong><br><em>Michael Ogezi, Freda Shi</em></li>
  <li><strong>Distilling an End-to-End Voice Assistant Without Instruction Training Data</strong><br><em>William Barr Held, Yanzhe Zhang, Weiyan Shi, Minzhi Li, Michael J Ryan, Diyi Yang</em></li>
  <li><strong>CoMet: Metaphor-Driven Covert Communication for Multi-Agent Language Games</strong><br><em>Shuhang Xu, Fangwei Zhong</em></li>
  <li><strong>CER: Confidence Enhanced Reasoning in LLMs</strong><br><em>Ali Razghandi, Seyed Mohammad Hadi Hosseini, Mahdieh Soleymani Baghshah</em></li>
  <li><strong>Watermarking Large Language Models: An Unbiased and Low-risk Method</strong><br><em>Minjia Mao, Dongjun Wei, Zeyu Chen, Xiao Fang, Michael Chau</em></li>
  <li><strong>On Synthetic Data Strategies for Domain-Specific Generative Retrieval</strong><br><em>Haoyang Wen, Jiang Guo, Yi Zhang, Jiarong Jiang, Zhiguo Wang</em></li>
  <li><strong>LLM Braces: Straightening Out LLM Predictions with Relevant Sub-Updates</strong><br><em>Ying Shen, Lifu Huang</em></li>
  <li><strong>CONFETTI: Conversational Function-Calling Evaluation Through Turn-Level Interactions</strong><br><em>Tamer Alkhouli, Katerina Margatina, James Gung, Raphael Shu, Claudia Zaghi, MONICA SUNKARA, Yi Zhang</em></li>
  <li><strong>Evaluating Theory of (an uncertain) Mind: Predicting the Uncertain Beliefs of Others from Conversational Cues</strong><br><em>Anthony Sicilia, Malihe Alikhani</em></li>
  <li><strong>Uncertainty in Causality: A New Frontier</strong><br><em>Shaobo Cui, Luca Mouchel, Boi Faltings</em></li>
  <li><strong>SynthesizeMe! Inducing Persona-Guided Prompts for Personalized Reward Models in LLMs</strong><br><em>Michael J Ryan, Omar Shaikh, Aditri Bhagirath, Daniel Frees, William Barr Held, Diyi Yang</em></li>
  <li><strong>When People are Floods: Analyzing Dehumanizing Metaphors in Immigration Discourse with Large Language Models</strong><br><em>Julia Mendelsohn, Ceren Budak</em></li>
  <li><strong>AGrail: A Lifelong Agent Guardrail with Effective and Adaptive Safety Detection</strong><br><em>Weidi Luo, Shenghong Dai, Xiaogeng Liu, Suman Banerjee, Huan Sun, Muhao Chen, Chaowei Xiao</em></li>
  <li><strong>Improving Model Factuality with Fine-grained Critique-based Evaluator</strong><br><em>Yiqing Xie, Wenxuan Zhou, Pradyot Prakash, Di Jin, Yuning Mao, Quintin Fettes, Arya Talebzadeh, Sinong Wang, Han Fang, Carolyn Rose, Daniel Fried, Hejia Zhang</em></li>
  <li><strong>Building a Long Text Privacy Policy Corpus with Multi-Class Labels</strong><br><em>David Stein, Florencia Marotta-Wurgler</em></li>
  <li><strong>x-SAL: Leading Symbolic Reasoning across Languages via Cross-lingual Symbolic-Aided Language Model</strong><br><em>Leonardo Ranaldi, Giulia Pucci</em></li>
  <li><strong>When the LM misunderstood the human chuckled: Analyzing garden path effects in humans and language models</strong><br><em>Samuel Joseph Amouyal, Aya Meltzer-Asscher, Jonathan Berant</em></li>
  <li><strong>Cross-Lingual Pitfalls: Automatic Probing Cross-Lingual Weakness of Multilingual Large Language Models</strong><br><em>Zixiang Xu, Yanbo Wang, Yue Huang, Xiuying Chen, Jieyu Zhao, Meng Jiang, Xiangliang Zhang</em></li>
  <li><strong>VLSBench: Unveiling Visual Leakage in Multimodal Safety</strong><br><em>Xuhao Hu, Dongrui Liu, Hao Li, Xuanjing Huang, Jing Shao</em></li>
  <li><strong>Browsing Lost Unformed Recollections: A Benchmark for Tip-of-the-Tongue Search and Reasoning</strong><br><em>Sky CH-Wang, Darshan Girish Deshpande, Smaranda Muresan, Anand Kannappan, Rebecca Qian</em></li>
  <li><strong>Subword models struggle with word learning, but surprisal hides it</strong><br><em>Bastian Bunzeck, Sina Zarrieß</em></li>
  <li><strong>Data Laundering: Artificially Boosting Benchmark Results through Knowledge Distillation</strong><br><em>Jonibek Mansurov, Akhmed Sakip, Alham Fikri Aji</em></li>
  <li><strong>Conspiracy Theories and Where to Find Them on TikTok</strong><br><em>Francesco Corso, Francesco Pierri, Gianmarco De Francisci Morales</em></li>
  <li><strong>Growing Through Experience: Scaling Episodic Grounding in Language Models</strong><br><em>Chunhui Zhang, Sirui Wang, Zhongyu Ouyang, Xiangchi Yuan, Soroush Vosoughi</em></li>
  <li><strong>LLM as Entity Disambiguator for Biomedical Entity-Linking</strong><br><em>Christophe Ye, Cassie S. Mitchell</em></li>
  <li><strong>Exploiting the Shadows: Unveiling Privacy Leaks through Lower-Ranked Tokens in Large Language Models</strong><br><em>Yuan Zhou, ZHUO ZHANG, Xiangyu Zhang</em></li>
  <li><strong>Towards Geo-Culturally Grounded LLM Generations</strong><br><em>Piyawat Lertvittayakumjorn, David Kinney, Vinodkumar Prabhakaran, Donald Martin Jr., Sunipa Dev</em></li>
  <li><strong>Attacking Vision-Language Computer Agents via Pop-ups</strong><br><em>Yanzhe Zhang, Tao Yu, Diyi Yang</em></li>
  <li><strong>Explicit and Implicit Data Augmentation for Social Event Detection</strong><br><em>Congbo Ma, Yuxia Wang, Jia Wu, Jian Yang, Jing Du, Zitai Qiu, Qing Li, Hu Wang, Preslav Nakov</em></li>
  <li><strong>In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents</strong><br><em>Zhen Tan, Jun Yan, I-Hung Hsu, Rujun Han, Zifeng Wang, Long Le, Yiwen Song, Yanfei Chen, Hamid Palangi, George Lee, Anand Rajan Iyer, Tianlong Chen, huan liu, Chen-Yu Lee, Tomas Pfister</em></li>
  <li><strong>Revisiting Classical Chinese Event Extraction with Ancient Literature Information</strong><br><em>Xiaoyi Bao, Zhongqing Wang, Jinghang Gu, Chu-Ren Huang</em></li>
  <li><strong>Unanswerability Evaluation for Retrieval Augmented Generation</strong><br><em>XIANGYU PENG, Prafulla Kumar Choubey, Caiming Xiong, Chien-Sheng Wu</em></li>
  <li><strong>SCALE: Towards Collaborative Content Analysis in Social Science with Large Language Model Agents and Human Intervention</strong><br><em>Chengshuai Zhao, Zhen Tan, Chau-Wai Wong, Xinyan Zhao, Tianlong Chen, huan liu</em></li>
  <li><strong>Self-Error-Instruct: Generalizing from Errors for LLMs Mathematical Reasoning</strong><br><em>Erxin Yu, Jing Li, Ming Liao, Qi Zhu, Boyang XUE, Minghui Xu, Baojun Wang, Lanqing HONG, Fei Mi, Lifeng Shang</em></li>
  <li><strong>RAGEval: Scenario Specific RAG Evaluation Dataset Generation Framework</strong><br><em>Kunlun Zhu, Yifan Luo, Dingling Xu, Yukun Yan, Zhenghao Liu, Shi Yu, Ruobing Wang, Shuo Wang, Yishan Li, Nan Zhang, Xu Han, Zhiyuan Liu, Maosong Sun</em></li>
  <li><strong>A Survey on Patent Analysis: From NLP to Multimodal AI</strong><br><em>Homaira Huda Shomee, Zhu Wang, Sathya N. Ravi, Sourav Medya</em></li>
  <li><strong>SciVer: Evaluating Foundation Models for Multimodal Scientific Claim Verification</strong><br><em>Chengye Wang, Yifei Shen, Zexi Kuang, Arman Cohan, Yilun Zhao</em></li>
  <li><strong>MultiAgentBench : Evaluating the Collaboration and Competition of LLM agents</strong><br><em>Kunlun Zhu, Hongyi Du, Zhaochen Hong, Xiaocheng Yang, Shuyi Guo, Zhe Wang, Zhenhailong Wang, Cheng Qian, Xiangru Tang, Heng Ji, Jiaxuan You</em></li>
  <li><strong>Sinhala Encoder-only Language Models and Evaluation</strong><br><em>Tharindu Ranasinghe, Hansi Hettiarachchi, Nadeesha Chathurangi Naradde Vidana Pathirana, Damith Premasiri, Lasitha Uyangodage, Isuri Nanomi Arachchige, Alistair Plum, Paul Rayson, Ruslan Mitkov</em></li>
  <li><strong>LLMs can Perform Multi-Dimensional Analytic Writing Assessments: A Case Study of L2 Graduate-Level Academic English Writing</strong><br><em>Zhengxiang Wang, Veronika Makarova, Zhi Li, Jordan Kodner, Owen Rambow</em></li>
  <li><strong>SEUF: Is Unlearning One Expert Enough for Mixture-of-Experts LLMs?</strong><br><em>Haomin Zhuang, Yihua Zhang, Kehan Guo, Jinghan Jia, Gaowen Liu, Sijia Liu, Xiangliang Zhang</em></li>
  <li><strong>Pragmatics in the Era of Large Language Models: A Survey on Datasets, Evaluation, Opportunities and Challenges</strong><br><em>Bolei Ma, Yuting Li, Wei Zhou, Ziwei Gong, Yang Janet Liu, Katja Jasinskaja, Annemarie Friedrich, Julia Hirschberg, Frauke Kreuter, Barbara Plank</em></li>
  <li><strong>LocAgent: Agentic Code Localization with Graph-Based Indexing</strong><br><em>Zhaoling Chen, Xiangru Tang, Gangda Deng, Fang Wu, Jialong Wu, Zhiwei Jiang, Viktor Prasanna, Arman Cohan, Xingyao Wang</em></li>
  <li><strong>COSMMIC: Comment-Sensitive Multimodal Multilingual Indian Corpus for Summarization and Headline Generation</strong><br><em>Raghvendra Kumar, Mohammed Salman S A, Aryan Sahu, Tridib Nandi, Pragathi Y P, Sriparna Saha, Jose G Moreno</em></li>
  <li><strong>Mind the Gap: Static and Interactive Evaluations of Large Audio Models</strong><br><em>Minzhi Li, William Barr Held, Michael J Ryan, Kunat Pipatanakul, Potsawee Manakul, Hao Zhu, Diyi Yang</em></li>
  <li><strong>Understanding In-context Machine Translation for Low-Resource Languages: A Case Study on Manchu</strong><br><em>Renhao Pei, Yihong Liu, Peiqin Lin, François Yvon, Hinrich Schuetze</em></li>
  <li><strong>CKnowEdit: A New Chinese Knowledge Editing Dataset for Linguistics, Facts, and Logic Error Correction in LLMs</strong><br><em>Jizhan Fang, Tianhe Lu, Yunzhi Yao, Ziyan Jiang, Xin Xu, Huajun Chen, Ningyu Zhang</em></li>
  <li><strong>TripleFact: Defending Data Contamination in the Evaluation of LLM-driven Fake News Detection</strong><br><em>Cheng Xu, Nan Yan</em></li>
  <li><strong>MUSTS: MUltilingual Semantic Textual Similarity Benchmark</strong><br><em>Tharindu Ranasinghe, Hansi Hettiarachchi, Constantin Orasan, Ruslan Mitkov</em></li>
  <li><strong>Meaning Beyond Truth Conditions: Evaluating Discourse Level Understanding via Anaphora Accessibility</strong><br><em>Xiaomeng Zhu, Zhenghao Zhou, Simon Charlow, Robert Frank</em></li>
  <li><strong>Benchmarking Systematic Relational Reasoning with Large Language and Reasoning Models</strong><br><em>Irtaza Khalid, Amir Masoud Nourollah, Steven Schockaert</em></li>
  <li><strong>Warmup Generations: A Task-Agnostic Approach for Guiding Sequence-to-Sequence Learning with Unsupervised Initial State Generation</strong><br><em>Senyu Li, Zipeng Sun, Jiayi Wang, Xue Liu, Pontus Stenetorp, Siva Reddy, David Ifeoluwa Adelani</em></li>
  <li><strong>Building Better: Avoiding Pitfalls in Developing Language Resources when Data is Scarce</strong><br><em>Nedjma Ousidhoum, Meriem Beloucif, Saif M. Mohammad</em></li>
  <li><strong>Can Large Language Models Accurately Generate Answer Keys for Health-related Questions?</strong><br><em>Davis Bartels, Deepak Gupta, Dina Demner-Fushman</em></li>
  <li><strong>Literary Evidence Retrieval via Long-Context Language Models</strong><br><em>Katherine Thai, Mohit Iyyer</em></li>
  <li><strong>BRIGHTER: BRIdging the Gap in Human-Annotated Textual Emotion Recognition Datasets for 28 Languages</strong><br><em>Shamsuddeen Hassan Muhammad, Nedjma Ousidhoum, Idris Abdulmumin, Jan Philip Wahle, Terry Ruas, Meriem Beloucif, Christine de Kock, Nirmal Surange, Daniela Teodorescu, Ibrahim Said Ahmad, David Ifeoluwa Adelani, Alham Fikri Aji, Felermino D. M. A. Ali, Ilseyar Alimova, Vladimir Araujo, Nikolay Babakov, Naomi Baes, Ana-Maria Bucur, Andiswa Bukula, Guanqun Cao, Rodrigo Tufiño, Rendi Chevi, Chiamaka Ijeoma Chukwuneke, Alexandra Ciobotaru, Daryna Dementieva, Murja Sani Gadanya, Robert Geislinger, Bela Gipp, Oumaima Hourrane, Oana Ignat, Falalu Ibrahim Lawan, Rooweither Mabuya, Rahmad Mahendra, Vukosi Marivate, Alexander Panchenko, Andrew Piper, Charles Henrique Porto Ferreira, Vitaly Protasov, Samuel Rutunda, Manish Shrivastava, Aura Cristina Udrea, Lilian Diana Awuor Wanzare, Sophie Wu, Florian Valentin Wunderlich, Hanif Muhammad Zhafran, Tianhui Zhang, Yi Zhou, Saif M. Mohammad</em></li>
  <li><strong>SkillVerse : Assessing and Enhancing LLMs with Tree Evaluation</strong><br><em>Yufei Tian, Jiao Sun, Nanyun Peng, Zizhao Zhang</em></li>
  <li><strong>CypherBench: Towards Precise Retrieval over Full-scale Modern Knowledge Graphs in the LLM Era</strong><br><em>Yanlin Feng, Simone Papicchio, Sajjadur Rahman</em></li>
  <li><strong>Empathy Prediction from Diverse Perspectives</strong><br><em>Francine Chen, Scott Carter, Tatiana Lau, Nayeli Suseth Bravo, Sumanta Bhattacharyya, Kate Sieck, Charlene C. Wu</em></li>
  <li><strong>Are LLMs effective psychological assessors? Leveraging adaptive RAG for interpretable mental health screening through psychometric practice</strong><br><em>Federico Ravenda, Seyed Ali Bahrainian, Andrea Raballo, Antonietta Mira, Noriko Kando</em></li>
  <li><strong>INTERACT: Enabling Interactive, Question-Driven Learning in Large Language Models</strong><br><em>Aum Kendapadi, Kerem Zaman, Rakesh R Menon, Shashank Srivastava</em></li>
  <li><strong>Circuit Stability Characterizes Language Model Generalization</strong><br><em>Alan Sun</em></li>
  <li><strong>Comparing LLM-generated and human-authored news text using formal syntactic theory</strong><br><em>Olga Zamaraeva, Dan Flickinger, Francis Bond, Carlos Gómez-Rodríguez</em></li>
  <li><strong>Improving Preference Extraction In LLMs By Identifying Latent Knowledge Through Classifying Probes</strong><br><em>Sharan Maiya, Yinhong Liu, Ramit Debnath, Anna Korhonen</em></li>
  <li><strong>White Men Lead, Black Women Help? Benchmarking and Mitigating Language Agency Social Biases in LLMs</strong><br><em>Yixin Wan, Kai-Wei Chang</em></li>
  <li><strong>AIMSCheck: Leveraging LLMs for AI-Assisted Review of Modern Slavery Statements Across Jurisdictions</strong><br><em>Adriana Eufrosina Bora, Akshatha Arodi, Duoyi Zhang, Jordan Bannister, Mirko Bronzi, Arsene Fansi Tchango, Md Abul Bashar, Richi Nayak, Kerrie Mengersen</em></li>
  <li><strong>Collapse of Dense Retrievers: Short, Early, and Literal Biases Outranking Factual Evidence</strong><br><em>Mohsen Fayyaz, Ali Modarressi, Hinrich Schuetze, Nanyun Peng</em></li>
  <li><strong>SelfElicit: Your Language Model Secretly Knows Where is the Relevant Evidence</strong><br><em>Zhining Liu, Rana Ali Amjad, Ravinarayana Adkathimar, Tianxin Wei, Hanghang Tong</em></li>
  <li><strong>The Male CEO and the Female Assistant: Evaluation and Mitigation of Gender Biases in Text-To-Image Generation of Dual Subjects</strong><br><em>Yixin Wan, Kai-Wei Chang</em></li>
  <li><strong>A Little Human Data Goes A Long Way</strong><br><em>Dhananjay Ashok, Jonathan May</em></li>
  <li><strong>Mitigating Shortcut Learning with InterpoLated Learning</strong><br><em>Michalis Korakakis, Andreas Vlachos, Adrian Weller</em></li>
  <li><strong>Toward Automatic Discovery of a Canine Phonetic Alphabet</strong><br><em>Theron S. Wang, Xingyuan Li, Hridayesh Lekhak, Tuan Minh Dang, Mengyue Wu, Kenny Q. Zhu</em></li>
  <li><strong>DavIR: Data Selection via Implicit Reward for Large Language Models</strong><br><em>Haotian Zhou, Tingkai Liu, Qianli Ma, Yufeng Zhang, Jianbo Yuan, Pengfei Liu, Yang You, Hongxia Yang</em></li>
  <li><strong>Byte Latent Transformer: Patches Scale Better Than Tokens</strong><br><em>Artidoro Pagnoni, Ramakanth Pasunuru, Pedro Rodriguez, John Nguyen, Benjamin Muller, Margaret Li, Chunting Zhou, LILI YU, Jason E Weston, Luke Zettlemoyer, Gargi Ghosh, Mike Lewis, Ari Holtzman, Srini Iyer</em></li>
  <li><strong>DiffuseDef: Improved Robustness to Adversarial Attacks via Iterative Denoising</strong><br><em>Zhenhao Li, Huichi Zhou, Marek Rei, Lucia Specia</em></li>
  <li><strong>Identifying Cellular Niches in Spatial Transcriptomics: An Investigation into the Capabilities of Large Language Models</strong><br><em>Huanhuan Wei, Xiao Luo, Hongyi Yu, Jinping Liang, Luning Yang, Lixing Lin, Alexandra Popa, Xiting Yan</em></li>
  <li><strong>Culture Matters in Toxic Language Detection in Persian</strong><br><em>Zahra Bokaei, Walid Magdy, Bonnie Webber</em></li>
  <li><strong>Bitnet.cpp: Efficient Edge Inference for Ternary LLMs</strong><br><em>Jinheng Wang, Hansong Zhou, Ting Song, Shijie Cao, Yan Xia, Ting Cao, Jianyu Wei, Shuming Ma, Hongyu Wang, Furu Wei</em></li>
  <li><strong>Instance-Selection-Inspired Undersampling Strategies for Bias Reduction in Small and Large Language Models for Binary Text Classification</strong><br><em>Guilherme Fonseca, Washington Cunha, Gabriel Prenassi, Marcos André Gonçalves, Leonardo Chaves Dutra da Rocha</em></li>
  <li><strong>Forward Knows Efficient Backward Path: Saliency-Guided Memory-Efficient Fine-tuning of Large Language Models</strong><br><em>Yeachan Kim, SangKeun Lee</em></li>
  <li><strong>Focus on What Matters: Enhancing Medical Vision-Language Models with Automatic Attention Alignment Tuning</strong><br><em>Aofei Chang, Le Huang, Alex James Boyd, Parminder Bhatia, Taha Kass-Hout, Cao Xiao, Fenglong Ma</em></li>
  <li><strong>LLMs + Persona-Plug = Personalized LLMs</strong><br><em>Jiongnan Liu, Yutao Zhu, Shuting Wang, Xiaochi Wei, Erxue Min, Yu Lu, Shuaiqiang Wang, Dawei Yin, Zhicheng Dou</em></li>
  <li><strong>Developmentally-plausible Working Memory Shapes a Critical Period for Language Acquisition</strong><br><em>Masato Mita, Ryo Yoshida, Yohei Oseki</em></li>
  <li><strong>IRIS: An Iterative and Integrated Framework for Verifiable Causal Discovery in the Absence of Tabular Data</strong><br><em>Tao Feng, Lizhen Qu, Niket Tandon, Gholamreza Haffari</em></li>
  <li><strong>INJONGO: A Multicultural Intent Detection and Slot-filling Dataset for 16 African Languages</strong><br><em>Hao Yu, Jesujoba Oluwadara Alabi, Andiswa Bukula, Jian Yun Zhuang, En-Shiun Annie Lee, Tadesse Kebede Guge, Israel Abebe Azime, Happy Buzaaba, Blessing Kudzaishe Sibanda, Godson Koffi KALIPE, Jonathan Mukiibi, Salomon KABONGO KABENAMUALU, Mmasibidi Setaka, Lolwethu Ndolela, Nkiruka Odu, Rooweither Mabuya, Shamsuddeen Hassan Muhammad, Salomey Osei, Sokhar Samb, Dietrich Klakow, David Ifeoluwa Adelani</em></li>
  <li><strong>Boosting Long-Context Information Seeking via Query-Guided Activation Refilling</strong><br><em>Hongjin Qian, Zheng Liu, Peitian Zhang, Zhicheng Dou, Defu Lian</em></li>
  <li><strong>Efficient Pretraining Data Selection for Language Models via Multi-Actor Collaboration</strong><br><em>Tianyi Bai, Ling Yang, Zhen Hao Wong, Fupeng Sun, Xinlin Zhuang, Jiahui Peng, Chi Zhang, Lijun Wu, Qiu Jiantao, Wentao Zhang, Binhang Yuan, Conghui He</em></li>
  <li><strong>AdaDHP: Fine-Grained Fine-Tuning via Dual Hadamard Product and Adaptive Parameter Selection</strong><br><em>Han Liu, Changya Li, Xiaotong Zhang, Feng Zhang, Fenglong Ma, Wei Wang, Hong Yu</em></li>
  <li><strong>KG-Agent: An Efficient Autonomous Agent Framework for Complex Reasoning over Knowledge Graph</strong><br><em>Jinhao Jiang, Kun Zhou, Xin Zhao, Yang Song, Chen Zhu, Hengshu Zhu, Ji-Rong Wen</em></li>
  <li><strong>Curriculum Debiasing: Toward Robust Parameter-Efficient Fine-Tuning Against Dataset Biases</strong><br><em>Mingyu Lee, Yeachan Kim, Wing-Lam Mok, SangKeun Lee</em></li>
  <li><strong>Does Context Matter? ContextualJudgeBench for Evaluating LLM-based Judges in Contextual Settings</strong><br><em>Austin Xu, Srijan Bansal, Yifei Ming, Semih Yavuz, Shafiq Joty</em></li>
  <li><strong>On the Reliability of Large Language Models for Causal Discovery</strong><br><em>Tao Feng, Lizhen Qu, Niket Tandon, Zhuang Li, Xiaoxi Kang, Gholamreza Haffari</em></li>
  <li><strong>Value-Spectrum: Quantifying Preferences of Vision-Language Models via Value Decomposition in Social Media Contexts</strong><br><em>Jingxuan Li, Yuning Yang, Shengqi Yang, Linfan Zhang, Ying Nian Wu</em></li>
  <li><strong>TeRDy: Temporal Relation Dynamics through Frequency Decomposition for Temporal Knowledge Graph Completion</strong><br><em>Ziyang Liu, Chaokun Wang</em></li>
  <li><strong>Incorporating Domain Knowledge into Materials Tokenization</strong><br><em>Yerim Oh, Jun-Hyung Park, Junho Kim, SungHo Kim, SangKeun Lee</em></li>
  <li><strong>PIG: Privacy Jailbreak Attack on LLMs via Gradient-based Iterative In-Context Optimization</strong><br><em>Yidan Wang, Yanan Cao, Yubing Ren, Fang Fang, Zheng Lin, Binxing Fang</em></li>
  <li><strong>Agents Under Siege: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks</strong><br><em>Rana Shahroz, Zhen Tan, Sukwon Yun, Charles Fleming, Tianlong Chen</em></li>
  <li><strong>Semantic-Eval : A Semantic Comprehension Evaluation Framework for Large Language Models Generation without Training</strong><br><em>Shusheng Li, Jiale Li, Yifei Qu, Xinwei Shi, Yanliang Guo, Ziyi He, Yubo Wang, Wenjun Tan</em></li>
  <li><strong>Between Circuits and Chomsky: Pre-pretraining on Formal Languages Imparts Linguistic Biases</strong><br><em>Michael Y. Hu, Jackson Petty, Chuan Shi, William Merrill, Tal Linzen</em></li>
  <li><strong>When to Speak, When to Abstain: Contrastive Decoding with Abstention</strong><br><em>Hyuhng Joon Kim, Youna Kim, Sang-goo Lee, Taeuk Kim</em></li>
  <li><strong>On the Risk of Evidence Pollution for Malicious Social Text Detection in the Era of LLMs</strong><br><em>Herun Wan, Minnan Luo, Zhixiong Su, Guang Dai, Xiang Zhao</em></li>
  <li><strong>Investigating and Extending Homans’ Social Exchange Theory with Large Language Model based Agents</strong><br><em>Lei Wang, Zheqing Zhang, Xu Chen</em></li>
  <li><strong>A Drop-In Solution for On-the-Fly Adaptation of Speculative Decoding in Large Language Models</strong><br><em>Jiesong Liu, Brian Park, Xipeng Shen</em></li>
  <li><strong>If Attention Serves as a Cognitive Model of Human Memory Retrieval, What is the Plausible Memory Representation?</strong><br><em>Ryo Yoshida, Shinnosuke Isono, Kohei Kajikawa, Taiga Someya, Yushi Sugimoto, Yohei Oseki</em></li>
  <li><strong>Aligning VLM Assistants with Personalized Situated Cognition</strong><br><em>Yongqi Li, Shen Zhou, Xiaohu Li, Xin Miao, Jintao Wen, Mayi Xu, Jianhao Chen, Birong Pan, Hankun Kang, Yuanyuan Zhu, Ming Zhong, Tieyun Qian</em></li>
  <li><strong>Attention Entropy is a Key Factor: An Analysis of Parallel Context Encoding with Full-attention-based Pre-trained Language Models</strong><br><em>Zhisong Zhang, Yan Wang, Xinting Huang, Tianqing Fang, Hongming Zhang, Chenlong Deng, Shuaiyi Li, Dong Yu</em></li>
  <li><strong>Faster Speculative Decoding via Effective Draft Decoder with Pruned Candidate Tree</strong><br><em>Huanran Zheng, Xiaoling Wang</em></li>
  <li><strong>Selecting and Merging: Towards Adaptable and Scalable Named Entity Recognition with Large Language Models</strong><br><em>Zhuojun Ding, Wei Wei, Chenghao Fan</em></li>
  <li><strong>Embracing Imperfection: Simulating Students with Diverse Cognitive Levels Using LLM-based Agents</strong><br><em>Tao Wu, Jingyuan Chen, Wang Lin, Mengze Li, Yumeng Zhu, Ang Li, Kun Kuang, Fei Wu</em></li>
  <li><strong>CADReview: Automatically Reviewing CAD Programs with Error Detection and Correction</strong><br><em>Jiali Chen, Xusen Hei, HongFei Liu, Yuancheng Wei, Zikun Deng, Jiayuan Xie, Yi Cai, Li Qing</em></li>
  <li><strong>Think&amp;Cite: Improving Attributed Text Generation with Self-Guided Tree Search and Progress Reward Modeling</strong><br><em>Junyi Li, Hwee Tou Ng</em></li>
  <li><strong>The Lawyer That Never Thinks: Consistency and Fairness as Keys to Reliable AI</strong><br><em>Dana R Alsagheer, Abdulrahman Kamal, Mohammad Kamal, Cosmo Yang Wu, Weidong Shi</em></li>
  <li><strong>Polishing Every Facet of the GEM: Testing Linguistic Competence of LLMs and Humans in Korean</strong><br><em>SungHo Kim, Nayeon Kim, Taehee Jeon, SangKeun Lee</em></li>
  <li><strong>SpeechFake: A Large-Scale Multilingual Speech Deepfake Dataset Incorporating Cutting-Edge Generation Methods</strong><br><em>Wen Huang, Yanmei Gu, Zhiming Wang, Huijia Zhu, Yanmin Qian</em></li>
  <li><strong>ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off Code Generation</strong><br><em>Houxing Ren, Mingjie Zhan, Zhongyuan Wu, Aojun Zhou, Junting Pan, Hongsheng Li</em></li>
  <li><strong>InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes Under Herd Behavior</strong><br><em>Huisheng Wang, Zhuoshi Pan, Hangjing Zhang, Mingxiao Liu, Hanqing Gao, H. Vicky Zhao</em></li>
  <li><strong>Enhancing Neural Machine Translation Through Target Language Data: A $k$NN-LM Approach for Domain Adaptation</strong><br><em>Abudurexiti Reheman, Hongyu Liu, Junhao Ruan, Abudukeyumu Abudula, yingfeng luo, Tong Xiao, JingBo Zhu</em></li>
  <li><strong>Multi-level Relevance Document Identifier Learning for Generative Retrieval</strong><br><em>Fuwei Zhang, Xiaoyu Liu, Xinyu Jia, Yingfei Zhang, Shuai Zhang, Xiang Li, Fuzhen Zhuang, Wei Lin, Zhao Zhang</em></li>
  <li><strong>EfficientQAT: Efficient Quantization-Aware Training for Large Language Models</strong><br><em>Mengzhao Chen, Wenqi Shao, Peng Xu, Jiahao Wang, Peng Gao, Kaipeng Zhang, Ping Luo</em></li>
  <li><strong>Exploring How Generative MLLMs Perceive More Than CLIP with the Same Vision Encoder</strong><br><em>Siting Li, Pang Wei Koh, Simon Shaolei Du</em></li>
  <li><strong>NexusSum: Hierarchical LLM Agents for Long-Form Narrative Summarization</strong><br><em>Hyuntak Kim, Byung-Hak Kim</em></li>
  <li><strong>HAIC: Improving Human Action Understanding and Generation with Better Captions for Multi-modal Large Language Models</strong><br><em>Xiao Wang, Jingyun Hua, Weihong Lin, Yuanxing Zhang, Fuzheng Zhang, Jianlong Wu, Di ZHANG, Liqiang Nie</em></li>
  <li><strong>Uni-Retrieval: A Multi-Style Retrieval Framework for STEM’s Education</strong><br><em>Yanhao Jia, Xinyi Wu, Li Hao, QinglinZhang, Yuxiao Hu, Shuai Zhao, Wenqi Fan</em></li>
  <li><strong>DenseLoRA: Dense Low-Rank Adaptation of Large Language Models</strong><br><em>Lin Mu, Xiaoyu Wang, Li Ni, Yang Li, Zhize Wu, Peiquan Jin, Yiwen Zhang</em></li>
  <li><strong>Exploring the Potential of LLMs as Personalized Assistants: Dataset, Evaluation, and Analysis</strong><br><em>Jisoo Mok, Ik-hwan Kim, Sangkwon Park, Sungroh Yoon</em></li>
  <li><strong>Cracking Factual Knowledge: A Comprehensive Analysis of Degenerate Knowledge Neurons in Large Language Models</strong><br><em>Yuheng Chen, Pengfei Cao, Yubo Chen, Yining Wang, Shengping Liu, Kang Liu, Jun Zhao</em></li>
  <li><strong>Towards Context-Robust LLMs: A Gated Representation Fine-tuning Approach</strong><br><em>Shenglai Zeng, Pengfei He, Kai Guo, Tianqi Zheng, Hanqing Lu, Yue Xing, Hui Liu</em></li>
  <li><strong>Seeking Rational Demonstrations for Large Language Models: A Domain Generalization Approach to Unsupervised Cross-Domain Keyphrase Generation</strong><br><em>Guangzhen Zhao, Yu Yao, Dechang Kong, Zhenjiang Dong</em></li>
  <li><strong>On Support Samples of Next Word Prediction</strong><br><em>Yuqian Li, Yupei Du, Yufang Liu, Feifei Feng, Mou Xiao Feng, Yuanbin Wu</em></li>
  <li><strong>WebWalker: Benchmarking LLMs in Web Traversal</strong><br><em>Jialong Wu, Wenbiao Yin, Yong Jiang, Zhenglin Wang, Zekun Xi, Runnan Fang, Linhai Zhang, Yulan He, Deyu Zhou, Pengjun Xie, Fei Huang</em></li>
  <li><strong>From Trade-off to Synergy: A Versatile Symbiotic Watermarking Framework for Large Language Models</strong><br><em>Yidan Wang, Yubing Ren, Yanan Cao, Binxing Fang</em></li>
  <li><strong>AutoGUI: Scaling GUI Grounding with Automatic Functionality Annotations from LLMs</strong><br><em>Hongxin Li, Jingfan CHEN, Jingran Su, Yuntao Chen, Li Qing, Zhaoxiang Zhang</em></li>
  <li><strong>Introducing Graph Context into Language Models through Parameter-Efficient Fine-Tuning for Lexical Relation Mining</strong><br><em>Jingwen Sun, Zhiyi Tian, Yu He, Jingwei Sun, Guangzhong Sun</em></li>
  <li><strong>S-RAG: A Novel Audit Framework for Detecting Unauthorized Use of Personal Data in RAG Systems</strong><br><em>Zhirui Zeng, Jiamou Liu, Meng-Fen Chiang, Jialing He, Zijian Zhang</em></li>
  <li><strong>Praetor: A Fine-Grained Generative LLM Evaluator with Instance-Level Customizable Evaluation Criteria</strong><br><em>Yongqi Leng, Renren Jin, Yue chen, Zhuowen Han, Ling Shi, Jianxiang Peng, Lei Yang, Juesi Xiao, Deyi Xiong</em></li>
  <li><strong>LexKeyPlan: Planning with Keyphrases and Retrieval Augmentation for Legal Text Generation: A Case Study on European Court of Human Rights Cases</strong><br><em>Santosh T.Y.S.S, Elvin Quero Hernandez</em></li>
  <li><strong>Mitigating Gender Confounding Bias from Spoken Language in Dementia Detection via Weight Masking</strong><br><em>Zhecheng Sheng, Xiruo Ding, Brian Hur, Changye Li, Trevor Cohen, Serguei V. S. Pakhomov</em></li>
  <li><strong>MCS-Bench: A Comprehensive Benchmark for Evaluating Multimodal Large Language Models in Chinese Classical Studies</strong><br><em>Yang Liu, Jiahuan Cao, Hiuyi Cheng, Yongxin Shi, Kai Ding, Lianwen Jin</em></li>
  <li><strong>The Knowledge Microscope: Features as Better Analytical Lenses than Neurons</strong><br><em>Yuheng Chen, Pengfei Cao, Kang Liu, Jun Zhao</em></li>
  <li><strong>From Real to Synthetic: Synthesizing Millions of Diversified and Complicated User Instructions with Attributed Grounding</strong><br><em>Chiwei Zhu, Benfeng Xu, Xiaorui Wang, Zhendong Mao</em></li>
  <li><strong>PrivaCI-Bench: Evaluating Privacy with Contextual Integrity and Legal Compliance</strong><br><em>Haoran Li, Wenbin Hu, Huihao JING, Yulin Chen, Qi Hu, Sirui Han, Tianshu Chu, Peizhao Hu, Yangqiu Song</em></li>
  <li><strong>Unveiling Environmental Impacts of Large Language Model Serving: A Functional Unit View</strong><br><em>Yanran Wu, Inez Hua, Yi Ding</em></li>
  <li><strong>ExpeTrans: LLMs Are Experiential Transfer Learners</strong><br><em>Jinglong Gao, Xiao Ding, Lingxiao Zou, Bibo Cai, Bing Qin, Ting Liu</em></li>
  <li><strong>Cool-Fusion: Fuse Large Language Models without Training</strong><br><em>Cong Liu, Xiaojun Quan, Yan Pan, Weigang Wu, Xu Chen, Liang Lin</em></li>
  <li><strong>DAPE V2: Process Attention Score as Feature Map for Length Extrapolation</strong><br><em>Chuanyang Zheng, Yihang Gao, Han Shi, Jing Xiong, Jiankai Sun, Jingyao Li, Minbin Huang, Xiaozhe Ren, Michael Ng, Xin Jiang, Zhenguo Li, Yu Li</em></li>
  <li><strong>MuSC: Improving Complex Instruction Following with Multi-granularity Self-Contrastive Training</strong><br><em>Hui Huang, Jiaheng Liu, Yancheng He, Shilong Li, Bing Xu, Conghui Zhu, Muyun Yang, Tiejun Zhao</em></li>
  <li><strong>LongReD: Mitigating Short-Text Degradation of Long-Context Large Language Models via Restoration Distillation</strong><br><em>Zican Dong, Junyi Li, Jinhao Jiang, Mingyu Xu, Xin Zhao, Bingning Wang, Weipeng Chen</em></li>
  <li><strong>APB: Accelerating Distributed Long-Context Inference by Passing Compressed Context Blocks across GPUs</strong><br><em>Yuxiang Huang, Mingye Li, Xu Han, Chaojun Xiao, Weilin Zhao, Sun Ao, Hao Zhou, Jie Zhou, Zhiyuan Liu, Maosong Sun</em></li>
  <li><strong>PPT: A Minor Language News Recommendation Model via Cross-Lingual Preference Pattern Transfer</strong><br><em>Yiyang Zhang, Nan Chen</em></li>
  <li><strong>GainRAG: Preference Alignment in Retrieval-Augmented Generation through Gain Signal Synthesis</strong><br><em>Yi Jiang, Sendong Zhao, Jianbo Li, Haochun Wang, Bing Qin</em></li>
  <li><strong>Top-$n\sigma$: Eliminating Noise in Logit Space for Robust Token Sampling of LLM</strong><br><em>Chenxia Tang, Jianchun Liu, Hongli Xu, Liusheng Huang</em></li>
  <li><strong>SCOPE: Optimizing Key-Value Cache Compression in Long-context Generation</strong><br><em>Jialong Wu, Zhenglin Wang, Linhai Zhang, Yilong Lai, Yulan He, Deyu Zhou</em></li>
  <li><strong>Mitigating Non-Representative Prototypes and Representation Bias in Few-Shot Continual Relation Extraction</strong><br><em>Thanh Duc Pham, Nam Le Hai, Linh Ngo Van, Nguyen Thi Ngoc Diep, Sang Dinh, Thien Huu Nguyen</em></li>
  <li><strong>MoQAE: Mixed-Precision Quantization for Long-Context LLM Inference via Mixture of Quantization-Aware Experts</strong><br><em>Wei Tao, Haocheng Lu, Xiaoyang Qu, Bin Zhang, Kai Lu, Jiguang Wan, Jianzong Wang</em></li>
  <li><strong>PrivacyRestore: Privacy-Preserving Inference in Large Language Models via Privacy Removal and Restoration</strong><br><em>Ziqian Zeng, Jianwei Wang, Junyao Yang, ZhengdongLu, Haoran Li, Huiping Zhuang, Cen Chen</em></li>
  <li><strong>Meta-rater: A Multi-dimensional Data Selection Method for Pre-training Language Models</strong><br><em>Xinlin Zhuang, Jiahui Peng, Ren Ma, Yinfan Wang, Tianyi Bai, Xingjian Wei, Qiu Jiantao, Chi Zhang, Ying Qian, Conghui He</em></li>
  <li><strong>GuessArena: Guess Who I Am? A Self-Adaptive Framework for Evaluating LLMs in Domain-Specific Knowledge and Reasoning</strong><br><em>Qingchen Yu, Zifan Zheng, Ding Chen, Simin Niu, Bo Tang, Feiyu Xiong, Zhiyu li</em></li>
  <li><strong>Sample-Efficient Human Evaluation of Large Language Models via Maximum Discrepancy Competition</strong><br><em>Kehua Feng, Keyan Ding, tan hongzhi, Kede Ma, Zhihua Wang, Shuangquan Guo, Cheng yuzhou, Ge Sun, Guozhou Zheng, Qiang Zhang, Huajun Chen</em></li>
  <li><strong>DTCRS: Dynamic Tree Construction for Recursive Summarization</strong><br><em>Guanran Luo</em></li>
  <li><strong>A Generative Adaptive Replay Continual Learning Model for Temporal Knowledge Graph Reasoning</strong><br><em>Zhiyu Zhang, Wei Chen, Youfang Lin, Huaiyu Wan</em></li>
  <li><strong>ARise: Towards Knowledge-Augmented Reasoning via Risk-Adaptive Search</strong><br><em>Yize Zhang, Tianshu Wang, Sirui Chen, Kun Wang, Xingyu Zeng, Hongyu Lin, Xianpei Han, Le Sun, Chaochao Lu</em></li>
  <li><strong>PKAG-DDI: Pairwise Knowledge-Augmented Language Model for Drug-Drug Interaction Event Text Generation</strong><br><em>Ziyan Wang, Zhankun Xiong, Feng Huang, Wen Zhang</em></li>
  <li><strong>Knowledge-Augmented Multimodal Clinical Rationale Generation for Disease Diagnosis with Small Language Models</strong><br><em>Shuai Niu, Jing Ma, Hongzhan Lin, Liang Bai, Zhihua Wang, Richard Yi Da Xu, Yunya Song, Xian Yang</em></li>
  <li><strong>TWIST: Text-encoder Weight-editing for Inserting Secret Trojans in Text-to-Image Models</strong><br><em>Xindi Li, Zhe Liu, Tong Zhang, Jiahao Chen, Qingming Li, Jinbao Li, Shouling Ji</em></li>
  <li><strong>Frictional Agent Alignment Framework: Slow Down and Don’t Break Things</strong><br><em>Abhijnan Nath, Carine Graff, Andrei Bachinin, Nikhil Krishnaswamy</em></li>
  <li><strong>Powerformer: Efficient and High-Accuracy Privacy-Preserving Language Model with Homomorphic Encryption</strong><br><em>Dongjin Park, Eunsang Lee, Joon-Woo Lee</em></li>
  <li><strong>Beware of Your Po! Measuring and Mitigating AI Safety Risks in Role-Play Fine-Tuning of LLMs</strong><br><em>Weixiang Zhao, Yulin Hu, Yang Deng, Jiahe Guo, Xingyu Sui, Xinyang Han, An Zhang, Yanyan Zhao, Bing Qin, Tat-Seng Chua, Ting Liu</em></li>
  <li><strong>Can Graph Neural Networks Learn Language with Extremely Weak Text Supervision?</strong><br><em>Zihao Li, Lecheng Zheng, Bowen Jin, Dongqi Fu, Baoyu Jing, Yikun Ban, Jingrui He, Jiawei Han</em></li>
  <li><strong>Towards Enhanced Immersion and Agency for LLM-based Interactive Drama</strong><br><em>Hongqiu Wu, Weiqi Wu, Tianyang Xu, Jiameng Zhang, hai zhao</em></li>
  <li><strong>Disambiguating Reference in Visually Grounded Dialogues through Joint Modeling of Textual and Multimodal Semantic Structures</strong><br><em>Shun Inadumi, Nobuhiro Ueda, Koichiro Yoshino</em></li>
  <li><strong>Improving Factuality with Explicit Working Memory</strong><br><em>Mingda Chen, Yang Li, Karthik Padthe, Rulin Shao, Alicia Yi Sun, Luke Zettlemoyer, Gargi Ghosh, Wen-tau Yih</em></li>
  <li><strong>Gradient-Adaptive Policy Optimization: Towards Multi-Objective Alignment of Large Language Models</strong><br><em>Chengao Li, Hanyu Zhang, Yunkun Xu, Hongyan Xue, Xiang Ao, Qing He</em></li>
  <li><strong>Dynamic Parallel Tree Search for Efficient LLM Reasoning</strong><br><em>Yifu Ding, Wentao Jiang, Shunyu Liu, Yongcheng Jing, Jinyang Guo, Yingjie Wang, Jing Zhang, Zengmao Wang, Ziwei Liu, Bo Du, Xianglong Liu, Dacheng Tao</em></li>
  <li><strong>Pre$^3$: Enabling Deterministic Pushdown Automata for Faster Structured LLM Generation</strong><br><em>Junyi Chen, Shihao Bai, Zaijun Wang, Siyu Wu, Chuheng Du, Hailong Yang, Ruihao Gong, Shengzhong Liu, Fan Wu, Guihai Chen</em></li>
  <li><strong>SHARE: An SLM-based Hierarchical Action CorREction Assistant for Text-to-SQL</strong><br><em>Ge Qu, Jinyang Li, Bowen Qin, Xiaolong Li, Nan Huo, Chenhao Ma, Reynold Cheng</em></li>
  <li><strong>GenderAlign: An Alignment Dataset for Mitigating Gender Bias in Large Language Models</strong><br><em>Tao Zhang, Ziqian Zeng, YuxiangXiao, Huiping Zhuang, Cen Chen, James R. Foulds, Shimei Pan</em></li>
  <li><strong>Large Language and Protein Assistant for Protein-Protein Interactions Prediction</strong><br><em>Peng Zhou, Pengsen Ma, Jianmin Wang, Xibao Cai, Haitao Huang, Wei Liu, Longyue Wang, Lai Hou Tim, xiangxiang Zeng</em></li>
  <li><strong>SynWorld: Virtual Scenario Synthesis for Agentic Action Knowledge Refinement</strong><br><em>Runnan Fang, Xiaobin Wang, Yuan Liang, Shuofei Qiao, Jialong Wu, Zekun Xi, Ningyu Zhang, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen</em></li>
  <li><strong>An Empirical Study of Many-to-Many Summarization with Large Language Models</strong><br><em>Jiaan Wang, Fandong Meng, Zengkui Sun, Yunlong Liang, Yuxuan Cao, Jiarong Xu, HAOXIANG SHI, Jie Zhou</em></li>
  <li><strong>Locate-and-Focus: Enhancing Terminology Translation in Speech Language Models</strong><br><em>Suhang Wu, Jialong Tang, Chengyi Yang, Pei Zhang, Baosong Yang, Junhui Li, Min Zhang, Jinsong Su</em></li>
  <li><strong>GuideBench: Benchmarking Domain-Oriented Guideline Following for LLM Agents</strong><br><em>Lingxiao Diao, Xinyue Xu, Wanxuan Sun, Cheng Yang, Zhuosheng Zhang</em></li>
  <li><strong>TC–RAG: Turing–Complete RAG’s Case study on Medical LLM Systems</strong><br><em>Xinke Jiang, Yue Fang, Rihong Qiu, Haoyu Zhang, Yongxin Xu, Hao Chen, WentaoZhang, Ruizhe Zhang, Yuchen Fang, Xinyu Ma, Xu Chu, Junfeng Zhao, Yasha Wang</em></li>
  <li><strong>SoRFT: Issue Resolving with Subtask-oriented Reinforced Fine-Tuning</strong><br><em>Zexiong Ma, Chao Peng, Pengfei Gao, Xiangxin Meng, Yanzhen Zou, Bing Xie</em></li>
  <li><strong>MiniLongBench: The Low-cost Long Context Understanding Benchmark for Large Language Models</strong><br><em>Zhongzhan Huang, Guoming Ling, Shanshan Zhong, Hefeng Wu, Liang Lin</em></li>
  <li><strong>Divide-Then-Align: Honest Alignment based on the Knowledge Boundary of RAG</strong><br><em>Xin Sun, Jianan Xie, Zhongqi Chen, Qiang Liu, Shu Wu, Yuehe Chen, Bowen Song, Zilei Wang, Weiqiang Wang, Liang Wang</em></li>
  <li><strong>PwnGPT: Automatic Exploit Generation Based on Large Language Models</strong><br><em>Wanzong Peng, Lin Ye, Xuetao Du, Hongli Zhang, Dongyang Zhan, Yunting Zhang, Yicheng Guo, Chen Zhang</em></li>
  <li><strong>VMLU Benchmarks: A comprehensive benchmark toolkit for Vietnamese LLMs</strong><br><em>Cuc Thi Bui, Nguyen Truong Son, Truong van trang, Lam Viet Phung, Pham Nhut Huy, Hoang Anh Le, Quoc Huu Van, Phong Nguyen-Thuan Do, Van Le Tran Truc, Duc Thanh Chau, Le-Minh Nguyen</em></li>
  <li><strong>Scaling Laws for RNN LLM in Long-Context Scenarios with State Size</strong><br><em>Kai Liu, Jianfei Gao, Kai Chen</em></li>
  <li><strong>Unifying Continuous and Discrete Text Diffusion with Non-simultaneous Diffusion Processes</strong><br><em>Bocheng Li, Zhujin Gao, Linli Xu</em></li>
  <li><strong>A Strategic Coordination Framework of Small LMs Matches Large LMs in Data Synthesis</strong><br><em>Xin Gao, Qizhi Pei, Zinan Tang, Yu Li, Honglin Lin, Jiang Wu, Lijun Wu, Conghui He</em></li>
  <li><strong>Defining and Evaluating Visual Language Models’ Basic Spatial Abilities: A Perspective from Psychometrics</strong><br><em>Wenrui Xu, Dalin Lyu, Weihang Wang, Jie Feng, Chen Gao, Yong Li</em></li>
  <li><strong>SPHERE: Unveiling Spatial Blind Spots in Vision-Language Models Through Hierarchical Evaluation</strong><br><em>Wenyu Zhang, Wei En Ng, Lixin Ma, Yuwen Wang, Junqi Zhao, Allison Koenecke, Boyang Li, WANGLU</em></li>
  <li><strong>Enhancing Retrieval Systems with Inference-Time Logical Reasoning</strong><br><em>Felix Faltings, Wei Wei, Yujia Bao</em></li>
  <li><strong>Using Subtext to Enhance Generative IDRR</strong><br><em>Zhipang Wang, Yu Hong, Weihao Sun, Guodong Zhou</em></li>
  <li><strong>User-side Model Consistency Monitoring for Open Source Large Language Models Inference Services</strong><br><em>Qijun Miao, Zhixuan Fang</em></li>
  <li><strong>Jailbreaking? One Step Is Enough!</strong><br><em>Weixiong Zheng, Peijian Zeng, YiWei Li, Hongyan Wu, Nankai Lin, Junhao Chen, Aimin Yang, Yongmei Zhou</em></li>
  <li><strong>Parenting: Optimizing Knowledge Selection of Retrieval-Augmented Language Models with Parameter Decoupling and Tailored Tuning</strong><br><em>Yongxin Xu, Ruizhe Zhang, Xinke Jiang, Yujie Feng, Yuzhen Xiao, Xinyu Ma, Runchuan Zhu, Xu Chu, Junfeng Zhao, Yasha Wang</em></li>
  <li><strong>PaSa: An LLM Agent for Comprehensive Academic Paper Search</strong><br><em>Yichen He, Guanhua Huang, Peiyuan Feng, Yuan Lin, Yuchen Zhang, Hang Li, Weinan E</em></li>
  <li><strong>Less Mature is More Adaptable for Sentence-level Language Modeling</strong><br><em>Abhilasha Sancheti, David Dale, Artyom Kozhevnikov, Maha Elbayad</em></li>
  <li><strong>EpMAN: Episodic Memory AttentioN for Generalizing to Longer Contexts</strong><br><em>Subhajit Chaudhury, Payel Das, Sarathkrishna Swaminathan, Georgios Kollias, Elliot Nelson, Khushbu Pahwa, Tejaswini Pedapati, Igor Melnyk, Matthew Riemer</em></li>
  <li><strong>UORA: Uniform Orthogonal Reinitialization Adaptation in Parameter Efficient Fine-Tuning of Large Models</strong><br><em>Xueyan Zhang, Jinman Zhao, Zhifei Yang, Yibo Zhong, Shuhao Guan, Linbo Cao, Yining Wang</em></li>
  <li><strong>Agri-CM$^3$: A Chinese Massive Multi-modal, Multi-level Benchmark for Agricultural Understanding and Reasoning</strong><br><em>Haotian Wang, Yi Guan, Fanshu Meng, Chao Zhao, Lian Yan, Yang Yang, Jingchi Jiang</em></li>
  <li><strong>TROVE: A Challenge for Fine-Grained Text Provenance via Source Sentence Tracing and Relationship Classification</strong><br><em>Junnan Zhu, Min Xiao, Yining Wang, Feifei Zhai, Yu Zhou, Chengqing Zong</em></li>
  <li><strong>CaLMQA: Exploring culturally specific long-form question answering across 23 languages</strong><br><em>Shane Arora, Marzena Karpinska, Hung-Ting Chen, Ipsita Bhattacharjee, Mohit Iyyer, Eunsol Choi</em></li>
  <li><strong>Croppable Knowledge Graph Embedding</strong><br><em>Yushan Zhu, Wen Zhang, Zhiqiang Liu, Mingyang Chen, Lei Liang, Huajun Chen</em></li>
  <li><strong>HyKGE: A Hypothesis Knowledge Graph Enhanced RAG Framework for Accurate and Reliable Medical LLMs Responses</strong><br><em>Xinke Jiang, Ruizhe Zhang, Yongxin Xu, Rihong Qiu, Yue Fang, Zhiyuan Wang, Jinyi Tang, Hongxin Ding, Xu Chu, Junfeng Zhao, Yasha Wang</em></li>
  <li><strong>LongRecipe: Recipe for Efficient Long Context Generalization in Large Language Models</strong><br><em>Zhiyuan Hu, Yuliang Liu, Jinman Zhao, Suyuchen Wang, WangYan, Wei Shen, Qing Gu, Anh Tuan Luu, See-Kiong Ng, Zhiwei Jiang, Bryan Hooi</em></li>
  <li><strong>BeamLoRA: Beam-Constraint Low-Rank Adaptation</strong><br><em>Naibin Gu, Zhenyu Zhang, Xiyu Liu, Peng Fu, Zheng Lin, Shuohuan Wang, Yu Sun, Hua Wu, Weiping Wang, Haifeng Wang</em></li>
  <li><strong>GODBench: A Benchmark for Multimodal Large Language Models in Video Comment Art</strong><br><em>Chenkai Zhang, Yiming Lei, Zeming Liu, Haitao Leng, ShaoGuo Liu, Tingting Gao, Qingjie Liu, Yunhong Wang</em></li>
  <li><strong>UniLR: Unleashing the Power of LLMs on Multiple Legal Tasks with a Unified Legal Retriever</strong><br><em>Ang Li, Yiquan Wu, Yifei Liu, Ming Cai, Lizhi Qing, Shihang Wang, Yangyang Kang, Chengyuan Liu, Fei Wu, Kun Kuang</em></li>
  <li><strong>Generative Psycho-Lexical Approach for Constructing Value Systems in Large Language Models</strong><br><em>Haoran Ye, TianZe Zhang, Yuhang Xie, Liyuan Zhang, Yuanyi Ren, Xin Zhang, Guojie Song</em></li>
  <li><strong>Beyond Dialogue: A Profile-Dialogue Alignment Framework Towards General Role-Playing Language Model</strong><br><em>Yeyong Yu, Runsheng Yu, Haojie Wei, Zhanqiu Zhang, Quan QIAN</em></li>
  <li><strong>ACECODER: Acing Coder RL via Automated Test-Case Synthesis</strong><br><em>Huaye Zeng, Dongfu Jiang, Haozhe Wang, Ping Nie, Xiaotong Chen, Wenhu Chen</em></li>
  <li><strong>Quantifying Semantic Emergence in Language Models</strong><br><em>Hang Chen, Xinyu Yang, Jiaying Zhu, Wenya Wang</em></li>
  <li><strong>DebateCoder: Towards Collective Intelligence of LLMs via Test Case Driven LLM Debate for Code Generation</strong><br><em>Jizheng Chen, Kounianhua Du, Xinyi Dai, Weiming Zhang, Xihuai Wang, Yasheng Wang, Ruiming Tang, Weinan Zhang, Yong Yu</em></li>
  <li><strong>The Tug of War Within: Mitigating the Fairness-Privacy Conflicts in Large Language Models</strong><br><em>Chen Qian, Dongrui Liu, Jie Zhang, Yong Liu, Jing Shao</em></li>
  <li><strong>GraphInsight: Unlocking Insights in Large Language Models for Graph Structure Understanding</strong><br><em>Yukun Cao, Shuo Han, Zengyi Gao, Zezhong Ding, Xike Xie, S Kevin Zhou</em></li>
  <li><strong>Phonotomizer: A Compact, Unsupervised, Online Training Approach to Real-Time, Multilingual Phonetic Segmentation</strong><br><em>Michael S. Yantosca, Albert M. K. Cheng</em></li>
  <li><strong>A Multi-persona Framework for Argument Quality Assessment</strong><br><em>Bojun Jin, Jianzhu Bao, Yufang Hou, Yang Sun, Yice Zhang, Huajie Wang, Bin Liang, Ruifeng Xu</em></li>
  <li><strong>Safe: Enhancing Mathematical Reasoning in Large Language Models via Retrospective Step-aware Formal Verification</strong><br><em>Chengwu Liu, Ye Yuan, Yichun Yin, Yan Xu, Xin Xu, Zaoyu Chen, Lifeng Shang, Qun Liu, Ming Zhang</em></li>
  <li><strong>SAM Decoding: Speculative Decoding via Suffix Automaton</strong><br><em>Yuxuan Hu, Ke Wang, Xiaokang Zhang, Fanjin Zhang, Cuiping Li, Hong Chen, Jing Zhang</em></li>
  <li><strong>PsyAdvisor: A Plug-and-Play Strategy Advice Planner with Proactive Questioning in Psychological Conversations</strong><br><em>Yuxin Hu, Danni Liu, Bo Liu, Yida Chen, Jiuxin Cao, Yan Liu</em></li>
  <li><strong>$HomeBench$: Evaluating LLMs in Smart Homes with Valid and Invalid Instructions Across Single and Multiple Devices</strong><br><em>Silin Li, Yuhang Guo, Jiashu Yao, Zeming Liu, Haifeng Wang</em></li>
  <li><strong>Advancing Zero-shot Text-to-Speech Intelligibility across Diverse Domains via Preference Alignment</strong><br><em>Xueyao Zhang, Yuancheng Wang, Chaoren Wang, Ziniu Li, Zhuo Chen, Zhizheng Wu</em></li>
  <li><strong>GiFT: Gibbs Fine-Tuning for Code Generation</strong><br><em>Haochen Li, Wanjin Feng, Xin Zhou, Zhiqi Shen</em></li>
  <li><strong>Enhancing Interpretable Image Classification Through LLM Agents and Conditional Concept Bottleneck Models</strong><br><em>Yiwen Jiang, Deval Mehta, Wei Feng, Zongyuan Ge</em></li>
  <li><strong>Reliably Bounding False Positives: A Zero-Shot Machine-Generated Text Detection Framework via Multiscaled Conformal Prediction</strong><br><em>Xiaowei Zhu, Yubing Ren, Yanan Cao, Xixun Lin, Fang Fang, Yangxi Li</em></li>
  <li><strong>RSCF: Relation-Semantics Consistent Filter for Entity Embedding of Knowledge Graph</strong><br><em>Junsik Kim, Jinwook Park, Kangil Kim</em></li>
  <li><strong>RolePlot: A Systematic Framework for Evaluating and Enhancing the Plot-Progression Capabilities of Role-Playing Agents</strong><br><em>Pinyi Zhang, Siyu An, Lingfeng Qiao, Yifei Yu, Jingyang Chen, Jie Wang, di yin, Xing Sun, Kai Zhang</em></li>
  <li><strong>TreeRL: LLM Reinforcement Learning with On-Policy Tree Search</strong><br><em>Zhenyu Hou, Ziniu Hu, Yujiang Li, Rui Lu, Jie Tang, Yuxiao Dong</em></li>
  <li><strong>Can a Single Model Master Both Multi-turn Conversations and Tool Use? CALM: A Unified Conversational Agentic Language Model</strong><br><em>Emre Can Acikgoz, Jeremiah Greer, Akul Datta, Ze Yang, William Zeng, Oussama Elachqar, Emmanouil Koukoumidis, Dilek Hakkani-Tür, Gokhan Tur</em></li>
  <li><strong>Single-to-mix Modality Alignment with Multimodal Large Language Model for Document Image Machine Translation</strong><br><em>Yupu Liang, Yaping Zhang, Zhiyang Zhang, Yang Zhao, Lu Xiang, Chengqing Zong, Yu Zhou</em></li>
  <li><strong>SDPO: Segment-Level Direct Preference Optimization for Social Agents</strong><br><em>Aobo Kong, Wentao Ma, Shiwan Zhao, Yongbin Li, Yuchuan Wu, Ke Wang, Xiaoqian Liu, Qicheng Li, Yong Qin, Fei Huang</em></li>
  <li><strong>KokoroChat: A Japanese Psychological Counseling Dialogue Dataset Collected via Role-Playing by Trained Counselors</strong><br><em>Zhiyang Qi, Takumasa Kaneko, Keiko Takamizo, Mariko Ukiyo, Michimasa Inaba</em></li>
  <li><strong>SURVEYFORGE : On the Outline Heuristics, Memory-Driven Generation, and Multi-dimensional Evaluation for Automated Survey Writing</strong><br><em>Xiangchao Yan, Shiyang Feng, Jiakang Yuan, Renqiu Xia, Bin Wang, LEI BAI, Bo Zhang</em></li>
  <li><strong>Making LLMs Better Many-to-Many Speech-to-Text Translators with Curriculum Learning</strong><br><em>Yexing Du, Youcheng Pan, Ziyang Ma, Bo Yang, Yifan Yang, Keqi Deng, Xie Chen, Yang Xiang, Ming Liu, Bing Qin</em></li>
  <li><strong>AbGen: Evaluating Large Language Models in Ablation Study Design and Evaluation for Scientific Research</strong><br><em>Yilun Zhao, Weiyuan Chen, Zhijian Xu, Yixin Liu, Chengye Wang, Manasi Patwardhan, Lovekesh Vig, Arman Cohan</em></li>
  <li><strong>Redundancy Principles for MLLMs Benchmarks</strong><br><em>Zicheng Zhang, Xiangyu Zhao, Xinyu Fang, Chunyi Li, Xiaohong Liu, Xiongkuo Min, Haodong Duan, Kai Chen, Guangtao Zhai</em></li>
  <li><strong>WavRAG: Audio-Integrated Retrieval Augmented Generation for Spoken Dialogue Models</strong><br><em>Yifu Chen, Shengpeng Ji, Haoxiao Wang, Ziqing Wang, Siyu Chen, Jinzheng He, Jin Xu, Zhou Zhao</em></li>
  <li><strong>ChildMandarin: A Comprehensive Mandarin Speech Dataset for Young Children Aged 3-5</strong><br><em>Jiaming Zhou, shiyao wang, Shiwan Zhao, Jiabei He, Haoqin Sun, Hui Wang, Cheng Liu, Aobo Kong, Yujie Guo, Xi Yang, Yequan Wang, Yonghua Lin, Yong Qin</em></li>
  <li><strong>Finding the Sweet Spot: Preference Data Construction for Scaling Preference Optimization</strong><br><em>Yao Xiao, Hai Ye, Linyao Chen, Hwee Tou Ng, Lidong Bing, Xiaoli Li, Roy Ka-Wei Lee</em></li>
  <li><strong>Enhancing Safe and Controllable Protein Generation via Knowledge Preference Optimization</strong><br><em>Yuhao Wang, Keyan Ding, Kehua Feng, Zeyuan Wang, Ming Qin, Xiaotong Li, Qiang Zhang, Huajun Chen</em></li>
  <li><strong>SINCon: Mitigate LLM-Generated Malicious Message Injection Attack for Rumor Detection</strong><br><em>Mingqing Zhang, Qiang Liu, Xiang Tao, Shu Wu, Liang Wang</em></li>
  <li><strong>Outlier-Safe Pre-Training for Robust 4-Bit Quantization of Large Language Models</strong><br><em>Jungwoo Park, Chanwoong Yoon, Hyeon Hwang, Taewhoo Lee, Jaewoo Kang</em></li>
  <li><strong>Agentic Knowledgeable Self-awareness</strong><br><em>Shuofei Qiao, Zhisong Qiu, Baochang Ren, Xiaobin Wang, Xiangyuan Ru, Ningyu Zhang, Xiang Chen, Yong Jiang, Pengjun Xie, Fei Huang, Huajun Chen</em></li>
  <li><strong>A Unified Agentic Framework for Evaluating Conditional Image Generation</strong><br><em>Jifang Wang, Yangxue, Longyue Wang, Zhenran Xu, Yiyu Wang, Yaowei Wang, Weihua Luo, Kaifu Zhang, Baotian Hu, Min zhang</em></li>
  <li><strong>Planning-Driven Programming: A Large Language Model Programming Workflow</strong><br><em>Chao Lei, Yanchuan Chang, Nir Lipovetzky, Krista A. Ehinger</em></li>
  <li><strong>Can Knowledge Graphs Make Large Language Models More Trustworthy? An Empirical Study Over Open-ended Question Answering</strong><br><em>Yuan Sui, Yufei He, Zifeng Ding, Bryan Hooi</em></li>
  <li><strong>Nudging: Inference-time Alignment of LLMs via Guided Decoding</strong><br><em>Yu Fei, Yasaman Razeghi, Sameer Singh</em></li>
  <li><strong>Unveiling Attractor Cycles in Large Language Models: A Dynamical Systems View of Successive Paraphrasing</strong><br><em>Zhilin Wang, Yafu Li, Jianhao Yan, Yu Cheng, Yue Zhang</em></li>
  <li><strong>State-offset Tuning: State-based Parameter-Efficient Fine-Tuning for State Space Models</strong><br><em>Wonjun Kang, Kevin Galim, Yuchen Zeng, Minjae Lee, Hyung Il Koo, Nam Ik Cho</em></li>
  <li><strong>SCAR: Data Selection via Style Consistency-Aware Response Ranking for Efficient Instruction-Tuning of Large Language Models</strong><br><em>Zhuang Li, YUNCHENG HUA, Thuy-Trang Vu, Haolan Zhan, Lizhen Qu, Gholamreza Haffari</em></li>
  <li><strong>Internal and External Impacts of Natural Language Processing Papers</strong><br><em>Yu Zhang</em></li>
  <li><strong>HFT: Half Fine-Tuning for Large Language Models</strong><br><em>Tingfeng Hui, Zhenyu Zhang, Shuohuan Wang, Weiran Xu, Yu Sun, Hua Wu</em></li>
  <li><strong>Beyond Surface Simplicity: Revealing Hidden Reasoning Attributes for Precise Commonsense Diagnosis</strong><br><em>Huijun Lian, Zekai Sun, Keqi Chen, Yingming Gao, Ya Li</em></li>
  <li><strong>From Objectives to Questions: A Planning-based Framework for Educational Mathematical Question Generation</strong><br><em>Cheng Cheng, Zhenya Huang, GuanHao Zhao, Yuxiang Guo, Xin Lin, Jinze Wu, Xin Li, Shijin Wang</em></li>
  <li><strong>RankCoT: Refining Knowledge for Retrieval-Augmented Generation through Ranking Chain-of-Thoughts</strong><br><em>Mingyan Wu, Zhenghao Liu, Yukun Yan, Xinze Li, Shi Yu, Zheni Zeng, Yu Gu, Ge Yu</em></li>
  <li><strong>Lost in Literalism: How Supervised Training Shapes Translationese in LLMs</strong><br><em>Yafu Li, Ronghao Zhang, Zhilin Wang, Huajian Zhang, Leyang Cui, Yongjing Yin, Tong Xiao, Yue Zhang</em></li>
  <li><strong>An Effective Incorporating Heterogeneous Knowledge Curriculum Learning for Sequence Labeling</strong><br><em>Xuemei Tang, Jun Wang, Qi Su, Chu-Ren Huang, Jinghang Gu</em></li>
  <li><strong>Accurate KV Cache Quantization with Outlier Tokens Tracing</strong><br><em>Yi Su, Yuechi Zhou, Quantong Qiu, Juntao Li, Qingrong Xia, Ping Li, Xinyu Duan, Zhefeng Wang, Min Zhang</em></li>
  <li><strong>Can Large Language Models Understand Internet Buzzwords Through User-Generated Content</strong><br><em>Chen Huang, Junkai Luo, Xinzuo Wang, Wenqiang Lei, Jiancheng Lv</em></li>
  <li><strong>EAC-MoE: Expert-Selection Aware Compressor for Mixture-of-Experts Large Language Models</strong><br><em>Yuanteng Chen, Yuantian Shao, Peisong Wang, Jian Cheng</em></li>
  <li><strong>Activation Steering Decoding: Mitigating Hallucination in Large Vision-Language Models through Bidirectional Hidden State Intervention</strong><br><em>Jingran Su, Jingfan CHEN, Hongxin Li, Yuntao Chen, Li Qing, Zhaoxiang Zhang</em></li>
  <li><strong>Interactive Evolution: A Neural-Symbolic Self-Training Framework For Large Language Models</strong><br><em>Fangzhi Xu, Qiushi Sun, Kanzhi Cheng, Jun Liu, Yu Qiao, Zhiyong Wu</em></li>
  <li><strong>Improving Medical Large Vision-Language Models with Abnormal-Aware Feedback</strong><br><em>Yucheng Zhou, Lingran Song, Jianbing Shen</em></li>
  <li><strong>Upcycling Instruction Tuning from Dense to Mixture-of-Experts via Parameter Merging</strong><br><em>Tingfeng Hui, Zhenyu Zhang, Shuohuan Wang, Yu Sun, Hua Wu, Sen Su</em></li>
  <li><strong>MapNav: A Novel Memory Representation via Annotated Semantic Maps for VLM-based Vision-and-Language Navigation</strong><br><em>Lingfeng Zhang, Xiaoshuai Hao, Qinwen Xu, Qiang Zhang, Xinyao Zhang, Pengwei Wang, Jing Zhang, Zhongyuan Wang, Shanghang Zhang, Renjing Xu</em></li>
  <li><strong>Exploring Compositional Generalization of Multimodal LLMs for Medical Imaging</strong><br><em>Zhenyang Cai, Junying Chen, Rongsheng Wang, Weihong Wang, Yonglin Deng, Dingjie Song, Yize Chen, Zixu Zhang, Benyou Wang</em></li>
  <li><strong>CLAIM: Mitigating Multilingual Object Hallucination in Large Vision-Language Models with Cross-Lingual Attention Intervention</strong><br><em>Zekai Ye, Qiming Li, Xiaocheng Feng, Libo Qin, Yichong Huang, Baohang Li, Kui Jiang, Yang Xiang, Zhirui Zhang, Yunfei Lu, Duyu Tang, Dandan Tu, Bing Qin</em></li>
  <li><strong>Wizard of Shopping: Target-Oriented E-commerce Dialogue Generation with Decision Tree Branching</strong><br><em>Xiangci Li, Zhiyu Chen, Jason Ingyu Choi, Nikhita Vedula, Besnik Fetahu, Oleg Rokhlenko, Shervin Malmasi</em></li>
  <li><strong>Multi-Agent Collaboration for Multilingual Code Instruction Tuning</strong><br><em>Jian Yang, Wei Zhang, Yibo Miao, Shanghaoran Quan, Zhenhe Wu, Qiyao Peng, Liqun Yang, Tianyu Liu, Zeyu Cui, Binyuan Hui, Junyang Lin</em></li>
  <li><strong>Cultivating Gaming Sense for Yourself: Making VLMs Gaming Experts</strong><br><em>wenxuan lu, Jiangyang He, Zhanqiu Zhang, Tianning Zang, Steven Y. Guo</em></li>
  <li><strong>Genius: A Generalizable and Purely Unsupervised Self-Training Framework For Advanced Reasoning</strong><br><em>Fangzhi Xu, Hang Yan, Chang Ma, Haiteng Zhao, Qiushi Sun, Kanzhi Cheng, Junxian He, Jun Liu, Zhiyong Wu</em></li>
  <li><strong>Accelerating Dense LLMs via L0-regularized Mixture-of-Experts</strong><br><em>Zhenyu Zhang, JiuDong Yang, taozhaowen, Meng Chen</em></li>
  <li><strong>Extending Complex Logical Queries on Uncertain Knowledge Graphs</strong><br><em>Weizhi Fei, Zihao Wang, Hang Yin, Yang Duan, Yangqiu Song</em></li>
  <li><strong>Knowledge Decoupling via Orthogonal Projection for Lifelong Editing of Large Language Models</strong><br><em>Haoyu Xu, Pengxiang Lan, Enneng Yang, Guibing Guo, Jianzhe Zhao, Linying Jiang, Xingwei Wang</em></li>
  <li><strong>$\phi$-Decoding: Adaptive Foresight Sampling for Balanced Inference-Time Exploration and Exploitation</strong><br><em>Fangzhi Xu, Hang Yan, Chang Ma, Haiteng Zhao, Jun Liu, Qika Lin, Zhiyong Wu</em></li>
  <li><strong>Can LLM Watermarks Robustly Prevent Unauthorized Knowledge Distillation?</strong><br><em>Leyi Pan, Aiwei Liu, Shiyu Huang, Yijian LU, Xuming Hu, Lijie Wen, Irwin King, Philip S. Yu</em></li>
  <li><strong>Rethinking Reward Model Evaluation Through the Lens of Reward Overoptimization</strong><br><em>Sunghwan Kim, Dongjin Kang, Taeyoon Kwon, Hyungjoo Chae, Dongha Lee, Jinyoung Yeo</em></li>
  <li><strong>LISTN: Lexicon induction with socio-temporal nuance</strong><br><em>Christine de Kock</em></li>
  <li><strong>LLaSE-G1: Incentivizing Generalization Capability for LLaMA-based Speech Enhancement</strong><br><em>Boyi Kang, Xinfa Zhu, Zihan Zhang, Zhen Ye, Mingshuai Liu, Ziqian Wang, Yike Zhu, Guobin Ma, Jun Chen, Longshuai Xiao, CHAO WENG, Wei Xue, Lei Xie</em></li>
  <li><strong>MadaKV: Adaptive Modality-Perception KV Cache Eviction for Efficient Multimodal Long-Context Inference</strong><br><em>Kunxi Li, Zhonghua Jiang, Zhouzhou Shen, ZhaodeWang, chengfei lv, Shengyu Zhang, Fan Wu, Fei Wu</em></li>
  <li><strong>Efficient OpAmp Adaptation for Zoom Attention to Golden Contexts</strong><br><em>Haoyuan Wu, Rui Ming, Haisheng Zheng, Zhuolun He, Bei Yu</em></li>
  <li><strong>Bridging Discrete Codec Representations and Speech Language Models</strong><br><em>Shengpeng Ji, Minghui Fang, Jialong Zuo, Ziyue Jiang, Dingdong WANG, Hanting Wang, Hai Huang, Zhou Zhao</em></li>
  <li><strong>Adaptive Tool Use in Large Language Models with Meta-Cognition Trigger</strong><br><em>Wenjun Li, Dexun Li, Kuicai Dong, Cong Zhang, Hao Zhang, Weiwen Liu, Yasheng Wang, Ruiming Tang, Yong Liu</em></li>
  <li><strong>MMLU-CF: A Contamination-free Multi-task Language Understanding Benchmark</strong><br><em>Qihao Zhao, Yangyu Huang, Tengchao Lv, Lei Cui, Qinzheng Sun, Shaoguang Mao, Xin Zhang, Ying Xin, Qiufeng Yin, Scarlett Li, Furu Wei</em></li>
  <li><strong>Code-Switching Red-Teaming: LLM Evaluation for Safety and Multilingual Understanding</strong><br><em>Haneul Yoo, Yongjin Yang, Hwaran Lee</em></li>
  <li><strong>Unleashing LLM Reasoning Capability via Scalable Question Synthesis from Scratch</strong><br><em>Yuyang Ding, Xinyu Shi, Xiaobo Liang, Juntao Li, Zhaopeng Tu, Qiaoming Zhu, Min Zhang</em></li>
  <li><strong>DREsS: Dataset for Rubric-based Essay Scoring on EFL Writing</strong><br><em>Haneul Yoo, Jieun Han, So-Yeon Ahn, Alice Oh</em></li>
  <li><strong>PQR: Improving Dense Retrieval via Potential Query Modeling</strong><br><em>Junfeng Kang, Rui Li, Qi Liu, Yanjiang Chen, Zheng Zhang, Junzhe Jiang, Heng Yu, Yu Su</em></li>
  <li><strong>Do Multimodal Large Language Models Truly See What We Point At? Investigating Indexical, Iconic, and Symbolic Gesture Comprehension</strong><br><em>Noriki Nishida, Koji Inoue, Hideki Nakayama, Mayumi Bono, Katsuya Takanashi</em></li>
  <li><strong>Cross-lingual Generalization and Compression: From Language-Specific to Shared Neurons</strong><br><em>Frederick Riemenschneider, Anette Frank</em></li>
  <li><strong>SDBench: A Survey-based Domain-specific LLM Benchmarking and Optimization Framework</strong><br><em>Cheng Guo, Hu Kai, Shuxian Liang, Yiyang Jiang, Yi Gao, Xian-Sheng Hua, Wei Dong</em></li>
  <li><strong>ReflecTool: Towards Reflection-Aware Tool-Augmented Clinical Agents</strong><br><em>Yusheng Liao, Shuyang Jiang, Yanfeng Wang, Yu Wang</em></li>
  <li><strong>Lexical Recall or Logical Reasoning: Probing the Limits of Reasoning Abilities in Large Language Models</strong><br><em>Henrike Beyer, Chris Reed</em></li>
  <li><strong>ChainEdit: Propagating Ripple Effects through Logical Rule-Guided Chain Updates</strong><br><em>Zilu dong, Xiangqing Shen, Zinong Yang, Rui Xia</em></li>
  <li><strong>HiDe-LLaVA: Hierarchical Decoupling for Continual Instruction Tuning of Multimodal Large Language Model</strong><br><em>Haiyang Guo, Fanhu Zeng, Ziwei Xiang, Fei Zhu, Da-Han Wang, Xu-Yao Zhang, Cheng-Lin Liu</em></li>
  <li><strong>Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models</strong><br><em>Qika Lin, Tianzhe Zhao, Kai He, Zhen Peng, Fangzhi Xu, Ling Huang, Jingying Ma, Mengling Feng</em></li>
  <li><strong>Finite State Automata Inside Transformers with Chain-of-Thought: A Mechanistic Study on State Tracking</strong><br><em>Yifan Zhang, Wenyu Du, Dongming Jin, Jie Fu, Zhi Jin</em></li>
  <li><strong>TeamLoRA: Boosting Low-Rank Adaptation with Expert Collaboration and Competition</strong><br><em>Tianwei Lin, Jiang Liu, Wenqiao Zhang, Yang Dai, Haoyuan Li, Zhelun Yu, Wanggui He, Juncheng Li, Jiannan Guo, Hao Jiang, Siliang Tang, Yueting Zhuang</em></li>
  <li><strong>CRiskEval: A Chinese Multi-Level Risk Evaluation Benchmark Dataset for Large Language Models</strong><br><em>Ling Shi, Deyi Xiong</em></li>
  <li><strong>STUN: Structured-Then-Unstructured Pruning for Scalable MoE Pruning</strong><br><em>Jaeseong Lee, seung-won hwang, Aurick Qiao, Daniel F Campos, Zhewei Yao, Yuxiong He</em></li>
  <li><strong>Mimicking the Familiar: Dynamic Command Generation for Information Theft Attacks in LLM Tool-Learning System</strong><br><em>Ziyou Jiang, Mingyang Li, Guowei Yang, Junjie Wang, Yuekai Huang, Zhiyuan Chang, Qing Wang</em></li>
  <li><strong>FlashAudio: Rectified Flow for Fast and High-Fidelity Text-to-Audio Generation</strong><br><em>Huadai Liu, Jialei Wang, Rongjie Huang, Yang Liu, Heng Lu, Wei Xue, Zhou Zhao</em></li>
  <li><strong>How does Misinformation Affect Large Language Model Behaviors and Preferences?</strong><br><em>Miao Peng, Nuo Chen, Jianheng Tang, Jia Li</em></li>
  <li><strong>YESciEval: Robust LLM-as-a-Judge for Scientific Question Answering</strong><br><em>Jennifer D’Souza, Hamed Babaei Giglou, Quentin Münch</em></li>
  <li><strong>GALLa: Graph Aligned Large Language Models for Improved Source Code Understanding</strong><br><em>Ziyin Zhang, Hang Yu, Sage Lee, Peng Di, Jianguo Li, Rui Wang</em></li>
  <li><strong>MEDDxAgent: A Unified Modular Agent Framework for Explainable Automatic Differential Diagnosis</strong><br><em>Daniel Philip Rose, Chia-Chien Hung, Marco Lepri, Israa Alqassem, Kiril Gashteovski, Carolin Lawrence</em></li>
  <li><strong>A Training-free LLM-based Approach to General Chinese Character Error Correction</strong><br><em>Houquan Zhou, Bo Zhang, Zhenghua Li, Ming Yan, Min Zhang</em></li>
  <li><strong>HSCR: Hierarchical Self-Contrastive Rewarding for Aligning Medical Vision Language Models</strong><br><em>Songtao Jiang, Yan Zhang, Yeying Jin, Zhihang Tang, Yangyang Wu, YANG FENG, Jian Wu, Zuozhu Liu</em></li>
  <li><strong>MAmmoTH-VL: Eliciting Multimodal Reasoning with Instruction Tuning at Scale</strong><br><em>Jiawei Guo, Tianyu Zheng, Yizhi LI, Yuelin Bai, Bo Li, Yubo Wang, King Zhu, Graham Neubig, Wenhu Chen, Xiang Yue</em></li>
  <li><strong>SIFT-50M: A Large-Scale Multilingual Dataset for Speech Instruction Fine-Tuning</strong><br><em>Prabhat Pandey, Rupak Vignesh Swaminathan, K V Vijay Girish, Arunasish Sen, Jian. Xie, Grant Strimel, Andreas Schwarz</em></li>
  <li><strong>Recent Advances in Speech Language Models: A Survey</strong><br><em>Wenqian Cui, Dianzhi Yu, Xiaoqi Jiao, Ziqiao Meng, Guangyan Zhang, Qichao Wang, Steven Y. Guo, Irwin King</em></li>
  <li><strong>LexCLiPR: Cross-Lingual Paragraph Retrieval from Legal Judgments</strong><br><em>Rohit Upadhya, Santosh T.Y.S.S</em></li>
  <li><strong>Multi-task Adversarial Attacks against Black-box Model with Few-shot Queries</strong><br><em>Wenqiang Wang, Yan XIAO, Hao Lin, Yangshijie Zhang, Xiaochun Cao</em></li>
  <li><strong>SPECTRA: Faster Large Language Model Inference with Optimized Internal and External Speculation</strong><br><em>Nguyen-Khang Le, Truong Dinh Do, Le-Minh Nguyen</em></li>
  <li><strong>Multi-level Association Refinement Network for Dialogue Aspect-based Sentiment Quadruple Analysis</strong><br><em>Zeliang Tong, Wei Wei, Xiaoye Qu, Rikui Huang, Zhixin Chen, Xingyu Yan</em></li>
  <li><strong>Innovative Image Fraud Detection with Cross-Sample Anomaly Analysis: The Power of LLMs</strong><br><em>QiWen Wang, Zhenghao Lin, Chen Lin, Junqi Yang, Zhenzhe Ying, Weiqiang Wang</em></li>
  <li><strong>Cooperative or Competitive? Understanding the Interaction between Attention Heads From A Game Theory Perspective</strong><br><em>Xiaoye Qu, Zengqi Yu, Dongrui Liu, Wei Wei, Daizong Liu, Jianfeng Dong, Yu Cheng</em></li>
  <li><strong>MM-Verify: Enhancing Multimodal Reasoning with Chain-of-Thought Verification</strong><br><em>Linzhuang Sun, Hao Liang, Jingxuan Wei, Bihui Yu, Tianpeng Li, Fan Yang, Zenan Zhou, Wentao Zhang</em></li>
  <li><strong>Graph-Structured Trajectory Extraction from Travelogues</strong><br><em>Aitaro Yamamoto, Hiroyuki Otomo, Hiroki Ouchi, Shohei Higashiyama, Hiroki Teranishi, Hiroyuki Shindo, Taro Watanabe</em></li>
  <li><strong>Learning First-Order Logic Rules for Argumentation Mining</strong><br><em>Yang Sun, Guanrong Chen, Hamid Alinejad-Rokny, Jianzhu Bao, Yuqi Huang, Bin Liang, Kam-Fai Wong, Min Yang, Ruifeng Xu</em></li>
  <li><strong>Investigating and Enhancing the Robustness of Large Multimodal Models Against Temporal Inconsistency</strong><br><em>Jiafeng Liang, Shixin Jiang, Xuan Dong, Ning Wang, Zheng Chu, Hui Su, Jinlan Fu, Ming Liu, See-Kiong Ng, Bing Qin</em></li>
  <li><strong>UniRAG: Unified Query Understanding Method for Retrieval Augmented Generation</strong><br><em>Rui Li, Liyang He, Qi Liu, Zheng Zhang, Heng Yu, Yuyang Ye, Linbo Zhu, Yu Su</em></li>
  <li><strong>Contextual Experience Replay for Continual Learning of Language Agents</strong><br><em>Yitao Liu, Chenglei Si, Karthik R Narasimhan, Shunyu Yao</em></li>
  <li><strong>Emma-X: An Embodied Multimodal Action Model with Grounded Chain of Thought and Look-ahead Spatial Reasoning</strong><br><em>Qi Sun, Pengfei Hong, Tej Deep Pala, Vernon Toh, U-Xuan Tan, Deepanway Ghosal, Soujanya Poria</em></li>
  <li><strong>Towards Comprehensive Argument Analysis in Education: Dataset, Tasks, and Method</strong><br><em>Yupei Ren, Xinyi Zhou, Ning Zhang, Shangqing Zhao, Man Lan, Xiaopeng Bai</em></li>
  <li><strong>Browsing Like Human: A Multimodal Web Agent with Experiential Fast-and-Slow Thinking</strong><br><em>Haohao Luo, Jiayi Kuang, Wei Liu, Ying Shen, Jian Luan, Yang Deng</em></li>
  <li><strong>MaXIFE: Multilingual and Cross-lingual Instruction Following Evaluation</strong><br><em>Yile Liu, Ziwei Ma, Xiu Jiang, Jinglu HU, ChangJing, Liang Li</em></li>
  <li><strong>Linguistic Generalizability of Test-Time Scaling in Mathematical Reasoning</strong><br><em>Guijin Son, Jiwoo Hong, Hyunwoo Ko, James Thorne</em></li>
  <li><strong>Can MLLMs Understand the Deep Implication Behind Chinese Images?</strong><br><em>Chenhao Zhang, Xi Feng, Yuelin Bai, Xeron Du, Jinchang Hou, Kaixin Deng, Guangzeng Han, Qinrui Li, Bingli Wang, Jiaheng Liu, Xingwei Qu, Yifei Zhang, Qixuan Zhao, Yiming Liang, Ziqiang Liu, Feiteng Fang, Min Yang, Wenhao Huang, Chenghua Lin, Ge Zhang, Shiwen Ni</em></li>
  <li><strong>KazMMLU: Evaluating Language Models on Kazakh, Russian, and Regional Knowledge of Kazakhstan</strong><br><em>Mukhammed Togmanov, Nurdaulet Mukhituly, Diana Turmakhan, Jonibek Mansurov, Maiya Goloburda, Akhmed Sakip, Zhuohan Xie, Yuxia Wang, Bekassyl Syzdykov, Nurkhan Laiyk, Alham Fikri Aji, Ekaterina Kochmar, Preslav Nakov, Fajri Koto</em></li>
  <li><strong>Fast or Slow? Integrating Fast Intuition and Deliberate Thinking for Enhancing Visual Question Answering</strong><br><em>Songtao Jiang, Chenyi Zhou, Yan Zhang, Yeying Jin, Zuozhu Liu</em></li>
  <li><strong>Towards Multi-dimensional Evaluation of LLM Summarization across Domains and Languages</strong><br><em>Hyangsuk Min, Yuho Lee, Minjeong Ban, Jiaqi Deng, Nicole Hee-Yeon Kim, Taewon Yun, Hang Su, Jason Cai, Hwanjun Song</em></li>
  <li><strong>ClusterAttn: KV Cache Compression under Intrinsic Attention Clustering</strong><br><em>Minwei Zhang, Haifeng Sun, Jingyu Wang, Shaolong Li, Wanyi Ning, Qi Qi, Zirui Zhuang, Jianxin Liao</em></li>
  <li><strong>SHARE: Shared Memory-Aware Open-Domain Long-Term Dialogue Dataset Constructed from Movie Script</strong><br><em>Eunwon Kim, Chanho Park, Buru Chang</em></li>
  <li><strong>Incongruity-aware Tension Field Network for Multi-modal Sarcasm Detection</strong><br><em>Jiecheng Zhang, C.L.Philip Chen, Shuzhen Li, Tong Zhang</em></li>
  <li><strong>Instruction Tuning on Public Government and Cultural Data for Low-Resource Language: a Case Study in Kazakh</strong><br><em>Nurkhan Laiyk, Daniil Orel, Rituraj Joshi, Maiya Goloburda, Yuxia Wang, Preslav Nakov, Fajri Koto</em></li>
  <li><strong>Stealing Training Data from Large Language Models in Decentralized Training through Activation Inversion Attack</strong><br><em>Chenxi Dai, Lin Lu, Pan Zhou</em></li>
  <li><strong>From Selection to Generation: A Survey of LLM-based Active Learning</strong><br><em>Yu Xia, Subhojyoti Mukherjee, Zhouhang Xie, Junda Wu, Xintong Li, Ryan Aponte, Hanjia Lyu, Joe Barrow, Hongjie Chen, Franck Dernoncourt, Branislav Kveton, Tong Yu, Ruiyi Zhang, Jiuxiang Gu, Nesreen K. Ahmed, Yu Wang, Xiang Chen, Hanieh Deilamsalehy, Sungchul Kim, Zhengmian Hu, Yue Zhao, Nedim Lipka, Seunghyun Yoon, Ting-Hao Kenneth Huang, Zichao Wang, Puneet Mathur, Soumyabrata Pal, Koyel Mukherjee, Zhehao Zhang, Namyong Park, Thien Huu Nguyen, Jiebo Luo, Ryan A. Rossi, Julian McAuley</em></li>
  <li><strong>OmniFlatten: An End-to-end GPT Model for Seamless Voice Conversation</strong><br><em>Qinglin Zhang, Luyao Cheng, Chong Deng, Qian Chen, Wen Wang, Siqi Zheng, Jiaqing Liu, Hai Yu, Chao-Hong Tan, Zhihao Du, ShiLiang Zhang</em></li>
  <li><strong>DoMIX: An Efficient Framework for Exploiting Domain Knowledge in Fine-Tuning</strong><br><em>Dohoon Kim, Donghun Kang, Taesup Moon</em></li>
  <li><strong>EAGLE: Expert-Guided Self-Enhancement for Preference Alignment in Pathology Large Vision-Language Model</strong><br><em>Meidan Ding, Jipeng Zhang, Wenxuan Wang, Haiqin Zhong, Xiaoqin Wang, XINHENG LYU, Wenting Chen, Linlin Shen</em></li>
  <li><strong>CoT-ICL Lab: A Petri Dish for Studying Chain-of-Thought Learning from In-Context Demonstrations</strong><br><em>Vignesh Kothapalli, Hamed Firooz, Maziar Sanjabi</em></li>
  <li><strong>Flexora: Flexible Low-Rank Adaptation for Large Language Models</strong><br><em>Chenxing Wei, Yao Shu, Ying Tiffany He, Fei Yu</em></li>
  <li><strong>QDTSynth: Quality-Driven Formal Theorem Synthesis for Enhancing Proving Performance of LLMs</strong><br><em>Lei Wang, Ruobing Zuo, Gaolei He, Jianlin Wang, Zhengfeng Yang</em></li>
  <li><strong>RSVP: Reasoning Segmentation via Visual Prompting and Multi-modal Chain-of-Thought</strong><br><em>Yi Lu, Jiawang Cao, Yongliang Wu, Bozheng Li, Licheng Tang, Yangguang Ji, Chong Wu, Jay Wu, Wenbo Zhu</em></li>
  <li><strong>QAEval: Mixture of Evaluators for Question-Answering Task Evaluation</strong><br><em>Tan Yue, Rui Mao, xuzhao Shi, SHUO ZHAN, Zuhao Yang, Dongyan Zhao</em></li>
  <li><strong>Debiasing the Fine-Grained Classification Task in LLMs with Bias-Aware PEFT</strong><br><em>Daiying Zhao, Xinyu Yang, Hang Chen</em></li>
  <li><strong>Demystifying Small Language Models for Edge Deployment</strong><br><em>Zhenyan Lu, Xiang Li, Dongqi Cai, Rongjie Yi, Fangming Liu, Wei Liu, Jian Luan, Xiwen Zhang, Nicholas D. Lane, Mengwei Xu</em></li>
  <li><strong>Adapt Once, Thrive with Updates: Transferable Parameter-Efficient Fine-Tuning on Evolving Base Models</strong><br><em>Naibin Gu, Peng Fu, Xiyu Liu, Ke Ma, Zheng Lin, Weiping Wang</em></li>
  <li><strong>Can Vision-Language Models Evaluate Handwritten Math?</strong><br><em>Oikantik Nath, Hanani Bathina, Mohammed Safi Ur Rahman Khan, Mitesh M Khapra</em></li>
  <li><strong>Continual Gradient Low-Rank Projection Fine-Tuning for LLMs</strong><br><em>Chenxu Wang, Yilin Lyu, Zicheng Sun, Liping Jing</em></li>
  <li><strong>Towards Objective Fine-tuning: How LLMs’ Prior Knowledge Causes Potential Poor Calibration?</strong><br><em>Ziming Wang, Zeyu Shi, Haoyi Zhou, Shiqi Gao, Qingyun Sun, Jianxin Li</em></li>
  <li><strong>Can Community Notes Replace Professional Fact-Checkers?</strong><br><em>Nadav Borenstein, Greta Warren, Desmond Elliott, Isabelle Augenstein</em></li>
  <li><strong>Towards Robust ESG Analysis Against Greenwashing Risks: Aspect-Action Analysis with Cross-Category Generalization</strong><br><em>Keane Ong, Rui Mao, Deeksha varshney, Erik Cambria, Gianmarco Mengaldo</em></li>
  <li><strong>HiddenDetect: Detecting Jailbreak Attacks against Multimodal Large Language Models via Monitoring Hidden States</strong><br><em>Yilei Jiang, Xinyan Gao, Tianshuo Peng, Yingshui Tan, Xiaoyong Zhu, Bo Zheng, Xiangyu Yue</em></li>
  <li><strong>SwiLTra-Bench: The Swiss Legal Translation Benchmark</strong><br><em>Joel Niklaus, Jakob Merane, Luka Nenadic, Sina Ahmadi, Yingqiang Gao, Cyrill A. H. Chevalley, Claude Humbel, Christophe Gösken, Lorenzo Tanzi, Thomas Lüthi, Stefan Palombo, Spencer Poff, Boling Yang, Nan Wu, Matthew Guillod, Robin Mamié, Daniel Brunner, Julio Pereyra, Niko Grupen</em></li>
  <li><strong>Two Intermediate Translations Are Better Than One: Fine-tuning LLMs for Document-level Translation Refinement</strong><br><em>Yichen Dong, Xinglin Lyu, Junhui Li, Daimeng Wei, Min Zhang, Shimin Tao, Hao Yang</em></li>
  <li><strong>Circuit Compositions: Exploring Modular Structures in Transformer-Based Language Models</strong><br><em>Philipp Mondorf, Sondre Wold, Barbara Plank</em></li>
  <li><strong>Can LLMs Ground when they (Don’t) Know: A Study on Direct and Loaded Political Questions</strong><br><em>Clara Lachenmaier, Judith Sieker, Sina Zarrieß</em></li>
  <li><strong>GraphCheck: Breaking Long-Term Text Barriers with Extracted Knowledge Graph-Powered Fact-Checking</strong><br><em>Yingjian Chen, Haoran Liu, Yinhong Liu, Jinxiang Xie, Rui Yang, Han Yuan, Yanran Fu, Peng Yuan Zhou, Qingyu Chen, James Caverlee, Irene Li</em></li>
  <li><strong>SCULPT: Systematic Tuning of Long Prompts</strong><br><em>Shanu Kumar, Akhila Yesantarao Venkata, Shubhanshu Khandelwal, Bishal Santra, Parag Agrawal, Manish Gupta</em></li>
  <li><strong>Crab: A Novel Configurable Role-Playing LLM with Assessing Benchmark</strong><br><em>Kai He, Yucheng Huang, Wenqing Wang, Delong Ran, Dongming Sheng, Junxuan Huang, Qika Lin, Jiaxing Xu, Wenqiang Liu, Mengling Feng</em></li>
  <li><strong>Chinese SafetyQA: A Safety Short-form Factuality Benchmark for Large Language Models</strong><br><em>Yingshui Tan, Boren Zheng, Baihui Zheng, Kerui Cao, Huiyun Jing, Jincheng Wei, Jiaheng Liu, Yancheng He, Wenbo Su, Xiaoyong Zhu, Bo Zheng, Kaifu Zhang</em></li>
  <li><strong>TRIDENT: Enhancing Large Language Model Safety with Tri-Dimensional Diversified Red-Teaming Data Synthesis</strong><br><em>Xiaorui Wu, Xiaofeng Mao, Fei Li, Xin Zhang, Donghong Ji, Chong Teng, Xuanhong Li, Zhuang Li</em></li>
  <li><strong>Cross-Lingual Optimization for Language Transfer in Large Language Models</strong><br><em>Jungseob Lee, Seongtae Hong, Hyeonseok Moon, Heuiseok Lim</em></li>
  <li><strong>ACE: A Generative Cross-Modal Retrieval Framework With Coarse-To-Fine Semantic Modeling</strong><br><em>Minghui Fang, Shengpeng Ji, Jialong Zuo, Hai Huang, Yan Xia, Jieming Zhu, Xize Cheng, Xiaoda Yang, Wenrui Liu, Gang Wang, Zhenhua Dong, Zhou Zhao</em></li>
  <li><strong>MMMU-Pro: A More Robust Multi-discipline Multimodal Understanding Benchmark</strong><br><em>Xiang Yue, Tianyu Zheng, Yuansheng Ni, Yubo Wang, Kai Zhang, Shengbang Tong, Yuxuan Sun, Botao Yu, Ge Zhang, Huan Sun, Yu Su, Wenhu Chen, Graham Neubig</em></li>
  <li><strong>Cheems: A Practical Guidance for Building and Evaluating Chinese Reward Models from Scratch</strong><br><em>Xueru Wen, Jie Lou, Zichao Li, Yaojie Lu, XingYu, Yuqiu Ji, Guohai Xu, Hongyu Lin, Ben He, Xianpei Han, Le Sun, Debing Zhang</em></li>
  <li><strong>Why Safeguarded Ships Run Aground? Aligned Large Language Models’ Safety Mechanisms Tend to Be Anchored in The Template Region</strong><br><em>Chak Tou Leong, Qingyu Yin, Jian Wang, Wenjie Li</em></li>
  <li><strong>LLaVA Steering: Visual Instruction Tuning with 500x Fewer Parameters through Modality Linear Representation-Steering</strong><br><em>Jinhe Bi, Yujun Wang, Haokun Chen, Xun Xiao, Artur Hecker, Volker Tresp, Yunpu Ma</em></li>
  <li><strong>Efficient Long Context Language Model Retrieval with Compression</strong><br><em>Minju Seo, Jinheon Baek, Seongyun Lee, Sung Ju Hwang</em></li>
  <li><strong>Ontology-Guided Reverse Thinking Makes Large Language Models Stronger on Knowledge Graph Question Answering</strong><br><em>Runxuan Liu, luobei, Jiaqi Li, Baoxin Wang, Ming Liu, Dayong Wu, Shijin Wang, Bing Qin</em></li>
  <li><strong>Towards Omni-RAG: Comprehensive Retrieval-Augmented Generation for Large Language Models in Medical Applications</strong><br><em>Zhe Chen, Yusheng Liao, Shuyang Jiang, Pingjie Wang, YiQiu Guo, Yanfeng Wang, Yu Wang</em></li>
  <li><strong>Predicting Turn-Taking and Backchannel in Human-Machine Conversations Using Linguistic, Acoustic, and Visual Signals</strong><br><em>Yuxin Lin, Yinglin Zheng, Ming Zeng, Wangzheng Shi</em></li>
  <li><strong>A New Formulation of Zipf’s Meaning-Frequency Law through Contextual Diversity</strong><br><em>Ryo Nagata, Kumiko Tanaka-Ishii</em></li>
  <li><strong>The Mirage of Model Editing: Revisiting Evaluation in the Wild</strong><br><em>Wanli Yang, Fei Sun, Jiajun Tan, Xinyu Ma, Qi Cao, Dawei Yin, Huawei Shen, Xueqi Cheng</em></li>
  <li><strong>LAQuer: Localized Attribution Queries in Content-grounded Generation</strong><br><em>Eran Hirsch, Aviv Slobodkin, David Wan, Elias Stengel-Eskin, Mohit Bansal, Ido Dagan</em></li>
  <li><strong>EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning</strong><br><em>Xiaoqian Liu, Ke Wang, Yongbin Li, Yuchuan Wu, Wentao Ma, Aobo Kong, Fei Huang, Jianbin Jiao, Junge Zhang</em></li>
  <li><strong>DCG-SQL: Enhancing In-Context Learning for Text-to-SQL with Deep Contextual Schema Link Graph</strong><br><em>Jihyung Lee, Jin-Seop Lee, Jaehoon Lee, YunSeok Choi, Jee-Hyong Lee</em></li>
  <li><strong>Multilingual Gloss-free Sign Language Translation: Towards Building a Sign Language Foundation Model</strong><br><em>Sihan Tan, Taro Miyazaki, Kazuhiro Nakadai</em></li>
  <li><strong>PreP-OCR: A Complete Pipeline for Document Image Restoration and Enhanced OCR Accuracy</strong><br><em>Shuhao Guan, Moule Lin, Cheng Xu, Xinyi Liu, Jinman Zhao, Jiexin Fan, Qi Xu, Derek Greene</em></li>
  <li><strong>Digest the Knowledge: Large Language Models empowered Message Passing for Knowledge Graph Question Answering</strong><br><em>Junhong Wan, Tao Yu, Kunyu Jiang, Yao Fu, Weihao Jiang, Jiang Zhu</em></li>
  <li><strong>RecLM: Recommendation Instruction Tuning</strong><br><em>Yangqin Jiang, Yuhao Yang, Lianghao Xia, Da Luo, Kangyi Lin, Chao Huang</em></li>
  <li><strong>DS$^2$-ABSA: Dual-Stream Data Synthesis with Label Refinement for Few-Shot Aspect-Based Sentiment Analysis</strong><br><em>Hongling Xu, Yice Zhang, Qianlong Wang, Ruifeng Xu</em></li>
  <li><strong>MISP-Meeting: A Real-World Dataset with Multimodal Cues for Long-form Meeting Transcription and Summarization</strong><br><em>HangChen, Chao-Han Huck Yang, Jia-Chen Gu, Hongxu Yin, Sabato Marco Siniscalchi, Jun Du</em></li>
  <li><strong>Learning Together to Perform Better: Teaching Small-Scale LLMs to Collaborate via Preferential Rationale Tuning</strong><br><em>Sohan Patnaik, Milan Aggarwal, Sumit Bhatia, Balaji Krishnamurthy</em></li>
  <li><strong>MolRAG: Unlocking the Power of Large Language Models for Molecular Property Prediction</strong><br><em>Ziting Xian, Jiawei Gu, Lingbo Li, Eran Segal, Shangsong Liang</em></li>
  <li><strong>SkillAggregation: Reference-free LLM-Dependent Aggregation</strong><br><em>Guangzhi Sun, Anmol Kagrecha, Potsawee Manakul, Phil Woodland, Mark Gales</em></li>
  <li><strong>MasRouter: Learning to Route LLMs for Multi-Agent Systems</strong><br><em>Yanwei Yue, Guibin Zhang, Boyang Liu, Guancheng Wan, Kun Wang, Dawei Cheng, Yiyan Qi</em></li>
  <li><strong>Beyond Single Labels: Improving Conversational Recommendation through LLM-Powered Data Augmentation</strong><br><em>Haozhe Xu, Xiaohua Wang, Changze Lv, Xiaoqing Zheng</em></li>
  <li><strong>Beyond One-Size-Fits-All: Tailored Benchmarks for Efficient Evaluation</strong><br><em>Peiwen Yuan, Yueqi Zhang, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Jiayi Shi, Chuyi Tan, Boyuan Pan, Yao Hu, Kan Li</em></li>
  <li><strong>Advancing Sequential Numerical Prediction in Autoregressive Models</strong><br><em>Xiang Fei, Jinghui Lu, Qi Sun, Hao Feng, Yanjie Wang, Wei Shi, An-Lan Wang, Jingqun Tang, Can Huang</em></li>
  <li><strong>iQUEST: An Iterative Question-Guided Framework for Knowledge Base Question Answering</strong><br><em>Shuai Wang, Yinan Yu</em></li>
  <li><strong>IRT-Router: Effective and Interpretable Multi-LLM Routing via Item Response Theory</strong><br><em>Wei Song, Zhenya Huang, Cheng Cheng, Weibo Gao, Bihan Xu, GuanHao Zhao, Fei Wang, Runze Wu</em></li>
  <li><strong>MLAS-LoRA: Language-Aware Parameters Detection and LoRA-Based Knowledge Transfer for Multilingual Machine Translation</strong><br><em>Tianyu Dong, Bo Li, Jinsong Liu, shaolin Zhu, Deyi Xiong</em></li>
  <li><strong>M2RC-EVAL: Massively Multilingual Repository-level Code Completion Evaluation</strong><br><em>Jiaheng Liu, Ken Deng, Congnan Liu, Jian Yang, Shukai Liu, He Zhu, Peng Zhao, Linzheng Chai, Yanan Wu, Ge Zhang, Yingshui Tan, Zekun Moore Wang, JinKe, Zhaoxiang Zhang, Bangyu Xiang, Guoan Zhang, Wenbo Su, Bo Zheng</em></li>
  <li><strong>Evaluating Design Decisions for Dual Encoder-based Entity Disambiguation</strong><br><em>Susanna Rücker, Alan Akbik</em></li>
  <li><strong>How to Compare Things Properly? A Study on Answering Comparative Questions using Argument Summarization</strong><br><em>Irina Nikishina, Saba Anwar, Nikolay Dolgov, Maria Manina, Daria Ignatenko, Artem Shelmanov, Chris Biemann</em></li>
  <li><strong>FinanceReasoning: Make Financial Numerical Reasoning More Credible, Comprehensive, and Challenging</strong><br><em>Zichen Tang, Haihong E, Ziyan Ma, Haoyang He, Jiacheng Liu, Zhongjun Yang, Zihua Rong, Rongjin Li, Kun Ji, Huang Qing, Xinyang Hu, Yang Liu, Qianhe Zheng</em></li>
  <li><strong>Controllable Style Arithmetic with Language Models</strong><br><em>Weiqi Wang, Wengang Zhou, Zongmeng Zhang, Jie Zhao, Houqiang Li</em></li>
  <li><strong>Masks Can be Learned As An Alternative of Experts</strong><br><em>Peiyu Liu, Tianwen Wei, Bo Zhu, Xin Zhao, Shuicheng YAN</em></li>
  <li><strong>Program Synthesis Benchmark for Visual Programming in XLogoOnline Environment</strong><br><em>Chao Wen, Jacqueline Staub, Adish Singla</em></li>
  <li><strong>Removal of Hallucination on Hallucination: Debate-Augmented RAG</strong><br><em>Wentao Hu, Wengyu Zhang, Yiyang Jiang, Chen Jason Zhang, Xiaoyong Wei, Li Qing</em></li>
  <li><strong>CodeDPO: Aligning Code Models with Self Generated and Verified Source Code</strong><br><em>Kechi Zhang, Ge Li, Yihong Dong, Jingjing Xu, Jun Zhang, Jing Su, Yongfei Liu, Zhi Jin</em></li>
  <li><strong>ProxAnn: Use-Oriented Evaluations of Topic Models and Document Clustering</strong><br><em>Alexander Miserlis Hoyle, Lorena Calvo-Bartolomé, Jordan Lee Boyd-Graber, Philip Resnik</em></li>
  <li><strong>BOOKWORLD: From Novels to Interactive Agent Societies for Story Creation</strong><br><em>Yiting Ran, Xintao Wang, Tian Qiu, Jiaqing Liang, Yanghua Xiao, Deqing Yang</em></li>
  <li><strong>Quantifying Lexical Semantic Shift via Unbalanced Optimal Transport</strong><br><em>Ryo Kishino, Hiroaki Yamagiwa, Ryo Nagata, Sho Yokoi, Hidetoshi Shimodaira</em></li>
  <li><strong>Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems</strong><br><em>Hao Peng, Yunjia Qi, Xiaozhi Wang, Zijun Yao, Bin Xu, Lei Hou, Juanzi Li</em></li>
  <li><strong>Adaptive and Robust Translation from Natural Language to Multi-model Query Languages</strong><br><em>Gengyuan Shi, Chaokun Wang, Liu Yabin, Jiawei Ren</em></li>
  <li><strong>SAKE: Steering Activations for Knowledge Editing</strong><br><em>Marco Scialanga, Thibault Laugel, Vincent Grari, Marcin Detyniecki</em></li>
  <li><strong>Middle-Layer Representation Alignment for Cross-Lingual Transfer in Fine-Tuned LLMs</strong><br><em>Danni Liu, Jan Niehues</em></li>
  <li><strong>Can external validation tools improve annotation quality for LLM-as-a-Judge?</strong><br><em>Arduin Findeis, Floris Weers, Guoli Yin, Ke Ye, Ruoming Pang, Tom Gunter</em></li>
  <li><strong>One for All: Update Parameterized Knowledge Across Multiple Models with Once Edit</strong><br><em>Weitao Ma, Xiyuan Du, Xiaocheng Feng, Lei Huang, Yichong Huang, Huiyi Zhang, Xiaoliang Yang, Baohang Li, Xiachong Feng, Ting Liu, Bing Qin</em></li>
  <li><strong>VLMInferSlow: Evaluating the Efficiency Robustness of Large Vision-Language Models as a Service</strong><br><em>Xiasi Wang, Tianliang Yao, Simin Chen, Runqi Wang, Lei YE, Kuofeng Gao, Yi Huang, Yuan Yao</em></li>
  <li><strong>The Alternative Annotator Test for LLM-as-a-Judge: How to Statistically Justify Replacing Human Annotators with LLMs</strong><br><em>Nitay Calderon, Roi Reichart, Rotem Dror</em></li>
  <li><strong>CrisisTS: Coupling Social Media Textual Data and Meteorological Time Series for Urgency Classification</strong><br><em>Romain Meunier, Farah Benamara, Véronique Moriceau, Savitha Ramasamy, Zhongzheng Qiao</em></li>
  <li><strong>How to Mitigate Overfitting in Weak-to-strong Generalization?</strong><br><em>Junhao Shi, Qinyuan Cheng, Zhaoye Fei, Yining Zheng, Qipeng Guo, Xipeng Qiu</em></li>
  <li><strong>Com$^2$ : A Causal-Guided Benchmark for Exploring Complex Commonsense Reasoning in Large Language Models</strong><br><em>Kai Xiong, Xiao Ding, Yixin Cao, Yuxiong Yan, Li Du, Yufei Zhang, Jinglong Gao, Jiaqian Liu, Bing Qin, Ting Liu</em></li>
  <li><strong>Dynamic Head Selection for Neural Lexicalized Constituency Parsing</strong><br><em>Yang Hou, Zhenghua Li</em></li>
  <li><strong>My Words Imply Your Opinion: Reader Agent-Based Propagation Enhancement for Personalized Implicit Emotion Analysis</strong><br><em>Jian Liao, Yu Feng, Yujin Zheng, Jun Zhao, Suge Wang, JianXing Zheng</em></li>
  <li><strong>EvolveBench: A Comprehensive Benchmark for Assessing Temporal Awareness in LLMs on Evolving Knowledge</strong><br><em>Zhiyuan Zhu, Yusheng Liao, Zhe Chen, Yuhao Wang, Yunfeng Guan, Yanfeng Wang, Yu Wang</em></li>
  <li><strong>Enabling LLM Knowledge Analysis via Extensive Materialization</strong><br><em>Yujia Hu, Tuan-Phong Nguyen, Shrestha Ghosh, Simon Razniewski</em></li>
  <li><strong>Rhythm Controllable and Efficient Zero-Shot Voice Conversion via Shortcut Flow Matching</strong><br><em>Jialong Zuo, Shengpeng Ji, Minghui Fang, Mingze Li, Ziyue Jiang, Xize Cheng, Xiaoda Yang, Chen Feiyang, Xinyu Duan, Zhou Zhao</em></li>
  <li><strong>Llama See, Llama Do: A Mechanistic Perspective on Contextual Entrainment and Distraction in LLMs</strong><br><em>Jingcheng Niu, Xingdi Yuan, Tong Wang, Hamidreza Saghir, Amir H. Abdi</em></li>
  <li><strong>CritiQ: Mining Data Quality Criteria from Human Preferences</strong><br><em>Honglin Guo, Kai Lv, Qipeng Guo, Tianyi Liang, Zhiheng Xi, Demin Song, Qiuyinzhe Zhang, Yu Sun, Kai Chen, Xipeng Qiu, Tao Gui</em></li>
  <li><strong>Theoretical Guarantees for Minimum Bayes Risk Decoding</strong><br><em>Yuki Ichihara, Yuu Jinnai, Kaito Ariu, Tetsuro Morimura, Eiji Uchibe</em></li>
  <li><strong>Mutual-Taught for Co-adapting Policy and Reward Models</strong><br><em>Tianyuan Shi, Canbin Huang, Fanqi Wan, Longguang Zhong, Ziyi Yang, Weizhou Shen, Xiaojun Quan, Ming Yan</em></li>
  <li><strong>Enhancing Cross-Lingual Transfer through Reversible Transliteration: A Huffman-Based Approach for Low-Resource Languages</strong><br><em>Wenhao Zhuang, Yuan Sun, Xiaobing Zhao</em></li>
  <li><strong>Unmasking Style Sensitivity: A Causal Analysis of Bias Evaluation Instability in Large Language Models</strong><br><em>Jiaxu Zhao, Meng Fang, Kun Zhang, Mykola Pechenizkiy</em></li>
  <li><strong>MockConf: A Student Interpretation Dataset: Analysis, Word- and Span-level Alignment and Baselines</strong><br><em>Dávid Javorský, Ondřej Bojar, François Yvon</em></li>
  <li><strong>BMIKE-53: Investigating Cross-Lingual Knowledge Editing with In-Context Learning</strong><br><em>Ercong Nie, Bo Shao, Mingyang Wang, Zifeng Ding, Helmut Schmid, Hinrich Schuetze</em></li>
  <li><strong>What Matters in Evaluating Book-Length Stories? A Systematic Study of Long Story Evaluation</strong><br><em>Dingyi Yang, Qin Jin</em></li>
  <li><strong>PROPER: A Progressive Learning Framework for Personalized Large Language Models with Group-Level Adaptation</strong><br><em>Linhai Zhang, Jialong Wu, Deyu Zhou, Yulan He</em></li>
  <li><strong>Enhancing Event-centric News Cluster Summarization via Data Sharpening and Localization Insights</strong><br><em>Longyin Zhang, Bowei Zou, AiTi Aw</em></li>
  <li><strong>MMBoundary: Advancing MLLM Knowledge Boundary Awareness through Reasoning Step Confidence Calibration</strong><br><em>Zhitao He, Sandeep Polisetty, Zhiyuan Fan, Shujin Wu, Yuchen Huang, Yi R. Fung</em></li>
  <li><strong>LIFBench: Evaluating the Instruction Following Performance and Stability of Large Language Models in Long-Context Scenarios</strong><br><em>Xiaodong Wu, Minhao Wang, Yichen Liu, Xiaoming Shi, He Yan, Lu Xiangju, Junmin Zhu, Wei Zhang</em></li>
  <li><strong>FEAT: A Preference Feedback Dataset through a Cost-Effective Auto-Generation and Labeling Framework for English AI Tutoring</strong><br><em>Hyein Seo, Taewook Hwang, Yohan Lee, Sangkeun Jung</em></li>
  <li><strong>Aligning Large Language Models to Follow Instructions and Hallucinate Less via Effective Data Filtering</strong><br><em>Shuzheng Si, Haozhe Zhao, Gang Chen, Cheng Gao, Yuzhuo Bai, Zhitong Wang, Kaikai An, Kangyang Luo, Chen Qian, Fanchao Qi, Baobao Chang, Maosong Sun</em></li>
  <li><strong>One-Shot is Enough: Consolidating Multi-Turn Attacks into Efficient Single-Turn Prompts for LLMs</strong><br><em>Junwoo Ha, Hyunjun Kim, Sangyoon Yu, Haon Park, Ashkan Yousefpour, Yuna Park, Suhyun Kim</em></li>
  <li><strong>RAEmoLLM: Retrieval Augmented LLMs for Cross-Domain Misinformation Detection Using In-Context Learning Based on Emotional Information</strong><br><em>Zhiwei Liu, Kailai Yang, Qianqian Xie, Christine de Kock, Sophia Ananiadou, Eduard Hovy</em></li>
  <li><strong>Task-Specific Information Decomposition for End-to-End Dense Video Captioning</strong><br><em>Zhiyue Liu, Xinru Zhang, Jinyuan Liu</em></li>
  <li><strong>CalibraEval: Calibrating Prediction Distribution to Mitigate Selection Bias in LLMs-as-Judges</strong><br><em>Haitao Li, Junjie Chen, Qingyao Ai, Zhumin Chu, Yujia Zhou, Qian Dong, Yiqun LIU</em></li>
  <li><strong>Explaining Matters: Leveraging Definitions and Semantic Expansion for Sexism Detection</strong><br><em>Sahrish Khan, Gabriele Pergola, Arshad Jhumka</em></li>
  <li><strong>Private Memorization Editing: Turning Memorization into a Defense to Strengthen Data Privacy in Large Language Models</strong><br><em>Elena Sofia Ruzzetti, Giancarlo A. Xompero, Davide Venditti, Fabio Massimo Zanzotto</em></li>
  <li><strong>PhysReason: A Comprehensive Benchmark towards Physics-Based Reasoning</strong><br><em>Xinyu Zhang, Yuxuan Dong, Yanrui Wu, Jiaxing Huang, Chengyou Jia, Basura Fernando, Mike Zheng Shou, Lingling Zhang, Jun Liu</em></li>
  <li><strong>Does Time Have Its Place? Temporal Heads: Where Language Models Recall Time-specific Information</strong><br><em>Yein Park, Chanwoong Yoon, Jungwoo Park, Minbyul Jeong, Jaewoo Kang</em></li>
  <li><strong>Velocitune: A Velocity-based Dynamic Domain Reweighting Method for Continual Pre-training</strong><br><em>Zheheng Luo, Xin Zhang, Xiao Liu, Haoling Li, Yeyun Gong, Qi Chen, Peng CHENG</em></li>
  <li><strong>Sheep’s Skin, Wolf’s Deeds: Are LLMs Ready for Metaphorical Implicit Hate Speech?</strong><br><em>Jingjie Zeng, Yuanyuan Sun, zekun wang, Liang Yang, Hongfei Lin</em></li>
  <li><strong>Neuron-Level Sequential Editing for Large Language Models</strong><br><em>Houcheng Jiang, Junfeng Fang, Tianyu Zhang, Baolong Bi, An Zhang, Ruipeng Wang, Tao Liang, Xiang Wang</em></li>
  <li><strong>Automatic Expert Discovery in LLM Upcycling via Sparse Interpolated Mixture-of-Experts</strong><br><em>Shengzhuang Chen, Ying Wei, Jonathan Richard Schwarz</em></li>
  <li><strong>SimulS2S-LLM: Unlocking Simultaneous Inference of Speech LLMs for Speech-to-Speech Translation</strong><br><em>Keqi Deng, Wenxi Chen, Xie Chen, Phil Woodland</em></li>
  <li><strong>VoxEval: Benchmarking the Knowledge Understanding Capabilities of End-to-End Spoken Language Models</strong><br><em>Wenqian Cui, Xiaoqi Jiao, Ziqiao Meng, Irwin King</em></li>
  <li><strong>RetroLLM: Empowering Large Language Models to Retrieve Fine-grained Evidence within Generation</strong><br><em>Xiaoxi Li, Jiajie Jin, Yujia Zhou, Yongkang Wu, Zhonghua Li, YE QI, Zhicheng Dou</em></li>
  <li><strong>ChronoSense: Exploring Temporal Understanding in Large Language Models with Time Intervals of Events</strong><br><em>Duygu Sezen Islakoglu, Jan-Christoph Kalo</em></li>
  <li><strong>The Role of Deductive and Inductive Reasoning in Large Language Models</strong><br><em>Chengkun Cai, Xu Zhao, Haoliang Liu, Zhongyu Jiang, Tianfang Zhang, Zongkai Wu, Jenq-Neng Hwang, Serge Belongie, Lei Li</em></li>
  <li><strong>Disentangling the Roles of Representation and Selection in Data Pruning</strong><br><em>Yupei Du, Yingjin Song, Hugh Mee Wong, Daniil Ignatev, Albert Gatt, Dong Nguyen</em></li>
  <li><strong>FRACTAL: Fine-Grained Scoring from Aggregate Text Labels</strong><br><em>Yukti Makhija, Priyanka Agrawal, Rishi Saket, Aravindan Raghuveer</em></li>
  <li><strong>ACT: Knowledgeable Agents to Design and Perform Complex Tasks</strong><br><em>Makoto Nakatsuji, Shuhei Tateishi, Yasuhiro Fujiwara, Ayaka Matsumoto, Narichika Nomoto, Yoshihide Sato</em></li>
  <li><strong>Logical forms complement probability in understanding language model (and human) performance</strong><br><em>Yixuan Wang, Freda Shi</em></li>
  <li><strong>Length Controlled Generation for Black-box LLMs</strong><br><em>Yuxuan Gu, Wenjie Wang, Xiaocheng Feng, Weihong Zhong, kun Zhu, Lei Huang, Ting Liu, Bing Qin, Tat-Seng Chua</em></li>
  <li><strong>Improving Contextual Faithfulness of Large Language Models via Retrieval Heads-Induced Optimization</strong><br><em>Lei Huang, Xiaocheng Feng, Weitao Ma, Yuchun Fan, Xiachong Feng, Yangfan Ye, Weihong Zhong, Yuxuan Gu, Baoxin Wang, Dayong Wu, Guoping Hu, Bing Qin</em></li>
  <li><strong>Global Eye: Breaking the “Fixed Thinking Pattern” during the Instruction Expansion Process</strong><br><em>wenxuan lu, Wei Liu, Jian Luan, Bin Wang, Songhao Jiang, Tianning Zang</em></li>
  <li><strong>On Synthesizing Data for Context Attribution in Question Answering</strong><br><em>Gorjan Radevski, Kiril Gashteovski, Shahbaz Syed, Christopher Malon, Sebastien Nicolas, Chia-Chien Hung, Timo Sztyler, Verena Heußer, Wiem Ben Rim, Masafumi Enomoto, Kunihiro Takeoka, Masafumi Oyamada, Goran Glavaš, Carolin Lawrence</em></li>
  <li><strong>TST: A Schema-Based Top-Down and Dynamic-Aware Agent of Text-to-Table Tasks</strong><br><em>Peiwen Jiang, Haitong Jiang, Ruhui Ma, Yvonne Jie Chen, Jinhua Cheng</em></li>
  <li><strong>EventRAG: Enhancing LLM Generation with Event Knowledge Graphs</strong><br><em>Zairun Yang, Yilin Wang, Zhengyan Shi, Yuan Yao, Lei Liang, Keyan Ding, Emine Yilmaz, Huajun Chen, Qiang Zhang</em></li>
  <li><strong>Supervised Fine-Tuning Achieve Rapid Task Adaption Via Alternating Attention Head Activation Patterns</strong><br><em>Yang Zhao, Li Du, Xiao Ding, Kai Xiong, Ting Liu, Bing Qin</em></li>
  <li><strong>Can’t See the Forest for the Trees: Benchmarking Multimodal Safety Awareness for Multimodal LLMs</strong><br><em>Wenxuan Wang, Xiaoyuan Liu, Kuiyi Gao, Jen-tse Huang, Youliang Yuan, Pinjia He, Shuai Wang, Zhaopeng Tu</em></li>
  <li><strong>Mis-prompt: Benchmarking Large Language Models for Proactive Error Handling</strong><br><em>Jiayi Zeng, Yizhe Feng, Mengliang He, Wenhui Lei, Wei Zhang, Zeming Liu, Xiaoming Shi, Aimin Zhou</em></li>
  <li><strong>TripCraft: A Benchmark for Spatio-Temporally Fine Grained Travel Planning</strong><br><em>Soumyabrata Chaudhuri, Pranav Purkar, Ritwik Raghav, Shubhojit Mallick, Manish Gupta, Abhik Jana, Shreya Ghosh</em></li>
  <li><strong>DualGuard: A Parameter Space Transformation Approach for Bidirectional Defense in Split-Based LLM Fine-Tuning</strong><br><em>Zihan Liu, Yizhen Wang, Rui Wang, Sai Wu</em></li>
  <li><strong>Movie101v2: Improved Movie Narration Benchmark</strong><br><em>Zihao Yue, Yepeng Zhang, Ziheng Wang, Qin Jin</em></li>
  <li><strong>Can LLMs Evaluate Complex Attribution in QA? Automatic Benchmarking using Knowledge Graphs</strong><br><em>Nan Hu, Jiaoyan Chen, Yike Wu, Guilin Qi, Hongru WANG, Sheng Bi, Yongrui Chen, Tongtong Wu, Jeff Z. Pan</em></li>
  <li><strong>Value Portrait: Understanding Values of LLMs with Human-aligned Benchmark</strong><br><em>Jongwook Han, Dongmin Choi, Woojung Song, Eun-Ju Lee, Yohan Jo</em></li>
  <li><strong>FEA-Bench: A Benchmark for Evaluating Repository-Level Code Generation for Feature Implementation</strong><br><em>Wei Li, Xin Zhang, Zhongxin Guo, Shaoguang Mao, Wen Luo, Guangyue Peng, Yangyu Huang, Houfeng Wang, Scarlett Li</em></li>
  <li><strong>Do not Abstain! Identify and Solve the Uncertainty</strong><br><em>Jingyu Liu, JingquanPeng, xiaopeng Wu, Xubin Li, Tiezheng Ge, Bo Zheng, Yong Liu</em></li>
  <li><strong>Decoding by Contrasting Knowledge: Enhancing Large Language Model Confidence on Edited Facts</strong><br><em>Baolong Bi, Shenghua Liu, Lingrui Mei, Yiwei Wang, Junfeng Fang, Pengliang Ji, Xueqi Cheng</em></li>
  <li><strong>ImpliHateVid: A Benchmark Dataset and Two-stage Contrastive Learning Framework for Implicit Hate Speech Detection in Videos</strong><br><em>Mohammad Zia Ur Rehman, Anukriti Bhatnagar, Omkar Kabde, Shubhi Bansal, Dr. Nagendra Kumar</em></li>
  <li><strong>Improving Chain-of-Thought Reasoning via Quasi-Symbolic Abstractions</strong><br><em>Leonardo Ranaldi, Marco Valentino, Andre Freitas</em></li>
  <li><strong>Information Extraction from Visually Rich Documents using LLM-based Organization of Documents into Independent Textual Segments</strong><br><em>Aniket Bhattacharyya, Anurag Tripathi, Ujjal Das, Archan Karmakar, Amit Pathak, Maneesh Gupta</em></li>
  <li><strong>Enhancing Large Language Model’s Capabilities in Open Domains via Autonomous Tool Integration from GitHub</strong><br><em>Bohan Lyu, Xin Cong, Heyang Yu, Pan Yang, Cheng Qian, Zihe Wang, Yujia Qin, Yining Ye, Yaxi Lu, Chen Qian, Zhong Zhang, Yukun Yan, Yankai Lin, Zhiyuan Liu, Maosong Sun</em></li>
  <li><strong>LLMs Can Simulate Standardized Patients via Agent Coevolution</strong><br><em>Zhuoyun Du, LujieZheng, Renjun Hu, Yuyang Xu, Xiawei Li, Ying Sun, Wei Chen, Jian Wu, Haolei Cai, Haochao Ying</em></li>
  <li><strong>Donate or Create? Comparing Data Collection Strategies for Emotion-labeled Multimodal Social Media Posts</strong><br><em>Christopher Bagdon, Aidan Combs, Carina Silberer, Roman Klinger</em></li>
  <li><strong>Which Demographics do LLMs Default to During Annotation?</strong><br><em>Johannes Schäfer, Aidan Combs, Christopher Bagdon, Jiahui Li, Nadine Probol, Lynn Greschner, Sean Papay, Yarik Menchaca Resendiz, Aswathy Velutharambath, Amelie Wuehrl, Sabine Weber, Roman Klinger</em></li>
  <li><strong>Can You Really Trust Code Copilot? Evaluating Large Language Models from a Code Security Perspective</strong><br><em>Yutao Mou, Xiao Deng, Yuxiao Luo, Shikun Zhang, Wei Ye</em></li>
  <li><strong>From Sub-Ability Diagnosis to Human-Aligned Generation: Bridging the Gap for Text Length Control via MarkerGen</strong><br><em>Peiwen Yuan, Chuyi Tan, Shaoxiong Feng, Yiwei Li, Xinglin Wang, Yueqi Zhang, Jiayi Shi, Boyuan Pan, Yao Hu, Kan Li</em></li>
  <li><strong>AGD: Adversarial Game Defense Against Jailbreak Attacks in Large Language Models</strong><br><em>Shilong Pan, Zhiliang Tian, Zhen Huang, Wanlong Yu, Zhihua Wen, Xinwang Liu, Kai Lu, Minlie Huang, Dongsheng Li</em></li>
  <li><strong>SCOP: Evaluating the Comprehension Process of Large Language Models from a Cognitive View</strong><br><em>Yongjie Xiao, Hongru Liang, Peixin Qin, YAO ZHANG, Wenqiang Lei</em></li>
  <li><strong>Table-Critic: A Multi-Agent Framework for Collaborative Criticism and Refinement in Table Reasoning</strong><br><em>Peiying Yu, Guoxin Chen, Jingjing Wang</em></li>
  <li><strong>An Expanded Massive Multilingual Dataset for High-Performance Language Technologies</strong><br><em>Laurie Burchell, Ona De Gibert Bonet, Nikolay Arefyev, Mikko Aulamo, Marta Bañón, Pinzhen Chen, Mariia Fedorova, Liane Guillou, Barry Haddow, Jan Hajič, Jindřich Helcl, Erik Henriksson, Mateusz Klimaszewski, Ville Komulainen, Andrey Kutuzov, Joona Kytöniemi, Veronika Laippala, Petter Mæhlum, Bhavitvya Malik, Farrokh Mehryary, Vladislav Mikhailov, Nikita Moghe, Amanda Myntti, Dayyán O’Brien, Stephan Oepen, Proyag Pal, Jousia Piha, Sampo Pyysalo, Gema Ramírez-Sánchez, David Samuel, Pavel Stepachev, Jörg Tiedemann, Dušan Variš, Tereza Vojtěchová, Jaume Zaragoza-Bernabeu</em></li>
  <li><strong>Scaling Text-Rich Image Understanding via Code-Guided Synthetic Multimodal Data Generation</strong><br><em>Yue Yang, Ajay Patel, Matt Deitke, Tanmay Gupta, Luca Weihs, Andrew Head, Mark Yatskar, Chris Callison-Burch, Ranjay Krishna, Aniruddha Kembhavi, Christopher Clark</em></li>
  <li><strong>Hierarchical Attention Generates Better Proofs</strong><br><em>Jianlong Chen, Chao Li, Yang Yuan, Andrew C Yao</em></li>
  <li><strong>Agent-RewardBench: Towards a Unified Benchmark for Reward Modeling across Perception, Planning, and Safety in Real-World Multimodal Agents</strong><br><em>Tianyi Men, Zhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao</em></li>
  <li><strong>It’s Not Bragging If You Can Back It Up: Can LLMs Understand Braggings?</strong><br><em>Jingjie Zeng, Huayang Li, Yuanyuan Sun, Liang Yang, Hongfei Lin</em></li>
  <li><strong>A Troublemaker with Contagious Jailbreak Makes Chaos in Honest Towns</strong><br><em>Tianyi Men, Pengfei Cao, Zhuoran Jin, Yubo Chen, Kang Liu, Jun Zhao</em></li>
  <li><strong>Meta-Learning Neural Mechanisms rather than Bayesian Priors</strong><br><em>Michael Eric Goodale, Salvador Mascarenhas, Yair Lakretz</em></li>
  <li><strong>Shifting from Ranking to Set Selection for Retrieval Augmented Generation</strong><br><em>Dahyun Lee, Yongrae Jo, Haeju Park, Moontae Lee</em></li>
  <li><strong>Understanding Large Language Model Vulnerabilities to Social Bias Attacks</strong><br><em>Jiaxu Zhao, Meng Fang, Fanghua Ye, Ke Xu, Qin Zhang, Joey Tianyi Zhou, Mykola Pechenizkiy</em></li>
  <li><strong>ChatSOP: An SOP-Guided MCTS Planning Framework for Controllable LLM Dialogue Agents</strong><br><em>Zhigen Li, Jianxiang Peng, Yanmeng Wang, Yong Cao, Tianhao Shen, Minghui Zhang, Linxi Su, Shang Wu, Yihang Wu, YuQian Wang, Ye Wang, Wei Hu, Jianfeng Li, Shaojun Wang, Jing Xiao, Deyi Xiong</em></li>
  <li><strong>Pixel-Level Reasoning Segmentation via Multi-turn Conversations</strong><br><em>Dexian Cai, Xiaocui Yang, YongKang Liu, Daling Wang, Shi Feng, Yifei Zhang, Soujanya Poria</em></li>
  <li><strong>Fixing Distribution Shifts of LLM Self-Critique via On-Policy Self-Play Training</strong><br><em>Rong Bao, Donglei Yu, Kai Fan, Minpeng Liao</em></li>
  <li><strong>Inferring Functionality of Attention Heads from their Parameters</strong><br><em>Amit Elhelo, Mor Geva</em></li>
  <li><strong>Faithful and Robust LLM-Driven Theorem Proving for NLI Explanations</strong><br><em>Xin Quan, Marco Valentino, Louise A. Dennis, Andre Freitas</em></li>
  <li><strong>Revealing the Deceptiveness of Knowledge Editing: A Mechanistic Analysis of Superficial Editing</strong><br><em>Jiakuan Xie, Pengfei Cao, Yubo Chen, Kang Liu, Jun Zhao</em></li>
  <li><strong>Masking in Multi-hop QA: An Analysis of How Language Models Perform with Context Permutation</strong><br><em>Wenyu Huang, Pavlos Vougiouklis, Mirella Lapata, Jeff Z. Pan</em></li>
  <li><strong>From Human Reading to NLM Understanding: Evaluating the Role of Eye-Tracking Data in Encoder-Based Models</strong><br><em>Luca Dini, Lucia Domenichelli, Dominique Brunato, Felice Dell’Orletta</em></li>
  <li><strong>Optimizing Question Semantic Space for Dynamic Retrieval-Augmented Multi-hop Question Answering</strong><br><em>LINHAO YE, Qin Chen, Jie Zhou, Lang Yu, Zhikai Lei, Liang He</em></li>
  <li><strong>Insight Over Sight: Exploring the Vision-Knowledge Conflicts in Multimodal LLMs</strong><br><em>Xiaoyuan Liu, Wenxuan Wang, Youliang Yuan, Jen-tse Huang, Qiuzhi Liu, Pinjia He, Zhaopeng Tu</em></li>
  <li><strong>SceneGenAgent: Precise Industrial Scene Generation with Coding Agent</strong><br><em>Xiao Xia, Dan Zhang, Zibo Liao, Zhenyu Hou, Tianrui Sun, Jing Li, Ling Fu, Yuxiao Dong</em></li>
  <li><strong>ToolCoder: A Systematic Code-Empowered Tool Learning Framework for Large Language Models</strong><br><em>Hanxing Ding, Shuchang Tao, Liang Pang, Zihao Wei, Jinyang Gao, Bolin Ding, Huawei Shen, Xueqi Cheng</em></li>
  <li><strong>Human Alignment: How Much Do We Adapt to LLMs?</strong><br><em>Cazalets Tanguy, Ruben Janssens, Tony Belpaeme, Joni Dambre</em></li>
  <li><strong>Enhancing Text Editing for Grammatical Error Correction: Arabic as a Case Study</strong><br><em>Bashar Alhafni, Nizar Habash</em></li>
  <li><strong>From Isolates to Families: Using Neural Networks for Automated Language Affiliation</strong><br><em>Frederic Blum, Steffen Herbold, Johann-Mattis List</em></li>
  <li><strong>ELBA-Bench: An Efficient Learning Backdoor Attacks Benchmark for Large Language Models</strong><br><em>Xuxu Liu, Siyuan Liang, Mengya Han, Yong Luo, Aishan Liu, Xiantao Cai, Zheng He, Dacheng Tao</em></li>
  <li><strong>Less, but Better: Efficient Multilingual Expansion for LLMs via Layer-wise Mixture-of-Experts</strong><br><em>Xue Zhang, Yunlong Liang, Fandong Meng, Songming Zhang, Yufeng Chen, Jinan Xu, Jie Zhou</em></li>
  <li><strong>When Harry Meets Superman: The Role of The Interlocutor in Persona-Based Dialogue Generation</strong><br><em>Daniela Occhipinti, Marco Guerini, Malvina Nissim</em></li>
  <li><strong>ICR Probe: Tracking Hidden State Dynamics for Reliable Hallucination Detection in LLMs</strong><br><em>Zhenliang Zhang, Xinyu Hu, Huixuan Zhang, Junzhe Zhang, Xiaojun Wan</em></li>
  <li><strong>Revisit Self-Debugging with Self-Generated Tests for Code Generation</strong><br><em>Xiancai Chen, Zhengwei Tao, Kechi Zhang, Changzhi Zhou, Xinyu Zhang, Wanli Gu, Yuanpeng He, Mengdi Zhang, Xunliang Cai, Haiyan Zhao, Zhi Jin</em></li>
  <li><strong>InSerter: Speech Instruction Following with Unsupervised Interleaved Pre-training</strong><br><em>Dingdong WANG, Jin Xu, Ruihang Chu, Zhifang Guo, Xiong Wang, Jincenzi Wu, Dongchao Yang, Shengpeng Ji, Junyang Lin</em></li>
  <li><strong>Exploring LLMs’ Ability to Spontaneously and Conditionally Modify Moral Expressions through Text Manipulation</strong><br><em>Candida Maria Greco, Lucio La Cava, Lorenzo Zangari, Andrea Tagarelli</em></li>
  <li><strong>Mixture of Ordered Scoring Experts for Cross-prompt Essay Trait Scoring</strong><br><em>Po-Kai Chen, Bo-Wei Tsai, Shao Kuan Wei, Chien-Yao Wang, Jia-Ching Wang, Yi-Ting Huang</em></li>
  <li><strong>A Sample Offline Saves Time: Knowledge Distillation in the LLM Era</strong><br><em>Anshumann, Mohd Abbas Zaidi, Akhil Kedia, Jinwoo Ahn, Taehwak Kwon, Kangwook Lee, Haejun Lee, Joohyung Lee</em></li>
  <li><strong>Enhancing Spoken Discourse Modeling in Language Models Using Gestural Cues</strong><br><em>Varsha Suresh, M. Hamza Mughal, Christian Theobalt, Vera Demberg</em></li>
  <li><strong>ExploraCoder: Advancing Code Generation for Multiple Unseen APIs via Planning and Chained Exploration</strong><br><em>Yunkun Wang, Yue Zhang, Zhen Qin, Chen Zhi, Binhua Li, Fei Huang, Yongbin Li, Shuiguang Deng</em></li>
  <li><strong>Segment First or Comprehend First? Explore the Limit of Unsupervised Word Segmentation with Large Language Models</strong><br><em>Zihong Zhang, Liqi He, Zuchao Li, Lefei Zhang, hai zhao, Bo Du</em></li>
  <li><strong>RUBY: An Effective Framework for Multi-Constraint Multi-Hop Question Generation</strong><br><em>Wenzhuo Zhao, Shuangyin Li</em></li>
  <li><strong>Can Indirect Prompt Injection Attacks Be Detected and Removed?</strong><br><em>Yulin Chen, Haoran Li, Yuan Sui, Yufei He, Yue Liu, Yangqiu Song, Bryan Hooi</em></li>
  <li><strong>Identifying Open Challenges in Language Identification</strong><br><em>Rob van der Goot</em></li>
  <li><strong>The Distracting Effect: Understanding Irrelevant Passages in RAG</strong><br><em>Chen Amiraz, Florin Cuconasu, Simone Filice, Zohar Karnin</em></li>
  <li><strong>Multilingual Encoder Knows more than You Realize: Shared Weights Pretraining for Extremely Low-Resource Languages</strong><br><em>Zeli Su, Ziyin Zhang, Guixian Xu, Jianing Liu, Xu Han, Ting Zhang, Yushuang Dong</em></li>
  <li><strong>Graphically Speaking: Unmasking Abuse in Social Media with Conversation Insights</strong><br><em>Célia Nouri, Chloé Clavel, Jean-Philippe Cointet</em></li>
  <li><strong>CodeTool: Enhancing Programmatic Tool Invocation of LLMs via Process Supervision</strong><br><em>YifeiLu, Fanghua Ye, Jian Li, Qiang Gao, Cheng Liu, Haibo Luo, nan du, Xiaolong Li, Feiliang Ren</em></li>
  <li><strong>RARE: Retrieval-Augmented Reasoning Enhancement for Large Language Models</strong><br><em>Hieu Tran, Zonghai Yao, Zhichao Yang, Junda Wang, Yifan Zhang, Feiyun Ouyang, Shuo Han, hong yu</em></li>
  <li><strong>Defense Against Prompt Injection Attack by Leveraging Attack Techniques</strong><br><em>Yulin Chen, Haoran Li, Zihao Zheng, Dekai Wu, Yangqiu Song, Bryan Hooi</em></li>
  <li><strong>Acquisition and Application of Novel Knowledge in Large Language Models</strong><br><em>Ziyu Shang, Jianghan Liu, Zhizhao Luo, Peng Wang, Wenjun Ke, Jiajun Liu, Zijie Xu, Guozheng Li</em></li>
  <li><strong>DNCASR: End-to-End Training for Speaker-Attributed ASR</strong><br><em>Xianrui Zheng, Chao Zhang, Phil Woodland</em></li>
  <li><strong>Exploring Persona Sentiment Sensitivity in Personalized Dialogue Generation</strong><br><em>Yonghyun Jun, Hwanhee Lee</em></li>
  <li><strong>AntiLeakBench: Preventing Data Contamination by Automatically Constructing Benchmarks with Updated Real-World Knowledge</strong><br><em>Xiaobao Wu, Liangming Pan, Yuxi Xie, Ruiwen Zhou, Shuai Zhao, Yubo Ma, Mingzhe Du, Rui Mao, Anh Tuan Luu, William Yang Wang</em></li>
  <li><strong>LLM-Guided Semantic-Aware Clustering for Topic Modeling</strong><br><em>Jianghan Liu, Ziyu Shang, Wenjun Ke, Peng Wang, Zhizhao Luo, Jiajun Liu, Guozheng Li, Yining Li</em></li>
  <li><strong>Hierarchical Bracketing Encodings for Dependency Parsing as Tagging</strong><br><em>Ana Ezquerro, David Vilares, Anssi Yli-Jyrä, Carlos Gómez-Rodríguez</em></li>
  <li><strong>OASIS: Order-Augmented Strategy for Improved Code Search</strong><br><em>GAO Zuchen, Zizheng Zhan, Xianming LI, Erxin Yu, Haotian Zhang, chenbin, Yuqun Zhang, Jing Li</em></li>
  <li><strong>Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?</strong><br><em>Yancheng He, Shilong Li, Jiaheng Liu, Weixun Wang, Xingyuan Bu, Ge Zhang, Z.Y. Peng, Zhaoxiang Zhang, Zhicheng Zheng, Wenbo Su, Bo Zheng</em></li>
  <li><strong>OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference</strong><br><em>Xiangyu Zhao, Shengyuan Ding, Zicheng Zhang, Haian Huang, Maosongcao, Jiaqi Wang, Weiyun Wang, Xinyu Fang, Wenhai Wang, Guangtao Zhai, Hua Yang, Haodong Duan, Kai Chen</em></li>
  <li><strong>Dynamic Order Template Prediction for Generative Aspect-Based Sentiment Analysis</strong><br><em>Yonghyun Jun, Hwanhee Lee</em></li>
  <li><strong>Tree-KG: An Expandable KG Construction Framework for Knowledge-intensive Domains</strong><br><em>Songjie Niu, Kaisen Yang, Rui Zhao, Yichao Liu, Zonglin Li, Hongning Wang, Wenguang Chen</em></li>
  <li><strong>Measuring Data Diversity for Instruction Tuning: A Systematic Analysis and A Reliable Metric</strong><br><em>Yuming Yang, Yang Nan, Junjie Ye, Shihan Dou, Xiao Wang, Shuo Li, Huijie Lv, Tao Gui, Qi Zhang, Xuanjing Huang</em></li>
  <li><strong>Micro-Act: Mitigate Knowledge Conflict in Question Answering via Actionable Self-Reasoning</strong><br><em>Nan Huo, Jinyang Li, Bowen Qin, Ge Qu, Xiaolong Li, Xiaodong Li, Chenhao Ma, Reynold Cheng</em></li>
  <li><strong>Minimal Pair-Based Evaluation of Code-Switching</strong><br><em>Igor Sterner, Simone Teufel</em></li>
  <li><strong>DNASpeech: A Contextualized and Situated Text-to-Speech Dataset with Dialogues, Narratives and Actions</strong><br><em>Chuanqi Cheng, Hongda Sun, Bo Du, Shuo Shang, Xinrong Hu, Rui Yan</em></li>
  <li><strong>LLaMA-Omni 2: LLM-based Real-time Spoken Chatbot with Autoregressive Streaming Speech Synthesis</strong><br><em>Qingkai Fang, Yan Zhou, Shoutao Guo, Shaolei Zhang, Yang Feng</em></li>
  <li><strong>Error Comparison Optimization for Large Language Models on Aspect-Based Sentiment Analysis</strong><br><em>Qianlong Wang, Keyang Ding, Hengxin Gao, Hui Wang, Ruifeng Xu</em></li>
  <li><strong>The AI Gap: How Socioeconomic Status Affects Language Technology Interactions</strong><br><em>Elisa Bassignana, Amanda Cercas Curry, Dirk Hovy</em></li>
  <li><strong>Probing LLMs for Multilingual Discourse Generalization Through a Unified Label Set</strong><br><em>Florian Eichin, Yang Janet Liu, Barbara Plank, Michael A. Hedderich</em></li>
  <li><strong>Crowdsource, Crawl, or Generate? Creating SEA-VL, a Multicultural Vision-Language Dataset for Southeast Asia</strong><br><em>Samuel Cahyawijaya, Holy Lovenia, Joel Ruben Antony Moniz, Tack Hwa Wong, Mohammad Rifqi Farhansyah, Thant Thiri Maung, Frederikus Hudi, David Anugraha, Muhammad Ravi Shulthan Habibi, Muhammad Reza Qorib, Amit Agarwal, Joseph Marvin Imperial, Hitesh Laxmichand Patel, Vicky Feliren, Bahrul Ilmi Nasution, Manuel Antonio Rufino, Genta Indra Winata, Rian Adam Rajagede, Carlos Rafael Catalan, Mohamed Fazli Mohamed Imam, Priyaranjan Pattnayak, Salsabila Zahirah Pranida, Kevin Pratama, Yeshil Bangera, Adisai Na-Thalang, Patricia Nicole Monderin, Yueqi Song, christian simon, Lynnette Hui Xian Ng, Richardy Lobo Sapan, Taki Hasan Rafi, Bin Wang, Supryadi, Kanyakorn Veerakanjana, Piyalitt Ittichaiwong, Matthew Theodore Roque, Karissa Vincentio, Takdanai Kreangphet, Phakphum Artkaew, Kadek Hendrawan Palgunadi, Yanzhi Yu, Rochana Prih Hastuti, William Nixon, Mithil Bangera, Adrian Xuan Wei Lim, Aye Hninn Khine, Hanif Muhammad Zhafran, Teddy Ferdinan, Audra Aurora Izzani, Ayushman Singh, Evan, Jauza Akbar Krito, Michael Anugraha, Fenal Ashokbhai Ilasariya, Haochen Li, John Amadeo Daniswara, Filbert Aurelian Tjiaranata, Eryawan Presma Yulianrifat, Can Udomcharoenchaikit, Fadil Risdian Ansori, Mahardika Krisna Ihsani, Giang Nguyen, Anab Maulana Barik, Dan John Velasco, Rifo Ahmad Genadi, Saptarshi Saha, Chengwei Wei, Isaiah Edri W. Flores, Kenneth Chen Ko Han, Anjela Gail D. Santos, Wan Shen Lim, Kaung Si Phyo, Tim Santos, Meisyarah Dwiastuti, Jiayun Luo, Jan Christian Blaise Cruz, Ming Shan Hee, Ikhlasul Akmal Hanif, M.Alif Al Hakim, Muhammad Rizky Sya’ban, Kun Kerdthaisong, Lester James Validad Miranda, Fajri Koto, Tirana Noor Fatyanosa, Alham Fikri Aji, Jostin Jerico Rosal, Jun Kevin, Robert Wijaya, Onno P. Kampman, Ruochen Zhang, Börje F. Karlsson, Peerat Limkonchotiwat</em></li>
  <li><strong>Soundwave: Less is More for Speech-Text Alignment in LLMs</strong><br><em>Yuhao Zhang, Zhiheng Liu, Fan Bu, Ruiyu Zhang, Benyou Wang, Haizhou Li</em></li>
  <li><strong>RoToR: Towards More Reliable Responses for Order-Invariant Inputs</strong><br><em>Soyoung Yoon, Dongha Ahn, Youngwon Lee, Minkyu Jung, HyungJoo Jang, seung-won hwang</em></li>
  <li><strong>Global MMLU: Understanding and Addressing Cultural and Linguistic Biases in Multilingual Evaluation</strong><br><em>Shivalika Singh, Angelika Romanou, Clémentine Fourrier, Jian Gang Ngui, David Ifeoluwa Adelani, Daniel Vila-Suero, Peerat Limkonchotiwat, Kelly Marchisio, Wei Qi Leong, Yosephine Susanto, Raymond Ng, Shayne Longpre, Sebastian Ruder, Wei-Yin Ko, Antoine Bosselut, Alice Oh, Andre Martins, Daphne Ippolito, Enzo Ferrante, Leshem Choshen, Marzieh Fadaee, Beyza Ermis, Sara Hooker</em></li>
  <li><strong>Improving Dialogue Discourse Parsing through Discourse-aware Utterance Clarification</strong><br><em>Yaxin Fan, Peifeng Li, Qiaoming Zhu</em></li>
  <li><strong>ImPart: Importance-Aware Delta-Sparsification for Improved Model Compression and Merging in LLMs</strong><br><em>Yan Yang, Yixia Li, Hongru WANG, Xuetao Wei, James Jianqiao Yu, Yun Chen, Guanhua Chen</em></li>
  <li><strong>Words of Warmth: Trust and Sociability Norms for over 26k English Words</strong><br><em>Saif M. Mohammad</em></li>
  <li><strong>BehaviorBox: Automated Behavioral Comparison of Language Models</strong><br><em>Lindia Tjuatja, Graham Neubig</em></li>
  <li><strong>HAF-RM: A Hybrid Alignment Framework for Reward Model Training</strong><br><em>Shujun Liu, Xiaoyu Shen, Yuhang Lai, Siyuan Wang, ShengbinYue, Zengfeng Huang, Xuanjing Huang, zhongyu wei</em></li>
  <li><strong>CULEMO: Cultural Lenses on Emotion - Benchmarking LLMs for Cross-Cultural Emotion Understanding</strong><br><em>Tadesse Destaw Belay, Ahmed Haj Ahmed, Alvin C Grissom II, Iqra Ameer, Grigori Sidorov, Olga Kolesnikova, Seid Muhie Yimam</em></li>
  <li><strong>DiffPO: Diffusion-styled Preference Optimization for Inference Time Alignment of Large Language Models</strong><br><em>Ruizhe Chen, Wenhao Chai, Zhifei Yang, Xiaotian Zhang, Ziyang Wang, Tony Quek, Joey Tianyi Zhou, Soujanya Poria, Zuozhu Liu</em></li>
  <li><strong>MemeQA: Holistic Evaluation of Meme Understanding</strong><br><em>Khoi P. N. Nguyen, Terrence Li, Derek Lou Zhou, Gabriel Xiong, Pranav Balu, Nandhan Alahari, Alan Huang, Tanush Chauhan, Harshavardhan Bala, Emre Guzelordu, Affan Kashfi, Aaron Xu, Suyesh Shrestha, Megan Vu, Jerry Wang, Vincent Ng</em></li>
  <li><strong>LoGU: Long-form Generation with Uncertainty Expressions</strong><br><em>Ruihan Yang, Caiqi Zhang, Zhisong Zhang, Xinting Huang, Sen Yang, Nigel Collier, Dong Yu, Deqing Yang</em></li>
  <li><strong>KiRAG: Knowledge-Driven Iterative Retriever for Enhancing Retrieval-Augmented Generation</strong><br><em>Jinyuan Fang, Zaiqiao Meng, Craig MacDonald</em></li>
  <li><strong>Enhancing Lexicon-Based Text Embeddings with Large Language Models</strong><br><em>Yibin Lei, Tao Shen, Yu Cao, Andrew Yates</em></li>
  <li><strong>CoCoLex: Confidence-guided Copy-based Decoding for Grounded Legal Text Generation</strong><br><em>Santosh T.Y.S.S, Youssef Tarek Elkhayat, Oana Ichim, Pranav Shetty, Dongsheng Wang, Zhiqiang Ma, Armineh Nourbakhsh, Xiaomo Liu</em></li>
  <li><strong>Beyond N-Grams: Rethinking Evaluation Metrics and Strategies for Multilingual Abstractive Summarization</strong><br><em>Itai Mondshine, Tzuf Paz-Argaman, Reut Tsarfaty</em></li>
  <li><strong>CC-Tuning: A Cross-Lingual Connection Mechanism for Improving Joint Multilingual Supervised Fine-Tuning</strong><br><em>Yangfan Ye, Xiaocheng Feng, Zekun Yuan, Xiachong Feng, Libo Qin, Lei Huang, Weitao Ma, Yichong Huang, Zhirui Zhang, Yunfei Lu, Xiaohui Yan, Duyu Tang, Dandan Tu, Bing Qin</em></li>
  <li><strong>SConU: Selective Conformal Uncertainty in Large Language Models</strong><br><em>Zhiyuan Wang, Qingni Wang, Yue Zhang, Tianlong Chen, Xiaofeng Zhu, Xiaoshuang Shi, Kaidi Xu</em></li>
  <li><strong>MegaPairs: Massive Data Synthesis for Universal Multimodal Retrieval</strong><br><em>Junjie Zhou, yongping xiong, Zheng Liu, Ze Liu, Shitao Xiao, Yueze Wang, Bo Zhao, Chen Jason Zhang, Defu Lian</em></li>
  <li><strong>When GPT Spills the Tea: Comprehensive Assessment of Knowledge File Leakage in GPTs</strong><br><em>Xinyue Shen, Yun Shen, Michael Backes, Yang Zhang</em></li>
  <li><strong>UniCodec: Unified Audio Codec with Single Domain-Adaptive Codebook</strong><br><em>Yidi Jiang, Qian Chen, Shengpeng Ji, Yu Xi, Wen Wang, Chong Zhang, Xianghu Yue, ShiLiang Zhang, Haizhou Li</em></li>
  <li><strong>KERL: Knowledge-Enhanced Personalized Recipe Recommendation using Large Language Models</strong><br><em>Fnu Mohbat, Mohammed J Zaki</em></li>
  <li><strong>Multilingual Arbitration: Optimizing Data Pools to Accelerate Multilingual Progress</strong><br><em>Ayomide Odumakinde, Daniel D’souza, Pat Verga, Beyza Ermis, Sara Hooker</em></li>
  <li><strong>Controlled Low-Rank Adaptation with Subspace Regularization for Continued Training on Large Language Models</strong><br><em>Yuheng Lu, Bingshuo Qian, Caixia Yuan, Huixing Jiang, Xiaojie Wang</em></li>
  <li><strong>Chinese SimpleQA: A Chinese Factuality Evaluation for Large Language Models</strong><br><em>Yancheng He, Shilong Li, Jiaheng Liu, Yingshui Tan, Weixun Wang, Hui Huang, Xingyuan Bu, Hangyu Guo, Chengwei Hu, Boren Zheng, Zhuoran Lin, Dekai Sun, Zhicheng Zheng, Wenbo Su, Bo Zheng</em></li>
  <li><strong>PVP: An Image Dataset for Personalized Visual Persuasion with Persuasiveness Ratings, Persuasion Strategies, and Viewer Characteristic</strong><br><em>Junseo Kim, Jongwook Han, Dongmin Choi, Jongwook Yoon, Eun-Ju Lee, Yohan Jo</em></li>
  <li><strong>Any Information Is Just Worth One Single Screenshot: Unifying Search With Visualized Information Retrieval</strong><br><em>Zheng Liu, Ze Liu, Zhengyang Liang, Junjie Zhou, Shitao Xiao, Chao Gao, Chen Jason Zhang, Defu Lian</em></li>
  <li><strong>Tunable LLM-based Proactive Recommendation Agent</strong><br><em>Mingze Wang, Chongming Gao, Wenjie Wang, Yangyang Li, Fuli Feng</em></li>
  <li><strong>AgentRM: Enhancing Agent Generalization with Reward Modeling</strong><br><em>Yu Xia, Jingru Fan, Weize Chen, Siyu Yan, Xin Cong, Zhong Zhang, Yaxi Lu, Yankai Lin, Zhiyuan Liu, Maosong Sun</em></li>
  <li><strong>Score Consistency Meets Preference Alignment: Dual-Consistency for Partial Reward Modeling</strong><br><em>Bin Xie, Bingbing Xu, Yige Yuan, Shengmao Zhu, Huawei Shen</em></li>
  <li><strong>Segment-Based Attention Masking for GPTs</strong><br><em>Shahar Katz, Liran Ringel, Yaniv Romano, Lior Wolf</em></li>
  <li><strong>Cramming 1568 Tokens into a Single Vector and Back Again: Exploring the Limits of Embedding Space Capacity</strong><br><em>Yuri Kuratov, Mikhail Arkhipov, Aydar Bulatov, Mikhail Burtsev</em></li>
  <li><strong>Bi-Tuning with Collaborative Information for Controllable LLM-based Sequential Recommendation</strong><br><em>Xinyu Zhang, Linmei Hu, Luhao Zhang, Wentao Cheng, Yashen Wang, Ge Shi, Chong Feng, Liqiang Nie</em></li>
  <li><strong>A Modular Approach for Clinical SLMs Driven by Synthetic Data with Pre-Instruction Tuning, Model Merging, and Clinical-Tasks Alignment</strong><br><em>Jean-Philippe Corbeil, Amin Dada, Jean-Michel Attendu, Asma Ben Abacha, Alessandro Sordoni, Lucas Caccia, Francois Beaulieu, Thomas Lin, Jens Kleesiek, Paul Vozila</em></li>
  <li><strong>DIVE into MoE: Diversity-Enhanced Reconstruction of Large Language Models from Dense into Mixture-of-Experts</strong><br><em>Yuchen Feng, Bowen Shen, Naibin Gu, Jiaxuan Zhao, Peng Fu, Zheng Lin, Weiping Wang</em></li>
  <li><strong>DAC: A Dynamic Attention-aware Approach for Task-Agnostic Prompt Compression</strong><br><em>Yi Zhao, Zuchao Li, hai zhao, Baoyuan Qi, Liu Guoming</em></li>
  <li><strong>Computation Mechanism Behind LLM Position Generalization</strong><br><em>Chi Han, Heng Ji</em></li>
  <li><strong>IPO: Your Language Model is Secretly a Preference Classifier</strong><br><em>Shivank Garg, Ayush Singh, Shweta Singh, Paras Chopra</em></li>
  <li><strong>Reversal of Thought: Enhancing Large Language Models with Preference-Guided Reverse Reasoning Warm-up</strong><br><em>Jiahao Yuan, Dehui du, Hao Zhang, Zixiang Di, Usman Naseem</em></li>
  <li><strong>Déjà Vu? Decoding Repeated Reading from Eye Movements</strong><br><em>Yoav Meiri, Omer Shubi, Cfir Avraham Hadar, Ariel Kreisberg Nitzav, Yevgeni Berzak</em></li>
  <li><strong>LLMs can be easily Confused by Instructional Distractions</strong><br><em>Yerin Hwang, Yongil Kim, Jahyun Koo, Taegwan Kang, Hyunkyung Bae, Kyomin Jung</em></li>
  <li><strong>PlanGenLLMs: A Modern Survey of LLM Planning Capabilities</strong><br><em>Hui Wei, Zihao Zhang, Shenghua He, Tian Xia, Shijia Pan, Fei Liu</em></li>
  <li><strong>IAM: Efficient Inference through Attention Mapping between Different-scale LLMs</strong><br><em>Yi Zhao, Zuchao Li, hai zhao</em></li>
  <li><strong>nvAgent: Automated Data Visualization from Natural Language via Collaborative Agent Workflow</strong><br><em>Geliang Ouyang, Jingyao Chen, Zhihe Nie, Yi Gui, Yao Wan, Hongyu Zhang, Dongping Chen</em></li>
  <li><strong>ZIPA: A family of efficient models for multilingual phone recognition</strong><br><em>Jian Zhu, Farhan Samir, Eleanor Chodroff, David R. Mortensen</em></li>
  <li><strong>GRACE: A Granular Benchmark for Evaluating Model Calibration against Human Calibration</strong><br><em>Yoo Yeon Sung, Eve Fleisig, Yu Hou, Ishan Upadhyay, Jordan Lee Boyd-Graber</em></li>
  <li><strong>That doesn’t sound right: Evaluating speech transcription quality in field linguistics corpora</strong><br><em>Eric Le Ferrand, Bo Jiang, Emily Prud’hommeaux, Joshua Hartshorne</em></li>
  <li><strong>Dynamic Evaluation with Cognitive Reasoning for Multi-turn Safety of Large Language Models</strong><br><em>Lanxue Zhang, Yanan Cao, Yuqiang Xie, Fang Fang, Yangxi Li</em></li>
  <li><strong>Is That Your Final Answer? Test-Time Scaling Improves Selective Question Answering</strong><br><em>William Jurayj, Jeffrey Cheng, Benjamin Van Durme</em></li>
  <li><strong>From Tools to Teammates: Evaluating LLMs in Multi-Session Coding Interactions</strong><br><em>Nathanaël Carraz Rakotonirina, Mohammed Hamdy, Jon Ander Campos, Lucas Weber, Alberto Testoni, Marzieh Fadaee, Sandro Pezzelle, Marco Del Tredici</em></li>
  <li><strong>Guiding not Forcing: Enhancing the Transferability of Jailbreaking Attacks on LLMs via Removing Superfluous Constraints</strong><br><em>Junxiao Yang, Zhexin Zhang, Shiyao Cui, Hongning Wang, Minlie Huang</em></li>
  <li><strong>Multilingual Text-to-Image Generation Magnifies Gender Stereotypes</strong><br><em>Felix Friedrich, Katharina Hämmerl, Patrick Schramowski, Manuel Brack, Jindřich Libovický, Alexander Fraser, Kristian Kersting</em></li>
  <li><strong>Adversarial Alignment with Anchor Dragging Drift ($A^3D^2$): Multimodal Domain Adaptation with Partially Shifted Modalities</strong><br><em>Jun Sun, Xinxin Zhang, Simin Hong, Jian Zhu, Lingfang Zeng</em></li>
  <li><strong>A Reality Check on Context Utilisation for Retrieval-Augmented Generation</strong><br><em>Lovisa Hagström, Sara Vera Marjanovic, Haeun Yu, Arnav Arora, Christina Lioma, Maria Maistro, Pepa Atanasova, Isabelle Augenstein</em></li>
  <li><strong>CU-MAM: Coherence-Driven Unified Macro-Structures for Argument Mining</strong><br><em>Debela Gemechu, Chris Reed</em></li>
  <li><strong>Safer or Luckier? LLMs as Safety Evaluators Are Not Robust to Artifacts</strong><br><em>Hongyu Chen, Seraphina Goldfarb-Tarrant</em></li>
  <li><strong>Text-to-ES Bench: A Comprehensive Benchmark for Converting Natural Language to Elasticsearch Query</strong><br><em>DonggeXue, Zhili Pu, Zhentao Xia, Hongli Sun, Ruihui Hou, Guangya Yu, Yupian Lin, Yongqi Fan, Jingping Liu, Tong Ruan</em></li>
  <li><strong>AlignDistil: Token-Level Language Model Alignment as Adaptive Policy Distillation</strong><br><em>Songming Zhang, Xue Zhang, Tong Zhang, Bojie Hu, Yufeng Chen, Jinan Xu</em></li>
  <li><strong>Acoustic Individual Identification of White-Faced Capuchin Monkeys Using Joint Multi-Species Embeddings</strong><br><em>Álvaro Vega-Hidalgo, Artem Abzaliev, Thore Bergman, Rada Mihalcea</em></li>
  <li><strong>DARS: Dynamic Action Re-Sampling to Enhance Coding Agent Performance by Adaptive Tree Traversal</strong><br><em>Vaibhav Aggarwal, Ojasv Kamal, Abhinav Japesh, Zhijing Jin, Bernhard Schölkopf</em></li>
  <li><strong>Steering off Course: Reliability Challenges in Steering Language Models</strong><br><em>Patrick Queiroz Da Silva, Hari Sethuraman, Dheeraj Rajagopal, Hannaneh Hajishirzi, Sachin Kumar</em></li>
  <li><strong>Impartial Multi-task Representation Learning via Variance-invariant Probabilistic Decoding</strong><br><em>Dou Hu, Lingwei Wei, Wei Zhou, Songlin Hu</em></li>
  <li><strong>If Eleanor Rigby Had Met ChatGPT: A Study on Loneliness in a Post-LLM World</strong><br><em>Adrian de Wynter</em></li>
  <li><strong>Integrating Audio, Visual, and Semantic Information for Enhanced Multimodal Speaker Diarization on Multi-party Conversation</strong><br><em>Luyao Cheng, Hui Wang, Chong Deng, Siqi Zheng, Yafeng Chen, Rongjie Huang, Qinglin Zhang, Qian Chen, Xihao Li, Wen Wang</em></li>
  <li><strong>Vulnerability of LLMs to Vertically Aligned Text Manipulations</strong><br><em>Zhecheng Li, Yiwei Wang, Bryan Hooi, Yujun Cai, Zhen Xiong, Nanyun Peng, Kai-Wei Chang</em></li>
  <li><strong>AutoMixer: Checkpoint Artifacts as Automatic Data Mixers</strong><br><em>Ernie Chang, Yang Li, Patrick Huber, Vish Vogeti, David Kant, Yangyang Shi, Vikas Chandra</em></li>
  <li><strong>Generalized Attention Flow: Feature Attribution for Transformer Models via Maximum Flow</strong><br><em>Behrooz Azarkhalili, Maxwell W. Libbrecht</em></li>
  <li><strong>Beyond Prompting: An Efficient Embedding Framework for Open-Domain Question Answering</strong><br><em>Zhanghao Hu, Hanqi Yan, Qinglin Zhu, Zhenyi Shen, Yulan He, Lin Gui</em></li>
  <li><strong>AIR-Bench: Automated Heterogeneous Information Retrieval Benchmark</strong><br><em>Jianlyu Chen, Nan Wang, Chaofan Li, Bo Wang, Shitao Xiao, Han Xiao, Hao Liao, Defu Lian, Zheng Liu</em></li>
  <li><strong>SELF-PERCEPT: Introspection Improves Large Language Models’ Detection of Multi-Person Mental Manipulation in Conversations</strong><br><em>Danush Khanna, Pratinav Seth, Sidhaarth Sredharan Murali, Aditya Kumar Guru, Siddharth Shukla, Tanuj Tyagi, SANDEEP CHAURASIA, Kripabandhu Ghosh</em></li>
  <li><strong>WE-MATH: Does Your Large Multimodal Model Achieve Human-like Mathematical Reasoning?</strong><br><em>Runqi Qiao, Qiuna Tan, Guanting Dong, MinhuiWu, Chong Sun, Xiaoshuai Song, Jiapeng Wang, Zhuoma GongQue, Shanglin Lei, YiFan Zhang, Zhe Wei, Miaoxuan Zhang, Runfeng Qiao, Xiao Zong, Yida Xu, Peiqing Yang, Zhimin Bao, Muxi Diao, Chen Li, Honggang Zhang</em></li>
  <li><strong>Modeling the Evolution of English Noun Compounds with Feature-Rich Diachronic Compositionality Prediction</strong><br><em>Filip Miletić, Sabine Schulte im Walde</em></li>
  <li><strong>What’s the Difference? Supporting Users in Identifying the Effects of Prompt and Model Changes Through Token Patterns</strong><br><em>Michael A. Hedderich, Anyi Wang, Raoyuan Zhao, Florian Eichin, Jonas Fischer, Barbara Plank</em></li>
  <li><strong>V-Oracle: Making Progressive Reasoning in Deciphering Oracle Bones for You and Me</strong><br><em>Runqi Qiao, Qiuna Tan, Guanting Dong, MinhuiWu, Jiapeng Wang, YiFan Zhang, Zhuoma GongQue, Chong Sun, Yida Xu, Yadong Xue, Ye Tian, Zhimin Bao, LAN YANG, Chen Li, Honggang Zhang</em></li>
  <li><strong>Unveiling Cultural Blind Spots: Analyzing the Limitations of mLLMs in Procedural Text Comprehension</strong><br><em>Amir Hossein Yari, Fajri Koto</em></li>
  <li><strong>Improving Language and Modality Transfer in Translation by Character-level Modeling</strong><br><em>Ioannis Tsiamas, David Dale, Marta R. Costa-jussà</em></li>
  <li><strong>DialUp! Modeling the Language Continuum by Adapting Models to Dialects and Dialects to Models</strong><br><em>Niyati Bafna, Emily Chang, Nathaniel Romney Robinson, David R. Mortensen, Kenton Murray, David Yarowsky, Hale Sirin</em></li>
  <li><strong>AutoMixAlign: Adaptive Data Mixing for Multi-Task Preference Optimization in LLMs</strong><br><em>Nicholas E. Corrado, Julian Katz-Samuels, Adithya M Devraj, Hyokun Yun, Chao Zhang, Yi Xu, Yi Pan, Bing Yin, Trishul Chilimbi</em></li>
  <li><strong>A Variational Approach for Mitigating Entity Bias in Relation Extraction</strong><br><em>Samuel Mensah, Elena Kochkina, Jabez Magomere, Joy Prakash Sain, Simerjot Kaur, Charese Smiley</em></li>
  <li><strong>Modelling Complex Semantics Relation with Contrastively Fine-Tuned Relational Encoders</strong><br><em>Naïm Es-sebbani, Esteban Marquer, Zied Bouraoui</em></li>
  <li><strong>Error-driven Data-efficient Large Multimodal Model Tuning</strong><br><em>Barry Menglong Yao, Qifan Wang, Lifu Huang</em></li>
  <li><strong>Planning with Diffusion Models for Target-Oriented Dialogue Systems</strong><br><em>Hanwen Du, Bo Peng, Xia Ning</em></li>
  <li><strong>Interactive and Expressive Code-Augmented Planning with Large Language Models</strong><br><em>Anthony Zhe Liu, Xinhe Wang, Jacob Sansom, Yao Fu, Jongwook Choi, Sungryull Sohn, Jaekyeom Kim, Honglak Lee</em></li>
  <li><strong>Synergistic Weak-Strong Collaboration by Aligning Preferences</strong><br><em>Yizhu Jiao, Xuchao Zhang, Zhaoyang Wang, Yubo Ma, Zhun Deng, Rujia Wang, Chetan Bansal, Saravan Rajmohan, Jiawei Han, Huaxiu Yao</em></li>
  <li><strong>Understanding Silent Data Corruption in LLM Training</strong><br><em>Jeffrey Jian Ma, Hengzhi Pei, Leonard Lausen, George Karypis</em></li>
  <li><strong>Align-SLM: Textless Spoken Language Models with Reinforcement Learning from AI Feedback</strong><br><em>Guan-Ting Lin, Prashanth Gurunath Shivakumar, Aditya Gourav, Yile Gu, Ankur Gandhe, Hung-yi Lee, Ivan Bulyko</em></li>
  <li><strong>Can LLMs Help Uncover Insights about LLMs? A Large-Scale, Evolving Literature Analysis of Frontier LLMs</strong><br><em>Jungsoo Park, Junmo Kang, Gabriel Stanovsky, Alan Ritter</em></li>
  <li><strong>BIG5-CHAT: Shaping LLM Personalities Through Training on Human-Grounded Data</strong><br><em>Wenkai Li, Jiarui Liu, Andy Liu, Xuhui Zhou, Mona T. Diab, Maarten Sap</em></li>
  <li><strong>Deep Temporal Reasoning in Video Language Models: A Cross-Linguistic Evaluation of Action Duration and Completion through Perfect Times</strong><br><em>Olga Loginova, Sofía Ortega Loguinova</em></li>
  <li><strong>Amplifying Trans and Nonbinary Voices: A Community-Centred Harm Taxonomy for LLMs</strong><br><em>Eddie L. Ungless, Sunipa Dev, Cynthia L. Bennett, Rebecca Gulotta, Jasmijn Bastings, Remi Denton</em></li>
  <li><strong>Enhancing Human Evaluation in Machine Translation with Comparative Judgement</strong><br><em>Yixiao Song, Parker Riley, Daniel Deutsch, Markus Freitag</em></li>
  <li><strong>Infogen: Generating Complex Statistical Infographics from Documents</strong><br><em>Akash Ghosh, Aparna Garimella, Pritika Ramu, Sambaran Bandyopadhyay, Sriparna Saha</em></li>
  <li><strong>Partial Colexifications Improve Concept Embeddings</strong><br><em>Arne Rubehn, Johann-Mattis List</em></li>
  <li><strong>Improved Unbiased Watermark for Large Language Models</strong><br><em>Ruibo Chen, Yihan Wu, Junfeng Guo, Heng Huang</em></li>
  <li><strong>MaCP: Minimal yet Mighty Adaptation via Hierarchical Cosine Projection</strong><br><em>Yixian Shen, Qi Bi, JIA-HONG HUANG, Hongyi Zhu, Andy D. Pimentel, Anuj Pathania</em></li>
  <li><strong>Multi-Attribute Steering of Language Models via Targeted Intervention</strong><br><em>Duy Nguyen, Archiki Prasad, Elias Stengel-Eskin, Mohit Bansal</em></li>
  <li><strong>AdaptAgent: Adapting Multimodal Web Agents with Few-Shot Learning from Human Demonstrations</strong><br><em>Gaurav Verma, Rachneet Kaur, Nishan Srishankar, Zhen Zeng, Tucker Balch, Manuela Veloso</em></li>
  <li><strong>Can LLMs Identify Critical Limitations within Scientific Research? A Systematic Evaluation on AI Research Papers</strong><br><em>Zhijian Xu, Yilun Zhao, Manasi Patwardhan, Lovekesh Vig, Arman Cohan</em></li>
  <li><strong>On the Acquisition of Shared Grammatical Representations in Bilingual Language Models</strong><br><em>Catherine Arnett, Tyler A. Chang, James A. Michaelov, Ben Bergen</em></li>
  <li><strong>GenKnowSub: Improving Modularity and Reusability of LLMs through General Knowledge Subtraction</strong><br><em>Mohammadtaha Bagherifard, Sahar Rajabi, Ali Edalat, Yadollah Yaghoobzadeh</em></li>
  <li><strong>Using Shapley interactions to understand how models use structure</strong><br><em>Diganta Misra, Divyansh Singhvi, Andrej Erkelens, Raghav Jain, Isabel Papadimitriou, Naomi Saphra</em></li>
  <li><strong>Adversarial Tokenization</strong><br><em>Renato Geh, Zilei Shao, Guy Van den Broeck</em></li>
  <li><strong>Classifying Unreliable Narrators with Large Language Models</strong><br><em>Anneliese Brei, Katharine Henry, Abhisheik Sharma, Shashank Srivastava, Snigdha Chaturvedi</em></li>
  <li><strong>ConceptCarve: Dynamic Realization of Evidence</strong><br><em>Eylon Caplan, Dan Goldwasser</em></li>
  <li><strong>QQSUM: A Novel Task and Model of Quantitative Query-Focused Summarization for Review-based Product Question Answering</strong><br><em>An Quang Tang, Xiuzhen Zhang, Minh Ngoc Dinh, Zhuang Li</em></li>
  <li><strong>Navigating Rifts in Human-LLM Grounding: Study and Benchmark</strong><br><em>Omar Shaikh, Hussein Mozannar, Gagan Bansal, Adam Fourney, Eric Horvitz</em></li>
  <li><strong>Substance over Style: Evaluating Proactive Conversational Coaching Agents</strong><br><em>Vidya Srinivas, Xuhai Xu, Xin Liu, Kumar Ayush, Isaac Galatzer-Levy, Shwetak Patel, Daniel McDuff, Tim Althoff</em></li>
  <li><strong>Open-World Planning via Lifted Regression with LLM-Inferred Affordances for Embodied Agents</strong><br><em>Xiaotian Liu, Ali Pesaranghader, HANZE LI, Punyaphat Sukcharoenchaikul, Jaehong Kim, Tanmana Sadhu, Hyejeong Jeon, Scott Sanner</em></li>
  <li><strong>(RSA)2: A Rhetorical-Strategy-Aware Rational Speech Act Framework for Figurative Language Understanding</strong><br><em>Cesare Spinoso-Di Piano, David Eric Austin, Pablo Piantanida, Jackie CK Cheung</em></li>
  <li><strong>The Role of Abstract Representations and Observed Preferences in the Ordering of Binomials in Large Language Models</strong><br><em>Zachary Nicholas Houghton, Kenji Sagae, Emily Morgan</em></li>
  <li><strong>SYNTHIA: Novel Concept Design with Affordance Composition</strong><br><em>Hyeonjeong Ha, Xiaomeng Jin, Jeonghwan Kim, Jiateng Liu, Zhenhailong Wang, Khanh Duy Nguyen, Ansel Blume, Nanyun Peng, Kai-Wei Chang, Heng Ji</em></li>
  <li><strong>Consistent Client Simulation for Motivational Interviewing-based Counseling</strong><br><em>Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, Nicholas Gabriel Lim, Cameron Tan Shi Ern, Phey Ling KIT, Jenny Giam Xiuhui, John Pinto, Ee-Peng Lim</em></li>
  <li><strong>AUTALIC: A Dataset for Anti-AUTistic Ableist Language In Context</strong><br><em>Naba Rizvi, Harper Strickland, Daniel Gitelman, Tristan Cooper, Alexis Morales Flores, Aekta Kallepalli, Akshat Alurkar, Haaset Owens, Saleha Ahmedi, Isha Khirwadkar, Imani N. S. Munyaka, Nedjma Ousidhoum</em></li>
  <li><strong>Structural Reasoning Improves Molecular Understanding of LLM</strong><br><em>Yunhui Jang, Jaehyung Kim, Sungsoo Ahn</em></li>
  <li><strong>CAMI: A Counselor Agent Supporting Motivational Interviewing through State Inference and Topic Exploration</strong><br><em>Yizhe Yang, Palakorn Achananuparp, Heyan Huang, Jing Jiang, Phey Ling KIT, Nicholas Gabriel Lim, Cameron Tan Shi Ern, Ee-Peng Lim</em></li>
  <li><strong>Know You First and Be You Better: Modeling Human-Like User Simulators via Implicit Profiles</strong><br><em>Kuang Wang, Xianfei Li, Shenghao Yang, Li Zhou, Feng Jiang, Haizhou Li</em></li>
  <li><strong>Targeted Syntactic Evaluation for Grammatical Error Correction</strong><br><em>Aomi Koyama, Masato Mita, Su-Youn Yoon, Yasufumi Takama, Mamoru Komachi</em></li>
  <li><strong>VQ-Eval: Evaluating Multimodal LLMs for Generating Feedback on AIGC Videos</strong><br><em>Tingyu Song, Guo Gan, Tongyan Hu, Yilun Zhao</em></li>
  <li><strong>Language Model Fine-Tuning on Scaled Survey Data for Predicting Distributions of Public Opinions</strong><br><em>Joseph Suh, Erfan Jahanparast, Suhong Moon, Minwoo Kang, Serina Chang</em></li>
  <li><strong>SAD-LM: A Large-Scale Generalist Diffusion Language Model</strong><br><em>Jaesung Tae, Hamish Ivison, Sachin Kumar, Arman Cohan</em></li>
  <li><strong>Detecting LLM-Generated Korean Text through Linguistic Feature Analysis</strong><br><em>Shinwoo Park, Shubin Kim, Do-Kyung Kim, Yo-Sub Han</em></li>
  <li><strong>Uncovering the Impact of Chain-of-Thought Reasoning for Direct Preference Optimization: Lessons from Text-to-SQL</strong><br><em>Hanbing Liu, Haoyang Li, Xiaokang Zhang, Ruotong Chen, Haiyong Xu, Tian Tian, Qi Qi, Jing Zhang</em></li>
  <li><strong>On Generalization across Measurement Systems: LLMs Entail More Test-Time Compute for Underrepresented Cultures</strong><br><em>Minh Duc Bui, Kyung eun Park, Goran Glavaš, Fabian David Schmidt, Katharina von der Wense</em></li>
  <li><strong>CORDIAL: Can Multimodal Large Language Models Effectively Understand Coherence Relationships?</strong><br><em>Aashish Anantha Ramakrishnan, Aadarsh Anantha Ramakrishnan, Dongwon Lee</em></li>
  <li><strong>Veracity Bias and Beyond: Uncovering LLMs’ Hidden Beliefs in Problem-Solving Reasoning</strong><br><em>Yue Zhou, Barbara Di Eugenio</em></li>
  <li><strong>Optimal Transport-Based Token Weighting scheme for Enhanced Preference Optimization</strong><br><em>Meng Li, Guangda Huzhang, Haibo Zhang, Xiting Wang, Anxiang Zeng</em></li>
  <li><strong>LLM Meets Scene Graph: Can Large Language Models Understand and Generate Scene Graphs? A Benchmark and Empirical Study</strong><br><em>Dongil Yang, Minjin Kim, Sunghwan Kim, Beong-woo Kwak, Minjun Park, Jinseok Hong, Woontack Woo, Jinyoung Yeo</em></li>
  <li><strong>Beyond Frameworks: Unpacking Collaboration Strategies in Multi-Agent Systems</strong><br><em>Haochun Wang, Sendong Zhao, Jingbo Wang, Zewen Qiang, Bing Qin, Ting Liu</em></li>
  <li><strong>The Invisible Hand: Unveiling Provider Bias in Large Language Models for Code Generation</strong><br><em>Xiaoyu Zhang, Juan Zhai, Shiqing Ma, Qingshuang Bao, Weipeng Jiang, Qian Wang, Chao Shen, Yang Liu</em></li>
  <li><strong>K/DA: Automated Data Generation Pipeline for Detoxifying Implicitly Offensive Language in Korean</strong><br><em>Minkyeong Jeon, Hyemin Jeong, Yerang Kim, Jiyoung Kim, Jae Hyeon Cho, Byung-Jun Lee</em></li>
  <li><strong>THOR-MoE: Hierarchical Task-Guided and Context-Responsive Routing for Neural Machine Translation</strong><br><em>Yunlong Liang, Fandong Meng, Jie Zhou</em></li>
  <li><strong>Neuron Empirical Gradient: Discovering and Quantifying Neurons’ Global Linear Controllability</strong><br><em>Xin Zhao, Zehui Jiang, Naoki Yoshinaga</em></li>
  <li><strong>Can third-parties read our emotions?</strong><br><em>Jiayi Li, Yingfan Zhou, Pranav Narayanan Venkit, Halima Binte Islam, Sneha Arya, Shomir Wilson, Sarah Rajtmajer</em></li>
  <li><strong>OZSpeech: One-step Zero-shot Speech Synthesis with Learned-Prior-Conditioned Flow Matching</strong><br><em>Nghia Huynh Nguyen Hieu, Ngoc Son Nguyen, Huynh Nguyen Dang, Thieu Vo, Truong-Son Hy, Van Nguyen</em></li>
  <li><strong>World Modeling Makes a Better Planner: Dual Preference Optimization for Embodied Task Planning</strong><br><em>Siyin Wang, Zhaoye Fei, Qinyuan Cheng, Shiduo Zhang, Panpan Cai, Jinlan Fu, Xipeng Qiu</em></li>
  <li><strong>JailbreakRadar: Comprehensive Assessment of Jailbreak Attacks Against LLMs</strong><br><em>Junjie Chu, Yugeng Liu, Ziqing Yang, Xinyue Shen, Michael Backes, Yang Zhang</em></li>
  <li><strong>CogniBench: A Legal-inspired Framework and Dataset for Assessing Cognitive Faithfulness of Large Language Models</strong><br><em>Xiaqiang Tang, Jian Li, Keyu Hu, nan du, Xiaolong Li, Xi Zhang, Weigao Sun, Sihong Xie</em></li>
  <li><strong>Neural Incompatibility: The Unbridgeable Gap of Cross-Scale Parametric Knowledge Transfer in Large Language Models</strong><br><em>Yuqiao Tan, Shizhu He, Kang Liu, Jun Zhao</em></li>
  <li><strong>Enhancing Mathematical Reasoning in LLMs by Stepwise Correction</strong><br><em>Zhenyu Wu, Qingkai Zeng, Zhihan Zhang, Zhaoxuan Tan, Chao Shen, Meng Jiang</em></li>
  <li><strong>PsyDial: A Large-scale Long-term Conversational Dataset for Mental Health Support</strong><br><em>Huachuan Qiu, Zhenzhong Lan</em></li>
  <li><strong>Enhancing Goal-oriented Proactive Dialogue Systems via Consistency Reflection and Correction</strong><br><em>Didi Zhang, Yaxin Fan, Peifeng Li, Qiaoming Zhu</em></li>
  <li><strong>Exclusion of Thought: Mitigating Cognitive Load in Large Language Models for Enhanced Reasoning in Multiple-Choice Tasks</strong><br><em>Qihang Fu, Yongbin Qin, Ruizhang Huang, Yanping Chen, Yulin Zhou, Lintao Long</em></li>
  <li><strong>Registering Source Tokens to Target Language Spaces in Multilingual Neural Machine Translation</strong><br><em>Zhi Qu, Yiran Wang, Jiannan Mao, Chenchen Ding, Hideki Tanaka, Masao Utiyama, Taro Watanabe</em></li>
  <li><strong>VisuoThink: Empowering LVLM Reasoning with Multimodal Tree Search</strong><br><em>Yikun Wang, Siyin Wang, Qinyuan Cheng, Zhaoye Fei, Liang Ding, Qipeng Guo, Dacheng Tao, Xipeng Qiu</em></li>
  <li><strong>Automated CAD Modeling Sequence Generation from Text Descriptions via Transformer-Based Large Language Models</strong><br><em>JianXing Liao, Junyan Xu, Yatao Sun, Maowen Tang, Sicheng He, Jingxian Liao, Shui Yu, Yun Li, Xiaohong Guan</em></li>
  <li><strong>LED-Merging: Mitigating Safety-Utility Conflicts in Model Merging with Location-Election-Disjoint</strong><br><em>Qianli Ma, Dongrui Liu, Qian Chen, Linfeng Zhang, Jing Shao</em></li>
  <li><strong>Dolphin: Moving Towards Closed-loop Auto-research through Thinking, Practice, and Feedback</strong><br><em>Jiakang Yuan, Xiangchao Yan, Bo Zhang, Tao Chen, Botian Shi, Wanli Ouyang, Yu Qiao, LEI BAI, Bowen Zhou</em></li>
  <li><strong>PerSphere: A Comprehensive Framework for Multi-Faceted Perspective Retrieval and Summarization</strong><br><em>Yun Luo, Yingjie Li, Xiangkun Hu, Qinglin Qi, Fang Guo, Qipeng Guo, Zheng Zhang, Yue Zhang</em></li>
  <li><strong>Prompt-Guided Internal States for Hallucination Detection of Large Language Models</strong><br><em>Fujie Zhang, Peiqi Yu, Biao Yi, Baolei Zhang, Tong Li, Zheli Liu</em></li>
  <li><strong>Typology-Guided Adaptation for African NLP</strong><br><em>Ndapa Nakashole</em></li>
  <li><strong>Don’t Erase, Inform! Detecting and Contextualizing Harmful Language in Cultural Heritage Collections</strong><br><em>Orfeas Menis Mastromichalakis, Jason Liartis, Kristina Rose, Antoine Isaac, Giorgos Stamou</em></li>
  <li><strong>ECLM: Entity Level Language Model for Spoken Language Understanding with Chain of Intent</strong><br><em>Shangjian Yin, Peijie Huang, JiaTian Chen, Haojing Huang, Yuhong Xu</em></li>
  <li><strong>FaithfulRAG: Fact-Level Conflict Modeling for Context-Faithful Retrieval-Augmented Generation</strong><br><em>Qinggang Zhang, Zhishang Xiang, Yilin Xiao, Le Wang, Junhui Li, Jinsong Su, Xinrun Wang</em></li>
  <li><strong>Knowledge Image Matters: Improving Knowledge-Based Visual Reasoning with Multi-Image Large Language Models</strong><br><em>Guanghui Ye, Huan Zhao, Zhixue Zhao, Xupeng Zha, Yang Liu, Zhihua Jiang</em></li>
  <li><strong>Evaluating Personalized Tool-Augmented LLMs from the Perspectives of Personalization and Proactivity</strong><br><em>Yupu Hao, Pengfei Cao, Zhuoran Jin, Huanxuan Liao, Yubo Chen, Kang Liu, Jun Zhao</em></li>
  <li><strong>GUICourse: From General Vision Language Model to Versatile GUI Agent</strong><br><em>Wentong Chen, Junbo Cui, Jinyi Hu, Yujia Qin, Junjie Fang, Yue Zhao, Chongyi Wang, Jun Liu, Guirong Chen, Yupeng Huo, Yuan Yao, Yankai Lin, Zhiyuan Liu, Maosong Sun</em></li>
  <li><strong>Evaluating Visual and Cultural Interpretation: The K-Viscuit Benchmark with Human-VLM Collaboration</strong><br><em>ChaeHun Park, Yujin Baek, Jaeseok Kim, Yu-Jung Heo, Du-Seong Chang, Jaegul Choo</em></li>
  <li><strong>Maximizing the Effectiveness of Larger BERT Models for Compression</strong><br><em>Wen-Shu Fan, Su Lu, Shangyu Xing, Xin-Chun Li, De-Chuan Zhan</em></li>
  <li><strong>Can LLMs Reason About Program Semantics? A Comprehensive Evaluation of LLMs on Formal Specification Inference</strong><br><em>Thanh Le-Cong, Bach Le, Toby Murray</em></li>
  <li><strong>HACo-Det: A Study Towards Fine-Grained Machine-Generated Text Detection under Human-AI Coauthoring</strong><br><em>Zhixiong Su, Yichen Wang, Herun Wan, Zhaohan Zhang, Minnan Luo</em></li>
  <li><strong>IndicSynth: A Large-Scale Multilingual Synthetic Speech Dataset for Low-Resource Indian Languages</strong><br><em>Divya V Sharma, Vijval Ekbote, Anubha Gupta</em></li>
  <li><strong>Reinforced IR: A Dual Reinforcement Framework For Domain-Adapted Information Retrieval</strong><br><em>Chaofan Li, Jianlyu Chen, Yingxia Shao, Chaozhuo Li, Quanqing Xu, Defu Lian, Zheng Liu</em></li>
  <li><strong>CoIR: A Comprehensive Benchmark for Code Information Retrieval Models</strong><br><em>Xiangyang Li, Kuicai Dong, Yi Quan Lee, Wei Xia, Hao Zhang, Xinyi Dai, Yasheng Wang, Ruiming Tang</em></li>
  <li><strong>Enhancing Multimodal Retrieval via Complementary Information Extraction and Alignment</strong><br><em>Delong Zeng, Yuexiang Xie, Yaliang Li, Ying Shen</em></li>
  <li><strong>JoPA: Explaining Large Language Model’s Generation via Joint Prompt Attribution</strong><br><em>Yurui Chang, Bochuan Cao, Yujia Wang, Jinghui Chen, Lu Lin</em></li>
  <li><strong>Proxy-Driven Robust Multimodal Sentiment Analysis with Incomplete Data</strong><br><em>Aoqiang Zhu, Min Hu, Xiaohua Wang, Jiaoyun Yang, Yiming Tang, Ning An</em></li>
  <li><strong>Not All Terms Matter: Recall-Oriented Adaptive Learning for PLM-aided Query Expansion in Open-Domain Question Answering</strong><br><em>Xinran Chen, Ben He, Xuanang Chen, Le Sun</em></li>
  <li><strong>A Mutual Information Perspective on Knowledge Graph Embedding</strong><br><em>Jiang Li, Xiangdong Su, Zehua Duo, Tian Lan, Xiaotao Guo, Guanglai Gao</em></li>
  <li><strong>Aligned but Blind: Alignment Increases Implicit Bias by Reducing Awareness of Race</strong><br><em>Lihao Sun, Chengzhi Mao, Valentin Hofmann, Xuechunzi Bai</em></li>
  <li><strong>IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization</strong><br><em>Xinghua Zhang, Haiyang Yu, ChengFu, Fei Huang, Yongbin Li</em></li>
  <li><strong>ProMALex: Progressive Modular Adapters for Multi-Jurisdictional Legal Language Modeling</strong><br><em>Santosh T.Y.S.S, Mohamed Hesham Elganayni</em></li>
  <li><strong>Flipping Knowledge Distillation: Leveraging Small Models’ Expertise to Enhance LLMs in Text Matching</strong><br><em>Mingzhe Li, Jing Xiang, Qishen Zhang, Kaiyang Wan, Xiuying Chen</em></li>
  <li><strong>Disentangling Language Medium and Culture Context for Evaluating Multilingual Large Language Models</strong><br><em>Jiahao Ying, Wei Tang, Yiran Zhao, Yixin Cao, Yu Rong, Wenxuan Zhang</em></li>
  <li><strong>Detecting Sockpuppetry on Wikipedia Using Meta-Learning</strong><br><em>Christine de Kock, Luc Raszewski</em></li>
  <li><strong>Diversity-oriented Data Augmentation with Large Language Models</strong><br><em>Zaitian Wang, Jinghan Zhang, Xinhao Zhang, Kunpeng Liu, pengfei wang, Yuanchun Zhou</em></li>
  <li><strong>Can LLMs Understand Unvoiced Speech? Exploring EMG-to-Text Conversion with LLMs</strong><br><em>Payal Mohapatra, Akash Pandey, Xiaoyuan Zhang, Qi Zhu</em></li>
  <li><strong>CoreEval: Automatically Building Contamination-Resilient Datasets with Real-World Knowledge toward Reliable LLM Evaluation</strong><br><em>Jingqian Zhao, Bingbing Wang, Geng Tu, Yice Zhang, Qianlong Wang, Bin Liang, Jing Li, Ruifeng Xu</em></li>
  <li><strong>RiOT: Efficient Prompt Refinement with Residual Optimization Tree</strong><br><em>Chenyi Zhou, Zhengyan Shi, Yuan Yao, Lei Liang, Huajun Chen, Qiang Zhang</em></li>
  <li><strong>Caution for the Environment: LLM Agents are Susceptible to Environmental Distractions</strong><br><em>Xinbei Ma, Yiting Wang, Yao Yao, Tongxin Yuan, Aston Zhang, Zhuosheng Zhang, hai zhao</em></li>
  <li><strong>Decoder-Only LLMs can be Masked Auto-Encoders</strong><br><em>Dan Qiao, Yuan Gao, Zheming Yang, Di Yang, Ziheng Wu, Pengcheng Lu, Minghui Qiu, Juntao Li, Min Zhang</em></li>
  <li><strong>Automatic Evaluation for Text-to-image Generation: Task-decomposed Framework, Distilled Training, and Meta-evaluation Benchmark</strong><br><em>Rong-Cheng Tu, Zi-Ao Ma, Tian Lan, Yuehao Zhao, Heyan Huang, Xian-Ling Mao</em></li>
  <li><strong>Mitigating Lost-in-Retrieval Problems in Retrieval Augmented Multi-Hop Question Answering</strong><br><em>Rongzhi Zhu, Xiangyu Liu, Zequn Sun, Yiwei Wang, Wei Hu</em></li>
  <li><strong>TableLoRA: Low-rank Adaptation on Table Structure Understanding for Large Language Models</strong><br><em>Xinyi He, Yihao Liu, Mengyu Zhou, Yeye He, Haoyu Dong, Shi Han, Zejian Yuan, Dongmei Zhang</em></li>
  <li><strong>Condor: Enhance LLM Alignment with Knowledge-Driven Data Synthesis and Refinement</strong><br><em>Maosongcao, Taolin Zhang, Mo Li, Chuyu Zhang, Yunxin Liu, Conghui He, Haodong Duan, Songyang Zhang, Kai Chen</em></li>
  <li><strong>CulFiT: A Fine-grained Cultural-aware LLM Training Paradigm via Multilingual Critique Data Synthesis</strong><br><em>Ruixiang Feng, Shen Gao, Xiuying Chen, Lisi Chen, Shuo Shang</em></li>
  <li><strong>Decoding Knowledge Attribution in Mixture-of-Experts: A Framework of Basic-Refinement Collaboration and Efficiency Analysis</strong><br><em>Junzhuo Li, Bo Wang, Xiuze Zhou, Peijie Jiang, Jia Liu, Xuming Hu</em></li>
  <li><strong>ChartLens: Fine-grained Visual Attribution in Charts</strong><br><em>Manan Suri, Puneet Mathur, Nedim Lipka, Franck Dernoncourt, Ryan A. Rossi, Dinesh Manocha</em></li>
  <li><strong>LESA: Learnable LLM Layer Scaling-Up</strong><br><em>Yifei Yang, zouying cao, Xinbei Ma, Yao Yao, Zhi Chen, Libo Qin, hai zhao</em></li>
  <li><strong>MMRC: A Large-Scale Benchmark for Understanding Multimodal Large Language Model in Real-World Conversation</strong><br><em>Haochen Xue, Feilong Tang, Ming Hu, Yexin Liu, Qidong Huang, Yulong Li, Chengzhi Liu, Zhongxing Xu, Chong Zhang, Chun-Mei Feng, Yutong Xie, Imran Razzak, Zongyuan Ge, Jionglong Su, Junjun He, Yu Qiao</em></li>
  <li><strong>Towards the Law of Capacity Gap in Distilling Language Models</strong><br><em>Chen Zhang, Qiuchi Li, Dawei Song, Zheyu Ye, Yan Gao, Yao Hu</em></li>
  <li><strong>WhiSPA: Semantically and Psychologically Aligned Whisper with Self-Supervised Contrastive and Student-Teacher Learning</strong><br><em>Rajath Rao, Adithya V Ganesan, Oscar Kjell, Jonah Luby, Akshay Raghavan, Scott M. Feltman, Whitney Ringwald, Ryan L. Boyd, Benjamin J. Luft, Camilo J. Ruggero, Neville Ryant, ROMAN KOTOV, H. Schwartz</em></li>
  <li><strong>Keys to Robust Edits: From Theoretical Insights to Practical Advances</strong><br><em>Jianhao Yan, Futing Wang, Yun Luo, Yafu Li, Yue Zhang</em></li>
  <li><strong>Boosting LLM’s Molecular Structure Elucidation with Knowledge Enhanced Tree Search Reasoning</strong><br><em>Xiang Zhuang, Bin Wu, Jiyu Cui, Kehua Feng, Xiaotong Li, Huabin Xing, Keyan Ding, Qiang Zhang, Huajun Chen</em></li>
  <li><strong>MEMERAG: A Multilingual End-to-End Meta-Evaluation Benchmark for Retrieval Augmented Generation</strong><br><em>María Andrea Cruz Blandón, Jayasimha Talur, Bruno Charron, Dong Liu, Saab Mansour, Marcello Federico</em></li>
  <li><strong>The Role of Visual Modality in Multimodal Mathematical Reasoning: Challenges and Insights</strong><br><em>Yufang Liu, Yao Du, Tao Ji, Jianing Wang, Yang Liu, Yuanbin Wu, Aimin Zhou, Mengdi Zhang, Xunliang Cai</em></li>
  <li><strong>The Essence of Contextual Understanding in Theory of Mind: A Study on Question Answering with Story Characters</strong><br><em>Chulun Zhou, Qiujing Wang, Mo Yu, Xiaoqian Yue, Rui Lu, Jiangnan Li, Yifan Zhou, Shunchi Zhang, Jie Zhou, Wai Lam</em></li>
  <li><strong>S$^2$R: Teaching LLMs to Self-verify and Self-correct via Reinforcement Learning</strong><br><em>Ruotian Ma, Peisong Wang, Cheng Liu, Xingyan Liu, Jiaqi Chen, Bang Zhang, Xin Zhou, nan du, Jia Li</em></li>
  <li><strong>Advancing Collaborative Debates with Role Differentiation through Multi-Agent Reinforcement Learning</strong><br><em>Haoran Li, Ziyi Su, Yun Xue, Zhiliang Tian, YIPING SONG, Minlie Huang</em></li>
  <li><strong>Retrieval-Augmented Fine-Tuning With Preference Optimization For Visual Program Generation</strong><br><em>Deokhyung Kang, Jeonghun Cho, Yejin Jeon, Sunbin Jang, Minsub Lee, JAWOON CHO, Gary Lee</em></li>
  <li><strong>STRICTA: Structured Reasoning in Critical Text Assessment for Peer Review and Beyond</strong><br><em>Nils Dycke, Matej Zečević, Ilia Kuznetsov, Beatrix Suess, Kristian Kersting, Iryna Gurevych</em></li>
  <li><strong>XDAC: XAI-Driven Detection and Attribution of LLM-Generated News Comments in Korean</strong><br><em>Wooyoung Go, Hyoungshick Kim, Alice Oh, Yongdae Kim</em></li>
  <li><strong>CENTAUR: Bridging the Impossible Trinity of Privacy, Efficiency, and Performance in Privacy-Preserving Transformer Inference</strong><br><em>Jinglong Luo, Guanzhong Chen, Yehong Zhang, SHIYU LIU, Hui Wang, Yue Yu, Xun Zhou, Yuan Qi, Zenglin Xu</em></li>
  <li><strong>Silencing Empowerment, Allowing Bigotry: Auditing the Moderation of Hate Speech on Twitch</strong><br><em>Prarabdh Shukla, Wei Yin Chong, Yash Patel, Brennan Schaffner, Danish Pruthi, Arjun Bhagoji</em></li>
  <li><strong>EdiText: Controllable Coarse-to-Fine Text Editing with Diffusion Language Models</strong><br><em>Che Hyun Lee, Heeseung Kim, Jiheum Yeom, Sungroh Yoon</em></li>
  <li><strong>TUMLU: A Unified and Native Language Understanding Benchmark for Turkic Languages</strong><br><em>Jafar Isbarov, Arofat Akhundjanova, Mammad Hajili, Kavsar Huseynova, Dmitry Gaynullin, Anar Rzayev, Osman Tursun, Aizirek Turdubaeva, Ilshat Saetov, Rinat Kharisov, Saule Belginova, Ariana Kenbayeva, Amina Alisheva, Abdullatif Köksal, SAMIR RUSTAMOV, Duygu Ataman</em></li>
  <li><strong>Look Both Ways and No Sink: Converting LLMs into Text Encoders without Training</strong><br><em>Ziyong Lin, Haoyi Wu, Shu Wang, Kewei Tu, Zilong Zheng, Zixia Jia</em></li>
  <li><strong>Mitigating Posterior Salience Attenuation in Long-Context LLMs with Positional Contrastive Decoding</strong><br><em>Zikai Xiao, Ziyang Wang, Wen MA, Yan Zhang, Wei Shen, WangYan, Luqi Gong, Zuozhu Liu</em></li>
  <li><strong>A Statistical and Multi-Perspective Revisiting of the Membership Inference Attack in Large Language Models</strong><br><em>Bowen Chen, Namgi Han, Yusuke Miyao</em></li>
  <li><strong>Around the World in 24 Hours: Probing LLM Knowledge of Time and Place</strong><br><em>Carolin Holtermann, Paul Röttger, Anne Lauscher</em></li>
  <li><strong>Mining the uncertainty patterns of humans and models in the annotation of moral foundations and human values</strong><br><em>Neele Falk, Gabriella Lapesa</em></li>
  <li><strong>“What do you call a dog that is incontrovertibly true? Dogma’’: Testing LLM Generalization through Humor</strong><br><em>Alessio Cocchieri, Luca Ragazzi, Paolo Italiani, Giuseppe Tagliavini, Gianluca Moro</em></li>
  <li><strong>Towards Harmonized Uncertainty Estimation for Large Language Models</strong><br><em>Rui Li, Jing Long, Muge Qi, Heming Xia, Lei Sha, Peiyi Wang, Zhifang Sui</em></li>
  <li><strong>VITAL: A New Dataset for Benchmarking Pluralistic Alignment in Healthcare</strong><br><em>Anudeex Shetty, Amin Beheshti, Mark Dras, Usman Naseem</em></li>
  <li><strong>Are We in the AI-Generated Text World Already? Quantifying and Monitoring AIGT on Social Media</strong><br><em>Zhen Sun, Zongmin Zhang, Xinyue Shen, Ziyi Zhang, Yule Liu, Michael Backes, Yang Zhang, Xinlei He</em></li>
  <li><strong>From English to Second Language Mastery: Enhancing LLMs with Cross-Lingual Continued Instruction Tuning</strong><br><em>Linjuan Wu, Hao-Ran Wei, Baosong Yang, Weiming Lu</em></li>
  <li><strong>WET: Overcoming Paraphrasing Vulnerabilities in Embeddings-as-a-Service with Linear Transformation Watermarks</strong><br><em>Anudeex Shetty, Qiongkai Xu, Jey Han Lau</em></li>
  <li><strong>HoPE: A Novel Positional Encoding Without Long-Term Decay for Enhanced Context Awareness and Extrapolation</strong><br><em>Yuhan Chen, Ang Lv, Jian Luan, Bin Wang, Wei Liu</em></li>
  <li><strong>One QuantLLM for ALL: Fine-tuning Quantized LLMs Once for Efficient Deployments</strong><br><em>Ke Yi, Yuhui Xu, Heng Chang, Yuan Meng, Tong Zhang, Jia Li</em></li>
  <li><strong>Beyond Logits: Aligning Feature Dynamics for Effective Knowledge Distillation</strong><br><em>Guoqiang Gong, Jiaxing Wang, Jin Xu, Deping Xiang, Zicheng Zhang, Leqi Shen, Yifeng Zhang, JunhuaShu, ZhaolongXing, Zhen Chen, Pengzhang Liu, Ke Zhang</em></li>
  <li><strong>Native Sparse Attention: Hardware-Aligned and Natively Trainable Sparse Attention</strong><br><em>Jingyang Yuan, Huazuo Gao, Damai Dai, Junyu Luo, Liang Zhao, Zhengyan Zhang, Zhenda Xie, Yuxing Wei, Lean Wang, Zhiping Xiao, Yuqing Wang, Chong Ruan, Ming Zhang, Wenfeng Liang, Wangding Zeng</em></li>
  <li><strong>DRAE: Dynamic Retrieval-Augmented Expert Networks for Lifelong Learning and Task Adaptation in Robotics</strong><br><em>Yayu Long, Kewei Chen, Long Jin, Mingsheng Shang</em></li>
  <li><strong>MT-RAIG: Novel Benchmark and Evaluation Framework for Retrieval-Augmented Insight Generation over Multiple Tables</strong><br><em>Kwangwook Seo, Donguk Kwon, Dongha Lee</em></li>
  <li><strong>Enhancing Chain-of-Thought Reasoning with Critical Representation Fine-tuning</strong><br><em>Chenxi Huang, Shaotian Yan, Liang Xie, Binbin Lin, Sinan Fan, Yue Xin, Deng Cai, Chen Shen, Jieping Ye</em></li>
  <li><strong>Does the Emotional Understanding of LVLMs Vary Under High-Stress Environments and Across Different Demographic Attributes?</strong><br><em>Jaewook Lee, Yeajin Jang, Oh-Woog KWON, Harksoo Kim</em></li>
  <li><strong>S2WTM: Spherical Sliced-Wasserstein Autoencoder for Topic Modeling</strong><br><em>Suman Adhya, Debarshi Kumar Sanyal</em></li>
  <li><strong>Learning to Look at the Other Side: A Probing Study of Word Semantics in LLMs with Enabled Bidirectional Attention</strong><br><em>Zhaoxin Feng, MA Jianfei, Xiaoyi Bao, Xiaojing Zhao, Emmanuele Chersoni</em></li>
  <li><strong>Tracing and Dissecting How LLMs Recall Factual Knowledge for Real World Questions</strong><br><em>Yiqun Wang, Chaoqun Wan, Sile Hu, Yonggang Zhang, Xiang Tian, Yaowu Chen, Xu Shen, Jieping Ye</em></li>
  <li><strong>Employing Discourse Coherence Enhancement to Improve Cross-Document Event and Entity Coreference Resolution</strong><br><em>Xinyu Chen, Peifeng Li, Qiaoming Zhu</em></li>
  <li><strong>Data Whisperer: Efficient Data Selection for Task-Specific LLM Fine-Tuning via Few-Shot In-Context Learning</strong><br><em>Shaobo Wang, Xiangqi Jin, Ziming Wang, Jize Wang, Jiajun Zhang, Kaixin Li, Zichen Wen, Zhong Li, Conghui He, Xuming Hu, Linfeng Zhang</em></li>
  <li><strong>Synthesizing Post-Training Data for LLMs through Multi-Agent Simulation</strong><br><em>Shuo Tang, Xianghe Pang, Zexi Liu, Bohan Tang, Rui Ye, Tian Jin, Xiaowen Dong, Yanfeng Wang, Siheng Chen</em></li>
  <li><strong>SoftCoT: Soft Chain-of-Thought for Efficient Reasoning with LLMs</strong><br><em>Yige Xu, Xu Guo, Zhiwei Zeng, Chunyan Miao</em></li>
  <li><strong>FCMR: Robust Evaluation of Financial Cross-Modal Multi-Hop Reasoning</strong><br><em>Seunghee Kim, Changhyeon Kim, Taeuk Kim</em></li>
  <li><strong>Beyond Prompt Engineering: Robust Behavior Control in LLMs via Steering Target Atoms</strong><br><em>Mengru Wang, Ziwen Xu, Shengyu Mao, Shumin Deng, Zhaopeng Tu, Huajun Chen, Ningyu Zhang</em></li>
  <li><strong>MobiLoRA: Accelerating LoRA-based LLM Inference on Mobile Devices via Context-aware KV Cache Optimization</strong><br><em>Borui Li, Yitao Wang, Haoran Ma, Ligeng Chen, Jun Xiao, Shuai Wang</em></li>
  <li><strong>Language Models Resist Alignment: Evidence From Data Compression</strong><br><em>Jiaming Ji, Kaile Wang, Tianyi Qiu, Boyuan Chen, Jiayi Zhou, Changye Li, Hantao Lou, Josef Dai, Yunhuai Liu, Yaodong Yang</em></li>
  <li><strong>Beyond the Answer: Advancing Multi-Hop QA with Fine-Grained Graph Reasoning and Evaluation</strong><br><em>Qichuan Liu, Chentao Zhang, Chenfeng Zheng, Guosheng Hu, Xiaodong Li, Zhihong Zhang</em></li>
  <li><strong>Mamba Knockout for Unraveling Factual Information Flow</strong><br><em>Nir Endy, Idan Daniel Grosbard, Yuval Ran-Milo, Yonatan Slutzky, Itay Tshuva, Raja Giryes</em></li>
  <li><strong>Small Changes, Big Impact: How Manipulating a Few Neurons Can Drastically Alter LLM Aggression</strong><br><em>Jaewook Lee, Junseo Jang, Oh-Woog KWON, Harksoo Kim</em></li>
  <li><strong>Towards Widening The Distillation Bottleneck for Reasoning Models</strong><br><em>Huifeng Yin, Yu Zhao, Minghao Wu, Xuanfan Ni, Bo Zeng, huaiyu.wh, Tianqi Shi, Liangying Shao, Chenyang Lyu, Longyue Wang, Weihua Luo, Kaifu Zhang</em></li>
  <li><strong>Curiosity-Driven Reinforcement Learning from Human Feedback</strong><br><em>Haoran Sun, Yekun Chai, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang</em></li>
  <li><strong>T2A-Feedback: Improving Basic Capabilities of Text-to-Audio Generation via Fine-grained AI Feedback</strong><br><em>Zehan Wang, Ke Lei, Chen Zhu, Jiawei Huang, Sashuai zhou, Luping Liu, Xize Cheng, Shengpeng Ji, Zhenhui Ye, Tao Jin, Zhou Zhao</em></li>
  <li><strong>CoE: A Clue of Emotion Framework for Emotion Recognition in Conversations</strong><br><em>Zhiyu Shen, Yunhe Pang, Yanghui Rao, Jianxing Yu</em></li>
  <li><strong>MPO: Multilingual Safety Alignment via Reward Gap Optimization</strong><br><em>Weixiang Zhao, Yulin Hu, Yang Deng, Tongtong Wu, Wenxuan Zhang, Jiahe Guo, An Zhang, Yanyan Zhao, Bing Qin, Tat-Seng Chua, Ting Liu</em></li>
  <li><strong>QualiSpeech: A Speech Quality Assessment Dataset with Natural Language Reasoning and Descriptions</strong><br><em>Siyin Wang, Wenyi Yu, Xianzhao Chen, Xiaohai Tian, Jun Zhang, Lu Lu, Yu Tsao, Junichi Yamagishi, Yuxuan Wang, Chao Zhang</em></li>
  <li><strong>On the Relation Between Fine-Tuning, Topological Properties, and Task Performance in Sense-Enhanced Embeddings</strong><br><em>Deniz Ekin Yavas, Timothée Bernard, Benoit Crabbé, Laura Kallmeyer</em></li>
  <li><strong>Finding Needles in Images: Can Multi-modal LLMs Locate Fine Details?</strong><br><em>Parth Thakkar, Ankush Agarwal, Prasad Kasu, Pulkit Bansal, Chaitanya Devaguptapu</em></li>
  <li><strong>Don’t Half-listen: Capturing Key-part Information in Continual Instruction Tuning</strong><br><em>Yongquan He, Wenyuan Zhang, Xuancheng Huang, peng zhang, Lingxun Meng, Xiang Zhou, Ke Zeng, Xunliang Cai</em></li>
  <li><strong>Generating Plausible Distractors for Multiple-Choice Questions via Student Choice Prediction</strong><br><em>Yooseop Lee, Suin Kim, Yohan Jo</em></li>
  <li><strong>Exploring Explanations Improves the Robustness of In-Context Learning</strong><br><em>Ukyo Honda, Tatsushi Oka</em></li>
  <li><strong>Prediction Hubs are Context-Informed Frequent Tokens in LLMs</strong><br><em>Beatrix Miranda Ginn Nielsen, Iuri Macocco, Marco Baroni</em></li>
  <li><strong>Capability Salience Vector: Fine-grained Alignment of Loss and Capabilities for Downstream Task Scaling Law</strong><br><em>Qiming Ge, Shuhao Xing, Songyang Gao, Yunhua Zhou, Yicheng Zou, Songyang Zhang, Zhi Chen, Hang Yan, Qi Zhang, Qipeng Guo, Kai Chen</em></li>
  <li><strong>CRUXEVAL-X: A Benchmark for Multilingual Code Reasoning, Understanding and Execution</strong><br><em>Ruiyang Xu, Jialun Cao, Yaojie Lu, Ming Wen, Hongyu Lin, Xianpei Han, Ben He, Shing-Chi Cheung, Le Sun</em></li>
  <li><strong>Graph of Records: Boosting Retrieval Augmented Generation for Long-context Summarization with Graphs</strong><br><em>Haozhen Zhang, Tao Feng, Jiaxuan You</em></li>
  <li><strong>Rubrik’s Cube: Testing a New Rubric for Evaluating Explanations on the CUBE dataset</strong><br><em>Diana Galvan-Sosa, Gabrielle Gaudeau, Pride Kavumba, Yunmeng Li, Hongyi gu, Zheng Yuan, Keisuke Sakaguchi, Paula Buttery</em></li>
  <li><strong>A Dual-Mind Framework for Strategic and Expressive Negotiation Agent</strong><br><em>Yutong Liu, Lida Shi, Rui Song, Hao Xu</em></li>
  <li><strong>Ref-Long: Benchmarking the Long-context Referencing Capability of Long-context Language Models</strong><br><em>Junjie Wu, Gefei Gu, Yanan Zheng, Dit-Yan Yeung, Arman Cohan</em></li>
  <li><strong>Revisiting Scaling Laws for Language Models: The Role of Data Quality and Training Strategies</strong><br><em>Zhengyu Chen, Siqi Wang, Teng Xiao, Yudong Wang, Shiqi Chen, Xunliang Cai, Junxian He, Jingang Wang</em></li>
  <li><strong>Limited Generalizability in Argument Mining: State-Of-The-Art Models Learn Datasets, Not Arguments</strong><br><em>Marc Feger, Katarina Boland, Stefan Dietze</em></li>
  <li><strong>Enhancing Machine Translation with Self-Supervised Preference Data</strong><br><em>Haoxiang Sun, Ruize Gao, Pei Zhang, Baosong Yang, Rui Wang</em></li>
  <li><strong>Unveil: Unified Visual-Textual Integration and Distillation for Multi-modal Document Retrieval</strong><br><em>Hao Sun, Yingyan Hou, Jiayan Guo, Bo Wang, Chunyu Yang, Jinsong Ni, Yan Zhang</em></li>
  <li><strong>Don’t Get Lost in the Trees: Streamlining LLM Reasoning by Overcoming Tree Search Exploration Pitfalls</strong><br><em>Ante Wang, Linfeng Song, Ye Tian, Dian Yu, Haitao Mi, Xiangyu Duan, Zhaopeng Tu, Jinsong Su, Dong Yu</em></li>
  <li><strong>MEXMA: Token-level objectives improve sentence representations</strong><br><em>João Maria Janeiro, Benjamin Piwowarski, Patrick Gallinari, Loic Barrault</em></li>
  <li><strong>Sparse-to-Dense: A Free Lunch for Lossless Acceleration of Video Understanding in LLMs</strong><br><em>Xuan Zhang, Cunxiao Du, Sicheng Yu, Jiawei Wu, Fengzhuo Zhang, Wei Gao, Qian Liu</em></li>
  <li><strong>Uncertainty-Aware Iterative Preference Optimization for Enhanced LLM Reasoning</strong><br><em>Lei Li, Hehuan Liu, Yaxin Zhou, ZhaoYang Gui, Xudong Weng, Yi YUAN, Zheng Wei, Zang Li</em></li>
  <li><strong>AgentDropout: Dynamic Agent Elimination for Token-Efficient and High-Performance LLM-Based Multi-Agent Collaboration</strong><br><em>Zhexuan Wang, Yutong Wang, Xuebo Liu, Liang Ding, Miao Zhang, Jie Liu, Min Zhang</em></li>
  <li><strong>Towards Dynamic Theory of Mind: Evaluating LLM Adaptation to Temporal Evolution of Human States</strong><br><em>Yang Xiao, Jiashuo WANG, Qiancheng Xu, Changhe Song, Chunpu Xu, Yi Cheng, Wenjie Li, Pengfei Liu</em></li>
  <li><strong>M-IFEval: On Multilingual Instruction-Following Capability of Large Language Models</strong><br><em>Bo Zeng, Chenyang Lyu, Sinuo Liu, Mingyan Zeng, Minghao Wu, Xuanfan Ni, Tianqi Shi, Yu Zhao, Yefeng Liu, Chenyu Zhu, Ruizhe Li, Jiahui Geng, Qing Li, Yu Tong, Longyue Wang, Weihua Luo, Kaifu Zhang</em></li>
  <li><strong>Revisiting Uncertainty Quantification Evaluation in Language Models: Spurious Interactions with Response Length Bias Results</strong><br><em>Andrea Santilli, Adam Golinski, Michael Kirchhof, Federico Danieli, Arno Blaas, Miao Xiong, Luca Zappella, Sinead Williamson</em></li>
  <li><strong>Representation Bending for Large Language Model Safety</strong><br><em>Ashkan Yousefpour, Taeheon Kim, Ryan Sungmo Kwon, Seungbeen Lee, Wonje Jeung, Seungju Han, Alvin Wan, Harrison Ngan, Youngjae Yu, Jonghyun Choi</em></li>
  <li><strong>Analyzing LLMs’ Cognition of Knowledge Boundary Across Languages Through the Lens of Internal Representation</strong><br><em>Chenghao Xiao, Hou Pong Chan, Hao Zhang, Mahani Aljunied, Lidong Bing, Noura Al Moubayed, Yu Rong</em></li>
  <li><strong>Enhancing Retrieval-Augmented Generation via Evidence Tree Search</strong><br><em>Hao Sun, Hengyi Cai, Yuchen Li, Xuanbo Fan, Xiaochi Wei, Shuaiqiang Wang, Yan Zhang, Dawei Yin</em></li>
  <li><strong>HalluLens: LLM Hallucination Benchmark</strong><br><em>Yejin Bang, Ziwei Ji, Alan Schelten, Anthony Hartshorn, Tara Fowler, Cheng Zhang, Nicola Cancedda, Pascale Fung</em></li>
  <li><strong>DEEPER Insight into Your User: Directed Persona Refinement for Dynamic Persona Modeling</strong><br><em>Aili Chen, Chengyu Du, Jiangjie Chen, Jinghan Xu, Yikai Zhang, Siyu Yuan, Zulong Chen, Liangyue Li, Yanghua Xiao</em></li>
  <li><strong>Asclepius: A Spectrum Evaluation Benchmark for Medical Multi-Modal Large Language Models</strong><br><em>Jie Liu, Wenxuan Wang, SU Yihang, Jingyuan Huang, Yudi Zhang, Cheng-Yi Li, Wenting Chen, Xiaohan Xing, Kao-Jung Chang, Linlin Shen, Michael R. Lyu</em></li>
  <li><strong>InstructPart: Task-Oriented Part Segmentation with Instruction Reasoning</strong><br><em>Zifu Wan, Yaqi Xie, Ce Zhang, Zhiqiu Lin, Zihan Wang, Simon Stepputtis, Deva Ramanan, Katia P. Sycara</em></li>
  <li><strong>GRaMPa: Subword Regularisation by Skewing Uniform Segmentation Distributions with an Efficient Path-counting Markov Model</strong><br><em>Thomas Bauwens, David Kaczér, Miryam de Lhoneux</em></li>
  <li><strong>Evaluating the Evaluation of Diversity in Commonsense Generation</strong><br><em>Tianhui Zhang, Bei Peng, Danushka Bollegala</em></li>
  <li><strong>Generate First, Then Sample: Enhancing Fake News Detection with LLM-Augmented Reinforced Sampling</strong><br><em>Zhao Tong, Yimeng Gu, Huidong Liu, Qiang Liu, Shu Wu, Haichao Shi, Xiao-Yu Zhang</em></li>
  <li><strong>ChemActor: Enhancing Automated Extraction of Chemical Synthesis Actions with LLM-Generated Data</strong><br><em>Yu Zhang, Ruijie Yu, Jidong Tian, Feng Zhu, Jiapeng Liu, Xiaokang Yang, Yaohui Jin, Yanyan Xu</em></li>
  <li><strong>Towards Fully Exploiting LLM Internal States to Enhance Knowledge Boundary Perception</strong><br><em>Shiyu Ni, Keping Bi, Jiafeng Guo, Lulu Yu, Baolong Bi, Xueqi Cheng</em></li>
  <li><strong>ALGEN: Few-shot Inversion Attacks on Textual Embeddings using Alignment and Generation</strong><br><em>Yiyi Chen, Qiongkai Xu, Johannes Bjerva</em></li>
  <li><strong>Decoding on Graphs: Faithful and Sound Reasoning on Knowledge Graphs through Generation of Well-Formed Chains</strong><br><em>Kun LI, Tianhua Zhang, Xixin Wu, Hongyin Luo, James R. Glass, Helen M. Meng</em></li>
  <li><strong>STaR-SQL: Self-Taught Reasoner for Text-to-SQL</strong><br><em>Mingqian He, Yongliang Shen, Wenqi Zhang, Qiuying Peng, Jun Wang, Weiming Lu</em></li>
  <li><strong>Fairness Beyond Performance: Investigating Reliability Disparities Across Groups in Legal NLP</strong><br><em>Santosh T.Y.S.S, Irtiza Chowdhury</em></li>
  <li><strong>Beyond Similarity: A Gradient-based Graph Method for Instruction Tuning Data Selection</strong><br><em>Yang Zhao, Li Du, Xiao Ding, Yangou Ouyang, Hepeng Wang, Kai Xiong, Jinglong Gao, Zhouhao Sun, Dongliang Xu, Qing Yang, Dongchen Li, Bing Qin, Ting Liu</em></li>
  <li><strong>FastMCTS: A Simple Sampling Strategy for Data Synthesis</strong><br><em>Peiji Li, Kai Lv, Yunfan Shao, Yichuan Ma, Linyang Li, Xiaoqing Zheng, Xipeng Qiu, Qipeng Guo</em></li>
  <li><strong>Dialogue-RAG: Enhancing Retrieval for LLMs via Node-Linking Utterance Rewriting</strong><br><em>Qiwei Li, Teng Xiao, Zuchao Li, Ping Wang, Mengjia Shen, hai zhao</em></li>
  <li><strong>Using Information Theory to Characterize Prosodic Typology: The Case of Tone, Pitch-Accent and Stress-Accent</strong><br><em>Ethan Wilcox, Cui Ding, Giovanni Acampa, Tiago Pimentel, Alex Warstadt, Tamar I Regev</em></li>
  <li><strong>Evaluating LLMs for Portuguese Sentence Simplification with Linguistic Insights</strong><br><em>ARTHUR MARIANO ROCHA DE AZEVEDO SCALERCIO, Elvis A. de Souza, Maria José Bocorny Finatto, Aline Paes</em></li>
  <li><strong>LaTIM: Measuring Latent Token-to-Token Interactions in Mamba Models</strong><br><em>Hugo Pitorro, Marcos Vinicius Treviso</em></li>
  <li><strong>Memorization Inheritance in Sequence-Level Knowledge Distillation for Neural Machine Translation</strong><br><em>Verna Dankers, Vikas Raunak</em></li>
  <li><strong>Improving Low-Resource Morphological Inflection via Self-Supervised Objectives</strong><br><em>Adam Wiemerslage, Katharina von der Wense</em></li>
  <li><strong>Don’t Reinvent the Wheel: Efficient Instruction-Following Text Embedding based on Guided Space Transformation</strong><br><em>Yingchaojie Feng, Yiqun Sun, Yandong Sun, Minfeng Zhu, Qiang Huang, Anthony Kum Hoe Tung, Wei Chen</em></li>
  <li><strong>BOOKCOREF: Coreference Resolution at Book Scale</strong><br><em>Giuliano Martinelli, Tommaso Bonomo, Pere-Lluís Huguet Cabot, Roberto Navigli</em></li>
  <li><strong>OMGM: Orchestrate Multiple Granularities and Modalities for Efficient Multimodal Retrieval</strong><br><em>Wei Yang, Jingjing Fu, Rui Wang, Jinyu Wang, Lei Song, Jiang Bian</em></li>
  <li><strong>Alleviating Hallucinations from Knowledge Misalignment in Large Language Models via Selective Abstention Learning</strong><br><em>Lei Huang, Xiaocheng Feng, Weitao Ma, Yuchun Fan, Xiachong Feng, Yuxuan Gu, Yangfan Ye, Liang Zhao, Weihong Zhong, Baoxin Wang, Dayong Wu, Guoping Hu, Lingpeng Kong, Tong Xiao, Ting Liu, Bing Qin</em></li>
  <li><strong>Retrospective Learning from Interactions</strong><br><em>Zizhao Chen, Mustafa Omer Gul, Yiwei Chen, Gloria Geng, Anne Wu, Yoav Artzi</em></li>
  <li><strong>Personalized Generation In Large Model Era: A Survey</strong><br><em>Yiyan Xu, Jinghao Zhang, Alireza Salemi, Xinting Hu, Wenjie Wang, Fuli Feng, Hamed Zamani, Xiangnan He, Tat-Seng Chua</em></li>
  <li><strong>Graph Counselor: Adaptive Graph Exploration via Multi-Agent Synergy to Enhance LLM Reasoning</strong><br><em>Junqi Gao, Xiang Zou, Ying Ai, Dong Li, Yichen Niu, Biqing Qi, Jianxing Liu</em></li>
  <li><strong>SOTOPIA-Ω: Dynamic Strategy Injection Learning and Social Instruction Following Evaluation for Social Agents</strong><br><em>Wenyuan Zhang, Tianyun Liu, Mengxiao Song, Xiaodong Li, Tingwen Liu</em></li>
  <li><strong>Can Language Models Replace Programmers? REPOCOD Says ‘Not Yet’</strong><br><em>Shanchao Liang, Nan Jiang, Yiran Hu, Lin Tan</em></li>
  <li><strong>Leveraging In-Context Learning for Political Bias Testing of LLMs</strong><br><em>Patrick Haller, Jannis Vamvas, Rico Sennrich, Lena Ann Jäger</em></li>
  <li><strong>CoRet: Improved Retriever for Code Editing</strong><br><em>Fabio James Fehr, Prabhu Teja S, Luca Franceschi, Giovanni Zappella</em></li>
  <li><strong>ACORD: An Expert-Annotated Retrieval Dataset for Legal Contract Drafting</strong><br><em>Steven H Wang, Maksim Zubkov, Kexin Fan, Sarah Harrell, Yuyang Sun, Wei Chen, Andreas Plesner, Roger Wattenhofer</em></li>
  <li><strong>LLMs know their vulnerabilities: Uncover Safety Gaps through Natural Distribution Shifts</strong><br><em>Qibing Ren, Hao Li, Dongrui Liu, Zhanxu Xie, Xiaoya Lu, Yu Qiao, Lei Sha, Junchi Yan, Lizhuang Ma, Jing Shao</em></li>
  <li><strong>WAFFLE: Fine-tuning Multi-Modal Model for Automated Front-End Development</strong><br><em>Shanchao Liang, Nan Jiang, Shangshu Qian, Lin Tan</em></li>
  <li><strong>Math Neurosurgery: Isolating Language Models’ Math Reasoning Abilities Using Only Forward Passes</strong><br><em>Bryan R Christ, Zachary Gottesman, Jonathan Kropko, Thomas Hartvigsen</em></li>
  <li><strong>Multiple LLM Agents Debate for Equitable Cultural Alignment</strong><br><em>Dayeon Ki, Rachel Rudinger, Tianyi Zhou, Marine Carpuat</em></li>
  <li><strong>RefreshKV: Updating Small KV Cache During Long-form Generation</strong><br><em>Fangyuan Xu, Tanya Goyal, Eunsol Choi</em></li>
  <li><strong>SEA: Low-Resource Safety Alignment for Multimodal Large Language Models via Synthetic Embeddings</strong><br><em>Weikai Lu, Hao Peng, Huiping Zhuang, Cen Chen, Ziqian Zeng</em></li>
  <li><strong>Has Machine Translation Evaluation Achieved Human Parity? The Human Reference and the Limits of Progress</strong><br><em>Lorenzo Proietti, Stefano Perrella, Roberto Navigli</em></li>
  <li><strong>Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective</strong><br><em>Yiyao Yu, Yuxiang Zhang, Dongdong Zhang, Xiao Liang, Hengyuan Zhang, Xingxing Zhang, MAHMOUD KHADEMI, Hany Hassan Awadalla, Junjie Wang, Yujiu Yang, Furu Wei</em></li>
  <li><strong>Language Models Grow Less Humanlike beyond Phase Transition</strong><br><em>Tatsuya Aoyama, Ethan Wilcox</em></li>
  <li><strong>PCoT: Persuasion-Augmented Chain of Thought for Detecting Fake News and Social Media Disinformation</strong><br><em>Arkadiusz Modzelewski, Witold Sosnowski, Tiziano Labruna, Adam Wierzbicki, Giovanni Da San Martino</em></li>
  <li><strong>Coordinating Chaos: A Structured Review of Linguistic Coordination Methodologies</strong><br><em>Benjamin Roger Litterer, David Jurgens, Dallas Card</em></li>
  <li><strong>iNews: A Multimodal Dataset for Modeling Personalized Affective Responses to News</strong><br><em>Tiancheng Hu, Nigel Collier</em></li>
  <li><strong>Mind the Gesture: Evaluating AI Sensitivity to Culturally Offensive Non-Verbal Gestures</strong><br><em>Akhila Yerukola, Saadia Gabriel, Nanyun Peng, Maarten Sap</em></li>
  <li><strong>500xCompressor: Generalized Prompt Compression for Large Language Models</strong><br><em>Zongqian Li, Yixuan Su, Nigel Collier</em></li>
  <li><strong>Estimating Privacy Leakage of Augmented Contextual Knowledge in Language Models</strong><br><em>James Flemings, Bo Jiang, Wanrong Zhang, Zafar Takhirov, Murali Annavaram</em></li>
  <li><strong>Document-Level Event-Argument Data Augmentation for Challenging Role Types</strong><br><em>Joseph Gatto, Omar Sharif, Parker Seegmiller, Sarah Masud Preum</em></li>
  <li><strong>Mapping the Podcast Ecosystem with the Structured Podcast Research Corpus</strong><br><em>Benjamin Roger Litterer, David Jurgens, Dallas Card</em></li>
  <li><strong>Unravelling the Logic: Investigating the Generalisation of Transformers in Numerical Satisfiability Problems</strong><br><em>Tharindu Madusanka, Marco Valentino, Iqra Zahid, Ian Pratt-Hartmann, Riza Batista-Navarro</em></li>
  <li><strong>The Nature of NLP: Analyzing Contributions in NLP Papers</strong><br><em>Aniket Pramanick, Yufang Hou, Saif M. Mohammad, Iryna Gurevych</em></li>
  <li><strong>$\mathtt{GeLLM^3O}$: Generalizing Large Language Models for Multi-property Molecule Optimization</strong><br><em>Vishal Dey, Xiao Hu, Xia Ning</em></li>
  <li><strong>Diffusion Directed Acyclic Transformer for Non-Autoregressive Machine Translation</strong><br><em>Quan Nguyen-Tri, Cong Dao Tran, Hoang Thanh-Tung</em></li>
  <li><strong>Follow-up Question Generation For Enhanced Patient-Provider Conversations</strong><br><em>Joseph Gatto, Parker Seegmiller, Timothy E. Burdick, Inas S. Khayal, Sarah DeLozier, Sarah Masud Preum</em></li>
  <li><strong>Unveiling Privacy Risks in LLM Agent Memory</strong><br><em>Bo Wang, Weiyi He, Shenglai Zeng, Zhen Xiang, Yue Xing, Jiliang Tang, Pengfei He</em></li>
  <li><strong>Watching the Watchers: Exposing Gender Disparities in Machine Translation Quality Estimation</strong><br><em>Emmanouil Zaranis, Giuseppe Attanasio, Sweta Agrawal, Andre Martins</em></li>
  <li><strong>Language Constrained Multimodal Hyper Adapter For Many-to-Many Multimodal Summarization</strong><br><em>Nayu Liu, Fanglong Yao, Haoran Luo, Yong Yang, Chen Tang, Bo Lv</em></li>
  <li><strong>PRMBench: A Fine-grained and Challenging Benchmark for Process-Level Reward Models</strong><br><em>Mingyang Song, Zhaochen Su, Xiaoye Qu, Jiawei Zhou, Yu Cheng</em></li>
  <li><strong>Efficient Ensemble for Fine-tuning Language Models on Multiple Datasets</strong><br><em>Dongyue Li, Ziniu Zhang, Lu Wang, Hongyang R. Zhang</em></li>
  <li><strong>Library-Like Behavior In Language Models is Enhanced by Self-Referencing Causal Cycles</strong><br><em>Munachiso S Nwadike, Zangir Iklassov, Toluwani Aremu, Tatsuya Hiraoka, Benjamin Heinzerling, Velibor Bojkovic, Hilal AlQuabeh, Martin Takáč, Kentaro Inui</em></li>
  <li><strong>Shaping the Safety Boundaries: Understanding and Defending Against Jailbreaks in Large Language Models</strong><br><em>Lang Gao, Jiahui Geng, Xiangliang Zhang, Preslav Nakov, Xiuying Chen</em></li>
  <li><strong>ASPERA: A Simulated Environment to Evaluate Planning for Complex Action Execution</strong><br><em>Alexandru Coca, Mark Gaynor, Zhenxing Zhang, Jianpeng Cheng, Bo-Hsiang Tseng, Peter Boothroyd, Hector Martinez Alonso, Diarmuid O Seaghdha, Anders Johannsen</em></li>
  <li><strong>ReflectDiffu: Reflect between Emotion-intent Contagion and Mimicry for Empathetic Response Generation via a RL-Diffusion Framework</strong><br><em>Jiahao Yuan, Zixiang Di, Zhiqing Cui, Guisong Yang, Usman Naseem</em></li>
  <li><strong>SARA: Salience-Aware Reinforced Adaptive Decoding for Large Language Models in Abstractive Summarization</strong><br><em>Nayu Liu, Junnan Zhu, Yiming Ma, Zhicong Lu, Wenlei Xu, Yong Yang, Jiang Zhong, kaiwen wei</em></li>
  <li><strong>Embedding-Converter: A Unified Framework for Cross-Model Embedding Transformation</strong><br><em>Jinsung Yoon, Sercan O Arik</em></li>
  <li><strong>Improving Automatic Evaluation of Large Language Models (LLMs) in Biomedical Relation Extraction via LLMs-as-the-Judge</strong><br><em>Md Tahmid Rahman Laskar, Israt Jahan, Elham Dolatabadi, Chun Peng, Enamul Hoque, Jimmy Huang</em></li>
  <li><strong>Answering Complex Geographic Questions by Adaptive Reasoning with Visual Context and External Commonsense Knowledge</strong><br><em>Fan Li, Jianxing Yu, Jielong Tang, Wenqing Chen, Hanjiang Lai, Yanghui Rao, Jian Yin</em></li>
  <li><strong>Efficient Knowledge Editing via Minimal Precomputation</strong><br><em>Akshat Gupta, Maochuan Lu, Thomas Hartvigsen, Gopala Anumanchipalli</em></li>
  <li><strong>Safety Alignment via Constrained Knowledge Unlearning</strong><br><em>Zesheng Shi, Yucheng Zhou, Jing Li, Yuxin Jin, YU LI, Daojing He, Fangming Liu, Saleh Alharbi, Jun Yu, Min Zhang</em></li>
  <li><strong>Response Wide Shut:Surprising Observations in Basic Vision Language Model Capabilities</strong><br><em>Shivam Chandhok, Wan-Cyuan Fan, Vered Shwartz, Vineeth N. Balasubramanian, Leonid Sigal</em></li>
  <li><strong>EffiVLM-Bench: A Comprehensive Benchmark for Evaluating Training-Free Acceleration in Large Visual-Languge Models</strong><br><em>Zekun Wang, MingHua Ma, Zexin Wang, Rongchuan Mu, hongtao liu, liping shan, Ming Liu, Bing Qin</em></li>
  <li><strong>Pre-Training Curriculum for Multi-Token Prediction in Language Models</strong><br><em>Ansar Aynetdinov, Alan Akbik</em></li>
  <li><strong>Can We Further Elicit Reasoning in LLMs? Critic-Guided Planning with Retrieval-Augmentation for Solving Challenging Tasks</strong><br><em>Xingxuan Li, Weiwen Xu, Ruochen Zhao, Fangkai Jiao, Shafiq Joty, Lidong Bing</em></li>
  <li><strong>On Many-Shot In-Context Learning for Long-Context Evaluation</strong><br><em>Kaijian Zou, Muhammad Khalifa, Lu Wang</em></li>
  <li><strong>Meaning Variation and Data Quality in the Corpus of Founding Era American English</strong><br><em>Dallas Card</em></li>
  <li><strong>Dedicated Feedback and Edit Models Empower Inference-Time Scaling for Open-Ended General-Domain Tasks</strong><br><em>Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Daniel Egert, Ellie Evans, Hoo-Chang Shin, Felipe Soares, Yi Dong, Oleksii Kuchaiev</em></li>
  <li><strong>CulturalBench: A Robust, Diverse and Challenging Benchmark for Measuring LMs’ Cultural Knowledge Through Human-AI Red-Teaming</strong><br><em>Yu Ying Chiu, Liwei Jiang, Bill Yuchen Lin, Chan Young Park, Shuyue Stella Li, Sahithya Ravi, Mehar Bhatia, Maria Antoniak, Yulia Tsvetkov, Vered Shwartz, Yejin Choi</em></li>
  <li><strong>Balancing the Budget: Understanding Trade-offs Between Supervised and Preference-Based Finetuning</strong><br><em>Mohit Raghavendra, Junmo Kang, Alan Ritter</em></li>
  <li><strong>All That Glitters is Not Novel: Plagiarism in AI Generated Research</strong><br><em>Tarun Gupta, Danish Pruthi</em></li>
  <li><strong>Writing Like the Best: Exemplar-Based Expository Text Generation</strong><br><em>Yuxiang Liu, Kevin Chen-Chuan Chang</em></li>
  <li><strong>Temporal Relation Extraction in Clinical Texts: A Span-based Graph Transformer Approach</strong><br><em>Rochana Chaturvedi, Peyman Baghershahi, Sourav Medya, Barbara Di Eugenio</em></li>
  <li><strong>Finding A Voice: Exploring the Potential of African American Dialect and Voice Generation for Chatbots</strong><br><em>Sarah E. Finch, Ellie S. Paek, Ikseon Choi, Jinho D. Choi</em></li>
  <li><strong>Delta-KNN: Improving Demonstration Selection in In-Context Learning for Alzheimer’s Disease Detection</strong><br><em>Chuyuan Li, Raymond Li, Thalia S. Field, Giuseppe Carenini</em></li>
  <li><strong>Help Me Write a Story: Evaluating LLMs’ Ability to Generate Writing Feedback</strong><br><em>Hannah Rashkin, Elizabeth Clark, Fantine Huot, Mirella Lapata</em></li>
  <li><strong>Language Fusion for Parameter-Efficient Cross-lingual Transfer</strong><br><em>Philipp Borchert, Ivan Vulić, Marie-Francine Moens, Jochen De Weerdt</em></li>
  <li><strong>Culture is Not Trivia: Sociocultural Theory for Cultural NLP</strong><br><em>Naitian Zhou, David Bamman, Isaac L. Bleaman</em></li>
  <li><strong>AAD-LLM: Neural Attention-Driven Auditory Scene Understanding</strong><br><em>Xilin Jiang, Sukru Samet Dindar, Vishal Choudhari, Stephan Bickel, Ashesh Mehta, Guy M McKhann, Daniel Friedman, Adeen Flinker, Nima Mesgarani</em></li>
  <li><strong>MindRef: Mimicking Human Memory for Hierarchical Reference Retrieval with Fine-Grained Location Awareness</strong><br><em>Ye Wang, Xinrun Xu, Zhiming Ding</em></li>
  <li><strong>Do Language Models Have Semantics? On the Five Standard Positions</strong><br><em>Anders Søgaard</em></li>
  <li><strong>Dehumanizing Machines: Mitigating Anthropomorphic Behaviors in Text Generation Systems</strong><br><em>Myra Cheng, Su Lin Blodgett, Alicia DeVrio, Lisa Egede, Alexandra Olteanu</em></li>
  <li><strong>Evaluating Multimodal Language Models as Visual Assistants for Visually Impaired Users</strong><br><em>Antonia Karamolegkou, Malvina Nikandrou, Georgios Pantazopoulos, Danae Sanchez Villegas, Phillip Rust, Ruchira Dhar, Daniel Hershcovich, Anders Søgaard</em></li>
  <li><strong>HumT DumT: Measuring and controlling human-like language in LLMs</strong><br><em>Myra Cheng, Sunny Yu, Dan Jurafsky</em></li>
  <li><strong>ChatBench: From Static Benchmarks to Human-AI Evaluation</strong><br><em>Serina Chang, Ashton Anderson, Jake M. Hofman</em></li>
  <li><strong>LLMs syntactically adapt their language use to their conversational partner</strong><br><em>Florian Kandra, Vera Demberg, Alexander Koller</em></li>
  <li><strong>Teaching an Old LLM Secure Coding: Localized Preference Optimization on Distilled Preferences</strong><br><em>Mohammad Saqib Hasan, Saikat Chakraborty, Santu Karmaker, Niranjan Balasubramanian</em></li>
  <li><strong>Anything Goes? A Crosslinguistic Study of (Im)possible Language Learning in LMs</strong><br><em>Xiulin Yang, Tatsuya Aoyama, Yuekun Yao, Ethan Wilcox</em></li>
  <li><strong>Ranking Unraveled: Recipes for LLM Rankings in Head-to-Head AI Combat</strong><br><em>Roland Daynauth, Christopher Clarke, Krisztian Flautner, Lingjia Tang, Jason Mars</em></li>
  <li><strong>LLM Agents Making Agent Tools</strong><br><em>Georg Wölflein, Dyke Ferber, Daniel Truhn, Ognjen Arandjelovic, Jakob Nikolas Kather</em></li>
  <li><strong>CrafText Benchmark: Advancing Language Grounding in Complex Multimodal Open-Ended World</strong><br><em>Zoya Volovikova, Gregory Gorbov, Petr Kuderov, Aleksandr Panov, Alexey Skrynnik</em></li>
  <li><strong>QG-SMS: Enhancing Test Item Analysis via Student Modeling and Simulation</strong><br><em>Bang Nguyen, Tingting Du, Mengxia Yu, Lawrence Angrave, Meng Jiang</em></li>
  <li><strong>Causal Graph based Event Reasoning using Semantic Relation Experts</strong><br><em>Mahnaz Koupaee, Xueying Bai, Mudan Chen, Greg Durrett, Nathanael Chambers, Niranjan Balasubramanian</em></li>
  <li><strong>LogicPro: Improving Complex Logical Reasoning via Program-Guided Learning</strong><br><em>Jin Jiang, Yuchen Yan, Yang Liu, Jianing Wang, Shuai Peng, Xunliang Cai, Yixin Cao, Mengdi Zhang, Liangcai Gao</em></li>
  <li><strong>Do LLMs Understand Dialogues? A Case Study on Dialogue Acts</strong><br><em>Ayesha Qamar, Jonathan Tong, Ruihong Huang</em></li>
  <li><strong>Research Borderlands: Analysing Scientific Writing Across Research Cultures</strong><br><em>Shaily Bhatt, Tal August, Maria Antoniak</em></li>
  <li><strong>CEAES: Bidirectional Reinforcement Learning Optimization for Consistent and Explainable Essay Assessment</strong><br><em>Xia Li, Wenjing Pan</em></li>
  <li><strong>DeAL: Decoding-time Alignment Framework for Large Language Models</strong><br><em>James Y. Huang, Sailik Sengupta, Daniele Bonadiman, Yi-An Lai, Arshit Gupta, Nikolaos Pappas, Saab Mansour, Katrin Kirchhoff, Dan Roth</em></li>
  <li><strong>Cultural Bias Matters: A Cross-Cultural Benchmark Dataset and Sentiment-Enriched Model for Understanding Multimodal Metaphors</strong><br><em>Senqi Yang, Dongyu Zhang, Jing Ren, Ziqi Xu, Xiuzhen Zhang, Yiliao Song, Hongfei Lin, Feng Xia</em></li>
  <li><strong>OmniCharacter: Towards Immersive Role-Playing Agents with Seamless Speech-Language Personality Interaction</strong><br><em>Haonan Zhang, Run Luo, Xiong Liu, Yuchuan Wu, Ting-En Lin, Pengpeng Zeng, QIANG QU, Feiteng Fang, Min Yang, Lianli Gao, Jingkuan Song, Fei Huang, Yongbin Li</em></li>
  <li><strong>Mixtures of In-Context Learners</strong><br><em>Giwon Hong, Emile van Krieken, Edoardo Ponti, Nikolay Malkin, Pasquale Minervini</em></li>
  <li><strong>Balancing Diversity and Risk in LLM Sampling: How to Select Your Method and Parameter for Open-Ended Text Generation</strong><br><em>Yuxuan Zhou, Margret Keuper, Mario Fritz</em></li>
  <li><strong>RADAR: Enhancing Radiology Report Generation with Supplementary Knowledge Injection</strong><br><em>Wenjun Hou, Yi Cheng, Kaishuai Xu, Heng Li, Yan Hu, Wenjie Li, Jiang Liu</em></li>
  <li><strong>Can LLMs Deceive CLIP? Benchmarking Adversarial Compositionality of Pre-trained Multimodal Representation via Text Updates</strong><br><em>Jaewoo Ahn, Heeseung Yun, Dayoon Ko, Gunhee Kim</em></li>
  <li><strong>Attention Speaks Volumes: Localizing and Mitigating Bias in Language Models</strong><br><em>Rishabh Adiga, Besmira Nushi, Varun Chandrasekaran</em></li>
  <li><strong>MTSA: Multi-turn Safety Alignment for LLMs through Multi-round Red-teaming</strong><br><em>Weiyang Guo, Jing Li, Wenya Wang, YU LI, Daojing He, Jun Yu, Min Zhang</em></li>
  <li><strong>The Efficiency vs. Accuracy Trade-off: Optimizing RAG-Enhanced LLM Recommender Systems Using Multi-Head Early Exit</strong><br><em>Huixue Zhou, Hengrui Gu, Zaifu Zhan, Xi Liu, Kaixiong Zhou, Yongkang Xiao, Mingfu Liang, Srinivas Prasad Govindan, Piyush Chawla, Jiyan Yang, Xiangfei Meng, Huayu Li, Buyun Zhang, Liang Luo, Wen-Yen Chen, Yiping Han, Bo Long, Rui Zhang, Tianlong Chen</em></li>
  <li><strong>Unraveling LoRA Interference: Orthogonal Subspaces for Robust Model Merging</strong><br><em>Haobo Zhang, Jiayu Zhou</em></li>
  <li><strong>BIG-Bench Extra Hard</strong><br><em>Mehran Kazemi, Bahare Fatemi, Hritik Bansal, John Palowitch, Chrysovalantis Anastasiou, Sanket Vaibhav Mehta, Lalit K Jain, Virginia Aglietti, Disha Jindal, Peter Chen, Nishanth Dikkala, Gladys Tyen, Xin Liu, Uri Shalit, Silvia Chiappa, Kate Olszewska, Yi Tay, Vinh Q. Tran, Quoc V Le, Orhan Firat</em></li>
  <li><strong>CSTree-SRI: Introspection-Driven Cognitive Semantic Tree for Multi-Turn Question Answering over Extra-Long Contexts</strong><br><em>Zhaowen Wang, Xiang Wei, Kangshao Du, Yiting Zhang, Libo Qin, Yingjie Xia, Li Kuang</em></li>
  <li><strong>TigerLLM - A Family of Bangla Large Language Models</strong><br><em>Nishat Raihan, Marcos Zampieri</em></li>
  <li><strong>InductionBench: LLMs Fail in the Simplest Complexity Class</strong><br><em>Wenyue Hua, Tyler Wong, Fei Sun, Liangming Pan, Adam Jardine, William Yang Wang</em></li>
  <li><strong>RATIONALYST: Pre-training Process-Supervision for Improving Reasoning</strong><br><em>Dongwei Jiang, Guoxuan Wang, Yining Lu, Andrew Wang, Jingyu Zhang, Chuyu Liu, Benjamin Van Durme, Daniel Khashabi</em></li>
  <li><strong>Make Imagination Clearer! Stable Diffusion-based Visual Imagination for Multimodal Machine Translation</strong><br><em>Andong Chen, Yuchen Song, Kehai Chen, Xuefeng Bai, Muyun Yang, Liqiang Nie, Jie Liu, Tiejun Zhao, Min zhang</em></li>
  <li><strong>Advancing SMoE for Continuous Domain Adaptation of MLLMs: Adaptive Router and Domain-Specific Loss</strong><br><em>Liang Zhang, Ziyao Lu, Fandong Meng, Hui Li, Jie Zhou, Jinsong Su</em></li>
  <li><strong>Mitigating Media Bias through Multi-document Events Reasoning in LLMs</strong><br><em>Yuanyuan Lei, Ruihong Huang</em></li>
  <li><strong>Who Writes What: Unveiling the Impact of Author Roles on AI-generated Text Detection</strong><br><em>Jiatao Li, Xiaojun Wan</em></li>
  <li><strong>RoCoFT: Efficient Finetuning of Large Language Models with Row-Column Updates</strong><br><em>Md Kowsher, Tara Esmaeilbeig, Chun-Nam Yu, Chen Chen, Mojtaba Soltanalian, Niloofar Yousefi</em></li>
  <li><strong>Scaling Laws and Efficient Inference for Ternary Language Models</strong><br><em>Tejas Vaidhya, Ayush Kaushal, Vineet Jain, Francis Couture-Harpin, Prashant Shishodia, Majid Behbahani, Irina Rish, Yuriy Nevmyvaka</em></li>
  <li><strong>Exploring the Impact of Instruction-Tuning on LLM’s Susceptibility to Misinformation</strong><br><em>Kyubeen Han, Junseo Jang, Hongjin Kim, Geunyeong Jeong, Harksoo Kim</em></li>
  <li><strong>Do Language Models Understand Honorific Systems in Javanese?</strong><br><em>Mohammad Rifqi Farhansyah, Iwan Darmawan, Adryan Kusumawardhana, Genta Indra Winata, Alham Fikri Aji, Derry Tanti Wijaya</em></li>
  <li><strong>Generative Reward Modeling via Synthetic Criteria Preference Learning</strong><br><em>xiaobo liang, Haoke Zhang, Juntao Li, Kehai Chen, Qiaoming Zhu, Min Zhang</em></li>
  <li><strong>Relation Extraction of Hierarchical Tables Using Multimodal Large Language Models</strong><br><em>Xinyu Zhang, Aibo Song, Jingyi Qiu, Jiahui Jin, Tianbo zhang, Xiaolin Fang</em></li>
  <li><strong>A Self-Denoising Model for Robust Few-Shot Relation Extraction</strong><br><em>Liang Zhang, yang zhang, Ziyao Lu, Fandong Meng, Jie Zhou, Jinsong Su</em></li>
  <li><strong>QuASAR: A Question-Driven Structure-Aware Approach for Table-to-Text Generation</strong><br><em>WeiJie Liu, Yibin Zheng, Fang Kong</em></li>
  <li><strong>Automated Structured Radiology Report Generation</strong><br><em>Jean-Benoit Delbrouck, Justin Xu, Johannes Moll, Alois Thomas, Zhihong Chen, Maya Varma, Asfandyar Azhar, Sophie Ostmeier, Andrew Johnston, Eduardo Pontes Reis, Christian Bluethgen, Mohamed S Muneer, Kelvin Zhenghao Li, Curtis Langlotz</em></li>
  <li><strong>LPOI: Listwise Preference Optimization for Vision Language Models</strong><br><em>Fatemeh Pesaran zadeh, Yoojin Oh, Gunhee Kim</em></li>
  <li><strong>Predicting Through Generation: Why Generation Is Better for Prediction</strong><br><em>Md Kowsher, Nusrat Jahan Prottasha, Prakash Bhat, Chun-Nam Yu, Mojtaba Soltanalian, Ivan Garibay, Ozlem Garibay, Chen Chen, Niloofar Yousefi</em></li>
  <li><strong>“Give Me BF16 or Give Me Death”? Accuracy-Performance Trade-Offs in LLM Quantization</strong><br><em>Eldar Kurtic, Alexandre Noll Marques, Shubhra Pandit, Mark Kurtz, Dan Alistarh</em></li>
  <li><strong>StitchLLM: Serving LLMs, One Block at a Time</strong><br><em>Bodun Hu, Shuozhe Li, Saurabh Agarwal, Myungjin Lee, Akshay Jajoo, Jiamin Li, Le Xu, Geon-Woo Kim, Donghyun Kim, Hong Xu, Amy Zhang, Aditya Akella</em></li>
  <li><strong>Walk in Others’ Shoes with a Single Glance: Human-Centric Visual Grounding with Top-View Perspective Transformation</strong><br><em>Yuqi Bu, Xin Wu, Zirui Zhao, Yi Cai, David Hsu, Qiong Liu</em></li>
  <li><strong>From Citations to Criticality: Predicting Legal Decision Influence in the Multilingual Swiss Jurisprudence</strong><br><em>Ronja Stern, Ken Kawamura, Matthias Stürmer, Ilias Chalkidis, Joel Niklaus</em></li>
  <li><strong>Is linguistically-motivated data augmentation worth it?</strong><br><em>Ray Groshan, Michael Ginn, Alexis Palmer</em></li>
  <li><strong>From Lists to Emojis: How Format Bias Affects Model Alignment</strong><br><em>Xuanchang Zhang, Wei Xiong, Lichang Chen, Tianyi Zhou, Heng Huang, Tong Zhang</em></li>
  <li><strong>Colloquial Singaporean English Style Transfer with Fine-Grained Explainable Control</strong><br><em>Jinggui Liang, Dung Vo, Yap Hong Xian, Hai Leong Chieu, Kian Ming A. Chai, Jing Jiang, Lizi Liao</em></li>
  <li><strong>From Informal to Formal – Incorporating and Evaluating LLMs on Natural Language Requirements to Verifiable Formal Proofs</strong><br><em>Jialun Cao, Yaojie Lu, Meiziniu Li, Haoyang Ma, Haokun Li, Mengda He, Cheng Wen, Le Sun, Hongyu Zhang, Shengchao Qin, Shing-Chi Cheung, Cong Tian</em></li>
  <li><strong>CoAM: Corpus of All-Type Multiword Expressions</strong><br><em>Yusuke Ide, Joshua Tanner, Adam Nohejl, Jacob Hoffman, Justin Vasselli, Hidetaka Kamigaito, Taro Watanabe</em></li>
  <li><strong>SeaKR: Self-aware Knowledge Retrieval for Adaptive Retrieval Augmented Generation</strong><br><em>Zijun Yao, Weijian Qi, Liangming Pan, Shulin Cao, Linmei Hu, Liu Weichuan, Lei Hou, Juanzi Li</em></li>
  <li><strong>Exposing the Achilles’ Heel: Evaluating LLMs Ability to Handle Mistakes in Mathematical Reasoning</strong><br><em>Joykirat Singh, Akshay Nambi, Vibhav Vineet</em></li>
  <li><strong>Revisiting LLMs as Zero-Shot Time Series Forecasters: Small Noise Can Break Large Models</strong><br><em>Junwoo Park, Hyuck Lee, Dohyun Lee, Daehoon Gwak, Jaegul Choo</em></li>
  <li><strong>Transferring Textual Preferences to Vision-Language Understanding through Model Merging</strong><br><em>Chen-An Li, Tzu-Han Lin, Yun-Nung Chen, Hung-yi Lee</em></li>
  <li><strong>Understanding the Dark Side of LLMs’ Intrinsic Self-Correction</strong><br><em>Qingjie Zhang, Di Wang, Haoting Qian, Yiming Li, Tianwei Zhang, Minlie Huang, Han Qiu</em></li>
  <li><strong>VideoVista2: 360° Horizons-Bridging Cultures, Languages, and Domains in Video Comprehension</strong><br><em>Xinyu Chen, yunxin li, Haoyuan Shi, Baotian Hu, Wenhan Luo, Yaowei Wang, Min Zhang</em></li>
  <li><strong>What are the Essential Factors in Crafting Effective Long Context Multi-Hop Instruction Datasets? Insights and Best Practices</strong><br><em>Zhi Chen, Qiguang Chen, Libo Qin, Qipeng Guo, haijun Lv, Yicheng Zou, Hang Yan, Kai Chen, Dahua Lin</em></li>
  <li><strong>Knowledge Graph Retrieval-Augmented Generation for LLM-based Recommendation</strong><br><em>Shijie Wang, Wenqi Fan, Yue Feng, LIN SHANRU, Xinyu Ma, Shuaiqiang Wang, Dawei Yin</em></li>
  <li><strong>SudoLM: Learning Access Control of Parametric Knowledge with Authorization Alignment</strong><br><em>Qin Liu, Fei Wang, Chaowei Xiao, Muhao Chen</em></li>
  <li><strong>ProgCo: Program Helps Self-Correction of Large Language Models</strong><br><em>Xiaoshuai Song, Yanan Wu, Weixun Wang, Jiaheng Liu, Wenbo Su, Bo Zheng</em></li>
  <li><strong>I0T: Embedding Standardization Method Towards Zero Modality Gap</strong><br><em>Na Min An, Eunki Kim, James Thorne, Hyunjung Shim</em></li>
  <li><strong>Leveraging Self-Attention for Input-Dependent Soft Prompting in LLMs</strong><br><em>Ananth Muppidi, Abhilash Nandy, Sambaran Bandyopadhyay</em></li>
  <li><strong>Odysseus Navigates the Sirens’ Song: Dynamic Focus Decoding for Factual and Diverse Open-Ended Text Generation</strong><br><em>Wen Luo, Feifan Song, Wei Li, Guangyue Peng, Shaohang Wei, Houfeng Wang</em></li>
  <li><strong>Better Embeddings with Coupled Adam</strong><br><em>Felix Stollenwerk, Tobias Stollenwerk</em></li>
  <li><strong>Bone Soups: A Seek-and-Soup Model Merging Approach for Controllable Multi-Objective Generation</strong><br><em>Guofu Xie, Xiao Zhang, Ting Yao, Yunsheng Shi</em></li>
  <li><strong>Controllable and Reliable Knowledge-Intensive Task Agents with Declarative GenieWorksheets</strong><br><em>Harshit Joshi, Shicheng Liu, James Chen, Larsen Weigle, Monica Lam</em></li>
  <li><strong>Benchmarking Long-Context Language Models on Long Code Understanding</strong><br><em>Jia Li, Xuyuan Guo, Lei Li, Kechi Zhang, Ge Li, Jia Li, Zhengwei Tao, Fang Liu, Chongyang Tao, Yuqi Zhu, Zhi Jin</em></li>
  <li><strong>MAGNET: Augmenting Generative Decoders with Representation Learning and Infilling Capabilities</strong><br><em>Savya Khosla, Aditi Tiwari, Kushal Kafle, Simon Jenni, Handong Zhao, John Collomosse, Jing Shi</em></li>
  <li><strong>Internal Value Alignment in Large Language Models through Controlled Value Vector Activation</strong><br><em>Haoran Jin, Meng Li, Xiting Wang, Zhihao Xu, Minlie Huang, Yantao Jia, Defu Lian</em></li>
  <li><strong>A Dual-Perspective NLG Meta-Evaluation Framework with Automatic Benchmark and Better Interpretability</strong><br><em>Xinyu Hu, Mingqi Gao, Li Lin, Zhenghan Yu, Xiaojun Wan</em></li>
  <li><strong>Recurrent Knowledge Localization and Fusion for Language Model Continual Learning</strong><br><em>Yujie Feng, Xujia Wang, ZEXIN LU, FuShenghong, Guangyuan SHI, Yongxin Xu, Yasha Wang, Philip S. Yu, Xu Chu, Xiao-Ming Wu</em></li>
  <li><strong>Data-Constrained Synthesis of Training Data for De-Identification</strong><br><em>Thomas Vakili, Aron Henriksson, Hercules Dalianis</em></li>
  <li><strong>Just a Scratch: Enhancing LLM Capabilities for Self-harm Detection through Intent Differentiation and Emoji Interpretation</strong><br><em>Soumitra Ghosh, gopendra Vikram singh, Shambhavi, Sabarna Choudhury, Asif Ekbal</em></li>
  <li><strong>Contrastive Learning on LLM Back Generation Treebank for Cross-domain Constituency Parsing</strong><br><em>Peiming Guo, Meishan Zhang, jianling li, Min Zhang, Yue Zhang</em></li>
  <li><strong>MMDEND: Dendrite-Inspired Multi-Branch Multi-Compartment Parallel Spiking Neuron for Sequence Modeling</strong><br><em>Kexin Wang, Yuhong Chou, Di Shang, Shijie Mei, Jiahong Zhang, Yanbin Huang, Man Yao, Bo XU, Guoqi Li</em></li>
  <li><strong>Inconsistent Tokenizations Cause Language Models to be Perplexed by Japanese Grammar</strong><br><em>Andrew Gambardella, Takeshi Kojima, Yusuke Iwasawa, Yutaka Matsuo</em></li>
  <li><strong>Understanding Impact of Human Feedback via Influence Functions</strong><br><em>Taywon Min, Haeone Lee, Yongchan Kwon, Kimin Lee</em></li>
  <li><strong>T2I-FactualBench: Benchmarking the Factuality of Text-to-Image Models with Knowledge-Intensive Concepts</strong><br><em>Ziwei Huang, Wanggui He, Quanyu Long, Yandi Wang, Haoyuan Li, Zhelun Yu, Fangxun Shu, Weilong Dai, Hao Jiang, Leilei Gan, Fei Wu</em></li>
  <li><strong>InspireDebate: Multi-Dimensional Subjective-Objective Evaluation-Guided Reasoning and Optimization for Debating</strong><br><em>Fuyu Wang, Jiangtong Li, Kun Zhu, Changjun Jiang</em></li>
  <li><strong>WAVE: Building Multimodal Web Agents via Iterative Real-World Exploration, Feedback and Optimization</strong><br><em>Hongliang He, Wenlin Yao, Kaixin Ma, Wenhao Yu, Hongming Zhang, Tianqing Fang, Zhenzhong Lan, Dong Yu</em></li>
  <li><strong>FOCUS: Evaluating Pre-trained Vision-Language Models on Underspecification Reasoning</strong><br><em>Kankan Zhou, Eason Lai, Kyriakos Mouratidis, Jing Jiang</em></li>
  <li><strong>Sightation Counts: Leveraging Sighted User Feedback in Building a BLV-aligned Dataset of Diagram Descriptions</strong><br><em>Wan Ju Kang, Eunki Kim, Na Min An, Sangryul Kim, Haemin Choi, Ki Hoon Kwak, James Thorne</em></li>
  <li><strong>Personal Travel Solver: A Preference-Driven LLM-Solver System for Travel Planning</strong><br><em>Zijian Shao, Jiancan Wu, Weijian Chen, Xiang Wang</em></li>
  <li><strong>Counterspeech the ultimate shield! Multi-Conditioned Counterspeech Generation through Attributed Prefix Learning</strong><br><em>Aswini Kumar Padhi, Anil Bandhakavi, Tanmoy Chakraborty</em></li>
  <li><strong>Unique Hard Attention: A Tale of Two Sides</strong><br><em>Selim Jerad, Anej Svete, Jiaoda Li, Ryan Cotterell</em></li>
  <li><strong>LLM$\times$MapReduce: Simplified Long-Sequence Processing using Large Language Models</strong><br><em>Zihan Zhou, Chong Li, 陈昕怡, Shuo Wang, Yu Chao, Zhili Li, Haoyu Wang, Qi Shi, Zhixing Tan, Xu Han, Xiaodong Shi, Zhiyuan Liu, Maosong Sun</em></li>
  <li><strong>CheXalign: Preference fine-tuning in chest X-ray interpretation models without human feedback</strong><br><em>Dennis Hein, Zhihong Chen, Sophie Ostmeier, Justin Xu, Maya Varma, Eduardo Pontes Reis, Arne Edward Michalson MD, Christian Bluethgen, Hyun Joo Shin, Curtis Langlotz, Akshay S Chaudhari</em></li>
  <li><strong>Knowledge Tracing in Programming Education Integrating Students’ Questions</strong><br><em>Doyoun Kim, Suin Kim, Yohan Jo</em></li>
  <li><strong>PRISM: A Framework for Producing Interpretable Political Bias Embeddings with Political-Aware Cross-Encoder</strong><br><em>Yiqun Sun, Qiang Huang, Anthony Kum Hoe Tung, Jun Yu</em></li>
  <li><strong>Representations of Fact, Fiction and Forecast in Large Language Models: Epistemics and Attitudes</strong><br><em>Meng Li, Michael Vrazitulis, David Schlangen</em></li>
  <li><strong>Lexical Diversity-aware Relevance Assessment for Retrieval-Augmented Generation</strong><br><em>Zhange Zhang, Yuqing Ma, Yulong Wang, Shan He, Tianbo Wang, Siqi He, Jiakai Wang, Xianglong Liu</em></li>
  <li><strong>Weaving Context Across Images: Improving Vision-Language Models through Focus-Centric Visual Chains</strong><br><em>Juntian Zhang, Chuanqi Cheng, Yuhan Liu, Wei Liu, Jian Luan, Rui Yan</em></li>
  <li><strong>Online Iterative Self-Alignment for Radiology Report Generation</strong><br><em>Ting Xiao, Lei Shi, Yang Zhang, HaoFeng Yang, Zhe Wang, Chenjia Bai</em></li>
  <li><strong>Chinese Inertial GAN for Handwriting Signal Generation and Recognition</strong><br><em>Yifeng Wang, Yi Zhao</em></li>
  <li><strong>LLMs Caught in the Crossfire: Malware Requests and Jailbreak Challenges</strong><br><em>Haoyang Li, Huan Gao, Zhiyuan Zhao, Zhiyu Lin, Junyu Gao, Xuelong Li</em></li>
  <li><strong>Evaluating Sequence Labeling on the basis of Information Theory</strong><br><em>Enrique Amigo, Elena Álvarez-Mellado, Julio Gonzalo, Jorge Carrillo-de-Albornoz</em></li>
  <li><strong>GRAT: Guiding Retrieval-Augmented Reasoning through Process Rewards Tree Search</strong><br><em>Xianshu Peng, Wei Wei</em></li>
  <li><strong>T-REG: Preference Optimization with Token-Level Reward Regularization</strong><br><em>Wenxuan Zhou, Shujian Zhang, Lingxiao Zhao, Tao Meng</em></li>
  <li><strong>Enhancing Input-Label Mapping in In-Context Learning with Contrastive Decoding</strong><br><em>Keqin Peng, Liang Ding, Yuanxin Ouyang, Meng Fang, Yancheng Yuan, Dacheng Tao</em></li>
  <li><strong>Gödel Agent: A Self-Referential Agent Framework for Recursively Self-Improvement</strong><br><em>Xunjian Yin, Xinyi Wang, Liangming Pan, Li Lin, Xiaojun Wan, William Yang Wang</em></li>
  <li><strong>AgentGym: Evaluating and Training Large Language Model-based Agents across Diverse Environments</strong><br><em>Zhiheng Xi, Yiwen Ding, Wenxiang Chen, Boyang Hong, Honglin Guo, Junzhe Wang, Xin Guo, Dingwen Yang, Chenyang Liao, Wei He, Songyang Gao, Lu Chen, Rui Zheng, Yicheng Zou, Tao Gui, Qi Zhang, Xipeng Qiu, Xuanjing Huang, Zuxuan Wu, Yu-Gang Jiang</em></li>
  <li><strong>Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A Perspective of Probability Theory</strong><br><em>Yexiang Liu, Zekun Li, Zhi Fang, Nan Xu, Ran He, Tieniu Tan</em></li>
  <li><strong>Learnability on the Information-Theoretic Continuum: Inductive Bias for Information Locality in Neural Language Models</strong><br><em>Taiga Someya, Anej Svete, Brian DuSell, Timothy J. O’Donnell, Mario Giulianelli, Ryan Cotterell</em></li>
  <li><strong>Learning to Reason Over Time: Timeline Self-Reflection for Improved Temporal Reasoning in Language Models</strong><br><em>Adrián Bazaga, Rexhina Blloshmi, Bill Byrne, Adrià de Gispert</em></li>
  <li><strong>Query-driven Document-level Scientific Evidence Extraction from Biomedical Studies</strong><br><em>Massimiliano Pronesti, Joao H Bettencourt-Silva, Paul Flanagan, Alessandra Pascale, Oisín Redmond, Anya Belz, Yufang Hou</em></li>
  <li><strong>Towards Robust Universal Information Extraction: Dataset, Evaluation, and Solution</strong><br><em>Jizhao Zhu, Akang Shi, Zixuan Li, Long Bai, Xiaolong Jin, Jiafeng Guo, Xueqi Cheng</em></li>
  <li><strong>Multi-perspective Alignment for Increasing Naturalness in Neural Machine Translation</strong><br><em>Huiyuan Lai, Esther Ploeger, Rik van Noord, Antonio Toral</em></li>
  <li><strong>Temporal reasoning for timeline summarisation in social media</strong><br><em>Jiayu Song, Mahmud Elahi Akhter, Dana Atzil-Slonim, Maria Liakata</em></li>
  <li><strong>Beyond Negative Stereotypes – Non-Negative Abusive Utterances about Identity Groups and Their Semantic Variants</strong><br><em>Tina Lommel, Elisabeth Eder, Josef Ruppenhofer, Michael Wiegand</em></li>
  <li><strong>Persistent Homology of Topic Networks for the Prediction of Reader Curiosity</strong><br><em>Manuel D.S. Hopp, Vincent Labatut, Arthur Amalvy, Richard Dufour, Hannah Stone, Hayley K Jach, Kou Murayama</em></li>
  <li><strong>Tokenisation is NP-Complete</strong><br><em>Philip Whittington, Gregor Bachmann, Tiago Pimentel</em></li>
  <li><strong>Understanding Language Model Scaling Laws in Terms of Training Dynamics via Loss Deceleration and Zero-Sum Learning</strong><br><em>Andrei Mircea, Ekaterina Lobacheva, Supriyo Chakraborty, Nima Chitsazan, Irina Rish</em></li>
  <li><strong>Parameter-Aware Contrastive Knowledge Editing: Tracing and Rectifying based on Critical Transmission Paths</strong><br><em>Songlin Zhai, Yuan Meng, Yuxin Zhang, Guilin Qi</em></li>
  <li><strong>Many Heads Are Better Than One: Improved Scientific Idea Generation by A LLM-Based Multi-Agent System</strong><br><em>Haoyang Su, Renqi Chen, SHIXIANG TANG, Zhenfei Yin, Xinzhe Zheng, Jinzhe Li, Biqing Qi, Qi Wu, Hui Li, Wanli Ouyang, Philip Torr, Bowen Zhou, Nanqing Dong</em></li>
  <li><strong>Inner Thinking Transformer: Leveraging Dynamic Depth Scaling to Foster Adaptive Internal Thinking</strong><br><em>Yilong Chen, Junyuan Shang, Zhenyu Zhang, Yanxi Xie, Jiawei Sheng, Tingwen Liu, Shuohuan Wang, Yu Sun, Hua Wu, Haifeng Wang</em></li>
  <li><strong>Document-Level Text Generation with Minimum Bayes Risk Decoding using Optimal Transport</strong><br><em>Yuu Jinnai</em></li>
  <li><strong>Opt-Out: Investigating Entity-Level Unlearning for Large Language Models via Optimal Transport</strong><br><em>Minseok Choi, Daniel Rim, Dohyun Lee, Jaegul Choo</em></li>
  <li><strong>Mixture of Small and Large Models for Chinese Spelling Check</strong><br><em>Ziheng Qiao, Houquan Zhou, Zhenghua Li</em></li>
  <li><strong>DISC: Plug-and-Play Decoding Intervention with Similarity of Characters for Chinese Spelling Check</strong><br><em>Ziheng Qiao, Houquan Zhou, Yumeng Liu, Zhenghua Li, Min Zhang, Bo Zhang, Chen Li, Ji Zhang, Fei Huang</em></li>
  <li><strong>The Causal Effect of Merge Operations in Bottom-up Tokenisers</strong><br><em>Pietro Lesci, Clara Meister, Thomas Hofmann, Andreas Vlachos, Tiago Pimentel</em></li>
  <li><strong>Value Residual Learning</strong><br><em>Zhanchao Zhou, Tianyi Wu, Zhiyun Jiang, Fares Obeid, Zhenzhong Lan</em></li>
  <li><strong>SGIC: A Self-Guided Iterative Calibration Framework for RAG</strong><br><em>Guanhua Chen, Yutong Yao, Lidia S. Chao, Xuebo Liu, Derek F. Wong</em></li>
  <li><strong>NusaAksara: A Multimodal and Multilingual Benchmark for Preserving Indonesian Indigenous Scripts</strong><br><em>Muhammad Farid Adilazuarda, Musa Izzanardi Wijanarko, Lucky Susanto, Khumaisa Nur’aini, Derry Tanti Wijaya, Alham Fikri Aji</em></li>
  <li><strong>LLM-based Rumor Detection via Influence Guided Sample Selection and Game-based Perspective Analysis</strong><br><em>Zhiliang Tian, jingyuan huang, Zejiang He, Zhen Huang, Menglong Lu, Linbo Qiao, Songzhu Mei, Yijie Wang, Dongsheng Li</em></li>
  <li><strong>Hierarchical-Task-Aware Multi-modal Mixture of Incremental LoRA Experts for Embodied Continual Learning</strong><br><em>Ziqi Jia, Anmin Wang, Xiaoyang Qu, Xiaowen Yang, Jianzong Wang</em></li>
  <li><strong>SpindleKV: A Novel KV Cache Reduction Method Balancing Both Shallow and Deep Layers</strong><br><em>Zicong Tang, Shi Luohe, Zuchao Li, Baoyuan Qi, Liu Guoming, Lefei Zhang, Ping Wang</em></li>
  <li><strong>Medical Graph RAG: Evidence-based Medical Large Language Model via Graph Retrieval-Augmented Generation</strong><br><em>Junde Wu, Jiayuan Zhu, Yunli Qi, Jingkun Chen, Min Xu, Filippo Menolascina, Yueming Jin, Vicente Grau</em></li>
  <li><strong>Unifying Uniform and Binary-coding Quantization for Accurate Compression of Large Language Models</strong><br><em>Seungcheol Park, Jeongin Bae, Beomseok Kwon, Minjun Kim, Byeongwook Kim, Se Jung Kwon, U Kang, Dongsoo Lee</em></li>
  <li><strong>Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools</strong><br><em>Junde Wu, Jiayuan Zhu, Yuyuan Liu, Min Xu, Yueming Jin</em></li>
  <li><strong>Probing Relative Interaction and Dynamic Calibration in Multi-modal Entity Alignment</strong><br><em>Chenxiao Li, Jingwei Cheng, Qiang Tong, Fu Zhang, Cairui Wang</em></li>
  <li><strong>Learn to Memorize: Scalable Continual Learning in Semiparametric Language Models with Mixture-of-Neighbors Induction Memory</strong><br><em>Guangyue Peng, Tao Ge, Wen Luo, Wei Li, Houfeng Wang</em></li>
  <li><strong>Adverse Event Extraction from Discharge Summaries: A New Dataset, Annotation Scheme, and Initial Findings</strong><br><em>Imane Guellil, Salomé Andres, Atul Anand, Bruce Guthrie, Huayu Zhang, Abul Hasan, Honghan Wu, Beatrice Alex</em></li>
  <li><strong>Speed Up Your Code: Progressive Code Acceleration Through Bidirectional Tree Editing</strong><br><em>Longhui Zhang, Jiahao Wang, Meishan Zhang, GaoXiong Cao, Ensheng Shi, mayuchi, Jun Yu, Honghai LIU, Jing Li, Min Zhang</em></li>
  <li><strong>Multi-Facet Blending for Faceted Query-by-Example Retrieval</strong><br><em>Heejin Do, Sangwon Ryu, Jonghwi Kim, Gary Lee</em></li>
  <li><strong>PIPER: Benchmarking and Prompting Event Reasoning Boundary of LLMs via Debiasing-Distillation Enhanced Tuning</strong><br><em>Zhicong Lu, Changyuan Tian, PeiguangLi, Li Jin, Sirui Wang, Wei Jia, Ying Shen, Guangluan Xu</em></li>
  <li><strong>MIR: Methodology Inspiration Retrieval for Scientific Research Problems</strong><br><em>Aniketh Garikaparthi, Manasi Patwardhan, Aditya Sanjiv Kanade, Aman Hassan, Lovekesh Vig, Arman Cohan</em></li>
  <li><strong>Sticking to the Mean: Detecting Sticky Tokens in Text Embedding Models</strong><br><em>Kexin Chen, Dongxia Wang, Yi Liu, Haonan Zhang, Wenhai Wang</em></li>
  <li><strong>Different Speech Translation Models Encode and Translate Speaker Gender Differently</strong><br><em>Dennis Fucci, Marco Gaido, Matteo Negri, Luisa Bentivogli, Andre Martins, Giuseppe Attanasio</em></li>
  <li><strong>Memorizing is Not Enough: Deep Knowledge Injection Through Reasoning</strong><br><em>Ruoxi Xu, Yunjie Ji, Boxi Cao, Yaojie Lu, Hongyu Lin, Xianpei Han, Ben He, Yingfei Sun, Xiangang Li, Le Sun</em></li>
  <li><strong>Improving Dialogue State Tracking through Combinatorial Search for In-Context Examples</strong><br><em>Haesung Pyun, Yoonah Park, Yohan Jo</em></li>
  <li><strong>Pretraining Context Compressor for Large Language Models with Embedding-Based Memory</strong><br><em>Yuhong Dai, Jianxun Lian, Yitian Huang, Wei Zhang, Mingyang Zhou, Mingqi Wu, Xing Xie, Hao Liao</em></li>
  <li><strong>Dialogue Systems for Emotional Support via Value Reinforcement</strong><br><em>Juhee Kim, Chunghu Mok, Jisun LEE, Hyang Sook Kim, Yohan Jo</em></li>
  <li><strong>Length-Induced Embedding Collapse in PLM-based Models</strong><br><em>Yuqi Zhou, Sunhao Dai, Zhanshuo Cao, Xiao Zhang, Jun Xu</em></li>
  <li><strong>SHuBERT: Self-Supervised Sign Language Representation Learning via Multi-Stream Cluster Prediction</strong><br><em>Shester Gueuwou, Xiaodan Du, Greg Shakhnarovich, Karen Livescu, Alexander H. Liu</em></li>
  <li><strong>ERU-KG: Efficient Reference-aligned Unsupervised Keyphrase Generation</strong><br><em>Lam Thanh Do, Aaditya Bodke, Pritom Saha Akash, Kevin Chen-Chuan Chang</em></li>
  <li><strong>Know Your Mistakes: Towards Preventing Overreliance on Task-Oriented Conversational AI Through Accountability Modeling</strong><br><em>Suvodip Dey, Yi-Jyun Sun, Gokhan Tur, Dilek Hakkani-Tür</em></li>
  <li><strong>LLMs Trust Humans More, That’s a Problem! Unveiling and Mitigating the Authority Bias in Retrieval-Augmented Generation</strong><br><em>Yuxuan LI, Xinwei Guo, Jiashi Gao, Guanhua Chen, Xiangyu Zhao, Jiaxin Zhang, Quanying Liu, Haiyan Wu, Xin Yao, Xuetao Wei</em></li>
  <li><strong>Divide-Then-Aggregate: An Efficient Tool Learning Method via Parallel Tool Invocation</strong><br><em>Dongsheng Zhu, Weixian Shi, Zhengliang Shi, Zhaochun Ren, Shuaiqiang Wang, Lingyong Yan, Dawei Yin</em></li>
  <li><strong>Reviving Cultural Heritage: A Novel Approach for Comprehensive Historical Document Restoration</strong><br><em>Yuyi Zhang, Peirong Zhang, Zhenhua Yang, Pengyu Yan, Yongxin Shi, Pengwei Liu, Fengjun Guo, Lianwen Jin</em></li>
  <li><strong>PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment</strong><br><em>Zekun Moore Wang, Shenzhi Wang, King Zhu, Jiaheng Liu, Ke Xu, Jie Fu, Wangchunshu Zhou, Wenhao Huang</em></li>
  <li><strong>Robust Utility-Preserving Text Anonymization Based on Large Language Models</strong><br><em>Tianyu Yang, Xiaodan Zhu, Iryna Gurevych</em></li>
  <li><strong>SEAL: Scaling to Emphasize Attention for Long-Context Retrieval</strong><br><em>Changhun Lee, Minsang Seok, Jun-gyu Jin, YoungHyun Cho, Eunhyeok Park</em></li>
  <li><strong>From Neurons to Semantics: Evaluating Cross-Linguistic Alignment Capabilities of Large Language Models via Neurons Alignment</strong><br><em>Chongxuan Huang, Yongshi Ye, Biao Fu, Qifeng Su, Xiaodong Shi</em></li>
  <li><strong>$\mathcal{A}^3$: Automatic Alignment Framework for Attributed Text Generation</strong><br><em>Yue Wang, Haoke Zhang, Juntao Li, Jinxiong Chang, Min Zhang</em></li>
  <li><strong>Towards Better Value Principles for Large Language Model Alignment: A Systematic Evaluation and Enhancement</strong><br><em>Bingbing Xu, Jing Yao, Xiaoyuan Yi, Aishan Maoliniyazi, Xing Xie, Xiaofeng Meng</em></li>
  <li><strong>Rethinking Semantic Parsing for Large Language Models: Enhancing LLM Performance with Semantic Hints</strong><br><em>Kaikai An, Shuzheng Si, Helan Hu, Haozhe Zhao, Yuchi Wang, Qingyan Guo, Baobao Chang</em></li>
  <li><strong>Language Models, Graph Searching, and Supervision Adulteration: When More Supervision is Less and How to Make More More</strong><br><em>Arvid Frydenlund</em></li>
  <li><strong>Comprehensive Analysis of Minimum Bayes Risk Decoding through Bias and Diversity Decomposition</strong><br><em>Hidetaka Kamigaito, Hiroyuki Deguchi, Yusuke Sakai, Katsuhiko Hayashi, Taro Watanabe</em></li>
  <li><strong>Performance Gap in Entity Knowledge Extraction Across Modalities in Vision Language Models</strong><br><em>Ido Cohen, Daniela Gottesman, Mor Geva, Raja Giryes</em></li>
  <li><strong>SDD: Self-Degraded Defense against Malicious Fine-tuning</strong><br><em>ZiXuan Chen, Weikai Lu, Xin Lin, Ziqian Zeng</em></li>
  <li><strong>CoachMe: Decoding Sport Elements with a Reference-Based Coaching Instruction Generation Model</strong><br><em>Wei-Hsin Yeh, Yu-An Su, Chih-Ning Chen, Yi-Hsueh Lin, Calvin Ku, WENHSIN CHIU, Min-Chun Hu, Lun-Wei Ku</em></li>
  <li><strong>DRPruning: Efficient Large Language Model Pruning through Distributionally Robust Optimization</strong><br><em>Hexuan Deng, Wenxiang Jiao, Xuebo Liu, Jing Li, Min Zhang, Zhaopeng Tu</em></li>
  <li><strong>How LLMs Comprehend Temporal Structure in Narratives: A Case Study in Cognitive Evaluation of LLMs</strong><br><em>Karin De Langis, Jong Inn Park, Andreas Schramm, Bin Hu, Khanh Chi Le, Dongyeop Kang</em></li>
  <li><strong>Data Caricatures: On the Representation of African American Language in Pretraining Corpora</strong><br><em>Nicholas Deas, Blake Vente, Amith Ananthram, Jessica A Grieser, Desmond U. Patton, Shana Kleiner, James R. Shepard III, Kathleen McKeown</em></li>
  <li><strong>Language Model Probabilities are $Not$ Calibrated in Numeric Contexts</strong><br><em>Charles Lovering, Michael Krumdick, Viet Dac Lai, Varshini Reddy, Seth Ebner, Nilesh Kumar, Rik Koncel-Kedziorski, Chris Tanner</em></li>
  <li><strong>MDCure: A Scalable Pipeline for Multi-Document Instruction-Following</strong><br><em>Gabrielle Kaili-May Liu, Bowen Shi, Avi Caciularu, Idan Szpektor, Arman Cohan</em></li>
  <li><strong>Misattribution Matters: Quantifying Unfairness in Authorship Attribution</strong><br><em>Pegah Alipoormolabashi, Ajay Patel, Niranjan Balasubramanian</em></li>
  <li><strong>Cross-Lingual Auto Evaluation for Assessing Multilingual LLMs</strong><br><em>Sumanth Doddapaneni, Mohammed Safi Ur Rahman Khan, Dilip Venkatesh, Raj Dabre, Anoop Kunchukuttan, Mitesh M Khapra</em></li>
  <li><strong>DeepReview: Improving LLM-based Paper Review with Human-like Deep Thinking Process</strong><br><em>Minjun Zhu, Yixuan Weng, Linyi Yang, Yue Zhang</em></li>
  <li><strong>Bypass Back-propagation: Optimization-based Structural Pruning for Large Language Models via Policy Gradient</strong><br><em>Yuan Gao, Zujing Liu, WEIZHONG ZHANG, Bo Du, Gui-Song Xia</em></li>
  <li><strong>Zero-Shot Text-to-Speech for Vietnamese</strong><br><em>Thi Vu, Linh The Nguyen, Dat Quoc Nguyen</em></li>
  <li><strong>Tree-of-Debate: Multi-Persona Debate Trees Elicit Critical Thinking for Scientific Comparative Analysis</strong><br><em>Priyanka Kargupta, Ishika Agarwal, Tal August, Jiawei Han</em></li>
  <li><strong>Hierarchical Memory Organization for Wikipedia Generation</strong><br><em>Eugene J. Yu, Dawei Zhu, Yifan Song, Xiangyu Wong, Jiebin Zhang, Wenxuan Shi, Xiaoguang Li, Qun Liu, Sujian Li</em></li>
  <li><strong>Class Distillation with Mahalanobis Contrast: An Efficient Training Paradigm for Pragmatic Language Understanding Tasks</strong><br><em>Chenlu Wang, Weimin Lyu, Ritwik Banerjee</em></li>
  <li><strong>Structure-aware Domain Knowledge Injection for Large Language Models</strong><br><em>Kai Liu, Ze Chen, Zhihang Fu, Wei Zhang, Rongxin Jiang, Fan Zhou, Yaowu Chen, Yue Wu, Jieping Ye</em></li>
  <li><strong>FinMME: A Financial Multi-Modal Evaluation Dataset</strong><br><em>Junyu Luo, Zhizhuo KOU, Liming Yang, Xiao Luo, Jinsheng Huang, Zhiping Xiao, Jingshu Peng, Chengzhong LIU, Jiaming Ji, Xuanzhe Liu, Sirui Han, Ming Zhang, Yike Guo</em></li>
  <li><strong>Dialectal Coverage And Generalization in Arabic Speech Recognition</strong><br><em>Amirbek Djanibekov, Hawau Olamide Toyin, Raghad Alshalan, Abdullah Alatir, Hanan Aldarmaki</em></li>
  <li><strong>Can LLMs Generate High-Quality Test Cases for Algorithm Problems? TestCase-Eval: A Systematic Evaluation of Fault Coverage and Exposure</strong><br><em>Zheyuan Yang, Zexi Kuang, Yilun Zhao</em></li>
  <li><strong>EditInspector: A Benchmark for Evaluation of Text-Guided Image Edits</strong><br><em>Ron Yosef, Yonatan Bitton, Dani Lischinski, Moran Yanuka</em></li>
  <li><strong>Reconsidering LLM Uncertainty Estimation Methods in the Wild</strong><br><em>Duygu Nur Yaldiz, Yavuz Faruk Bakman, Sungmin Kang, Tuo Zhang, Baturalp Buyukates, Sai Praneeth Karimireddy, Salman Avestimehr</em></li>
  <li><strong>Are Optimal Algorithms Still Optimal? Rethinking Sorting in LLM-Based Pairwise Ranking with Batching and Caching</strong><br><em>Juan Wisznia, Cecilia Bolaños, Juan Tollo, Giovanni Franco Gabriel Marraffini, Agustín Andrés Gianolini, Noe Fabian Hsueh, Luciano Del Corro</em></li>
  <li><strong>Bregman Conditional Random Fields: Sequence Labeling with Parallelizable Inference Algorithms</strong><br><em>Caio Corro, Mathieu Lacroix, Joseph Le Roux</em></li>
  <li><strong>SEE: Strategic Exploration and Exploitation for Cohesive In-Context Prompt Optimization</strong><br><em>Wendi Cui, Jiaxin Zhang, Zhuohang Li, Hao Sun, Damien Lopez, Kamalika Das, Bradley A. Malin, Sricharan Kumar</em></li>
  <li><strong>Programming by Example meets Historical Linguistics: A Large Language Model Based Approach to Sound Law Induction</strong><br><em>Atharva Naik, Darsh Agrawal, Hong Sng, Clayton Marr, Kexun Zhang, Nathaniel Romney Robinson, Kalvin Chang, Rebecca Byrnes, Aravind Mysore, Carolyn Rose, David R Mortensen</em></li>
  <li><strong>Synergizing Unsupervised Episode Detection with LLMs for Large-Scale News Events</strong><br><em>Priyanka Kargupta, Yunyi Zhang, Yizhu Jiao, Siru Ouyang, Jiawei Han</em></li>
  <li><strong>Beyond True or False: Retrieval-Augmented Hierarchical Analysis of Nuanced Claims</strong><br><em>Priyanka Kargupta, Runchu Tian, Jiawei Han</em></li>
  <li><strong>The Task Shield: Enforcing Task Alignment to Defend Against Indirect Prompt Injection in LLM Agents</strong><br><em>Feiran Jia, Tong Wu, Xin Qin, Anna Squicciarini</em></li>
  <li><strong>Sandcastles in the Storm: Revisiting the (Im)possibility of Strong Watermarking</strong><br><em>Fabrice Y Harel-Canada, Boran Erol, Connor Choi, Jason Liu, Gary Jiarui Song, Nanyun Peng, Amit Sahai</em></li>
  <li><strong>Time-MQA: Time Series Multi-Task Question Answering with Context Enhancement</strong><br><em>Yaxuan Kong, Yiyuan Yang, Yoontae Hwang, Wenjie Du, Stefan Zohren, Zhangyang Wang, Ming Jin, Qingsong Wen</em></li>
  <li><strong>From Perceptions to Decisions: Wildfire Evacuation Decision Prediction with Behavioral Theory-informed LLMs</strong><br><em>Ruxiao Chen, Chenguang Wang, Yuran Sun, Xilei Zhao, Susu Xu</em></li>
  <li><strong>GETReason: Enhancing Image Context Extraction through Hierarchical Multi-Agent Reasoning</strong><br><em>Shikhhar Siingh, Abhinav Rawat, Chitta Baral, Vivek Gupta</em></li>
  <li><strong>Hanging in the Balance: Pivotal Moments in Crisis Counseling Conversations</strong><br><em>Vivian Nguyen, Lillian Lee, Cristian Danescu-Niculescu-Mizil</em></li>
  <li><strong>Unveiling the Potential of BERT-family: A New Recipe for Building Scalable, General and Competitive Large Language Models</strong><br><em>Yisheng Xiao, Juntao Li, Wenpeng Hu, Min Zhang</em></li>
  <li><strong>TaxoAdapt: Aligning LLM-Based Multidimensional Taxonomy Construction to Evolving Research Corpora</strong><br><em>Priyanka Kargupta, Nan Zhang, Yunyi Zhang, Rui Zhang, Prasenjit Mitra, Jiawei Han</em></li>
  <li><strong>An Empirical Study of Iterative Refinements for Non-autoregressive Translation</strong><br><em>Yisheng Xiao, Pei Guo, Zechen Sun, Juntao Li, Kai Song, Min Zhang</em></li>
  <li><strong>Retrofitting Large Language Models with Dynamic Tokenization</strong><br><em>Darius Feher, Ivan Vulić, Benjamin Minixhofer</em></li>
  <li><strong>Principled Content Selection to Generate Diverse and Personalized Multi-Document Summaries</strong><br><em>Vishakh Padmakumar, Zichao Wang, David Arbour, Jennifer Healey</em></li>
  <li><strong>Bilingual Zero-Shot Stance Detection</strong><br><em>Chenye Zhao, Cornelia Caragea</em></li>
  <li><strong>GrammaMT: Improving Machine Translation with Grammar-Informed In-Context Learning</strong><br><em>Rita Ramos, Everlyn Asiko Chimoto, Maartje Ter Hoeve, Natalie Schluter</em></li>
  <li><strong>Theorem Prover as a Judge for Synthetic Data Generation</strong><br><em>Joshua Ong Jun Leang, Giwon Hong, Wenda Li, Shay B Cohen</em></li>
  <li><strong>Measuring the Effect of Transcription Noise on Downstream Language Understanding Tasks</strong><br><em>Ori Shapira, Shlomo Chazan, Amir David Nissan Cohen</em></li>
  <li><strong>Can You Trust LLMs’ Judgements of the Validity of Simple Inferences With Partisan Conclusions? – No!</strong><br><em>Reto Gubelmann, Ghassen Karray</em></li>
  <li><strong>PARME: Parallel Corpora for Low-Resourced Middle Eastern Languages</strong><br><em>Sina Ahmadi, Rico Sennrich, Erfan Karami, Ako Marani, Parviz Fekrazad, Gholamreza Akbarzadeh Baghban, Hanah Hadi, Semko Heidari, Mahîr Dogan, Pedram Asadi, Dashne Bashir, Mohammad Amin Ghodrati, Kourosh Amini, Zeynab Ashourinezhad, Mana Baladi, Farshid Ezzati, Alireza Ghasemifar, Daryoush Hosseinpour, Behrooz Abbaszadeh, Amin Hassanpour, Bahaddin jalal hamaamin, Saya Kamal Hama, Ardeshir Mousavi, Sarko Nazir Hussein, Isar Nejadgholi, Mehmet Ölmez, Horam Osmanpour, Rashid Roshan Ramezani, Aryan Sediq Aziz, Ali Salehi, Mohammadreza Yadegari, Kewyar Yadegari, Sedighe Zamani Roodsari</em></li>
  <li><strong>METAL: A Multi-Agent Framework for Chart Generation with Test-Time Scaling</strong><br><em>Bingxuan Li, Yiwei Wang, Jiuxiang Gu, Kai-Wei Chang, Nanyun Peng</em></li>
  <li><strong>ConLoan: A Contrastive Multilingual Dataset for Evaluating Loanwords</strong><br><em>Sina Ahmadi, Micha David Hess, Elena Álvarez-Mellado, Alessia Battisti, Cui Ding, Anne Göhring, Yingqiang Gao, Zifan Jiang, Andrianos Michail, Peshmerge Morad, Joel Niklaus, Maria Christina Panagiotopoulou, Stefano Perrella, Juri Opitz, Anastassia Shaitarova, Rico Sennrich</em></li>
  <li><strong>A Theory of LLM Sampling: Part Descriptive and Part Prescriptive</strong><br><em>Sarath Sivaprasad, Pramod Kaushik, Sahar Abdelnabi, Mario Fritz</em></li>
  <li><strong>MEraser: An Effective Fingerprint Erasure Approach for Large Language Models</strong><br><em>Jingxuan Zhang, Zhenhua Xu, Rui Hu, Wenpeng Xing, Xuhong Zhang, Meng Han</em></li>
  <li><strong>VISA: Retrieval Augmented Generation with Visual Source Attribution</strong><br><em>Xueguang Ma, Shengyao Zhuang, Bevan Koopman, Guido Zuccon, Wenhu Chen, Jimmy Lin</em></li>
  <li><strong>DRAMA: Diverse Augmentation from Large Language Models Towards Smaller Generalizable Dense Retrievers</strong><br><em>Xueguang Ma, Xi Victoria Lin, Barlas Oguz, Jimmy Lin, Wen-tau Yih, Xilun Chen</em></li>
  <li><strong>Stochastic Chameleons: Irrelevant Context Hallucinations Reveal Class-Based (Mis)Generalization in LLMs</strong><br><em>Ziling Cheng, Meng Cao, Marc-Antoine Rondeau, Jackie CK Cheung</em></li>
  <li><strong>TreeCut: A Synthetic Unanswerable Math Word Problem Dataset for LLM Hallucination Evaluation</strong><br><em>Jialin Ouyang</em></li>
  <li><strong>MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning</strong><br><em>Chanwoo Park, Seungju Han, Xingzhi Guo, Asuman E. Ozdaglar, Kaiqing Zhang, Joo-Kyung Kim</em></li>
  <li><strong>Map&amp;Make: Schema Guided Text to Table Generation</strong><br><em>Naman Ahuja, Fenil Bardoliya, Chitta Baral, Vivek Gupta</em></li>
  <li><strong>WinSpot: GUI Grounding Benchmark with Multimodal Large Language Models</strong><br><em>Zheng Hui, Yinheng Li, Dan Zhao, Colby Banbury, Tianyi Chen, Kazuhito Koishida</em></li>
  <li><strong>IRIS: Interpretable Retrieval-Augmented Classification for Long Interspersed Document Sequences</strong><br><em>Fengnan Li, Elliot D. Hill, JIANG SHU, Jiaxin Gao, Matthew M. Engelhard</em></li>
  <li><strong>Spurious Correlations and Beyond: Understanding and Mitigating Shortcut Learning in SDOH Extraction with Large Language Models</strong><br><em>Fardin Ahsan Sakib, Ziwei Zhu, Karen Trister Grace, Meliha Yetisgen, Ozlem Uzuner</em></li>
  <li><strong>Symmetrical Visual Contrastive Optimization: Aligning Vision-Language Models with Minimal Contrastive Images</strong><br><em>Shengguang Wu, Fan-Yun Sun, Kaiyue Wen, Nick Haber</em></li>
  <li><strong>Enhancing NER by Harnessing Multiple Datasets with Conditional Variational Autoencoders</strong><br><em>Taku Oi, Makoto Miwa</em></li>
  <li><strong>CHEER-Ekman: Fine-grained Embodied Emotion Classification</strong><br><em>Phan Anh Duong, Cat Luong, Divyesh Bommana, Tianyu Jiang</em></li>
  <li><strong>Can we Retrieve Everything All at Once? ARM: An Alignment-Oriented LLM-based Retrieval Method</strong><br><em>Peter Baile Chen, Yi Zhang, Mike Cafarella, Dan Roth</em></li>
  <li><strong>R2D2: Remembering, Replaying and Dynamic Decision Making with a Reflective Agentic Memory</strong><br><em>Tenghao Huang, Kinjal Basu, Ibrahim Abdelaziz, Pavan Kapanipathi, Jonathan May, Muhao Chen</em></li>
  <li><strong>ScanEZ: Integrating Cognitive Models with Self-Supervised Learning for Spatiotemporal Scanpath Prediction</strong><br><em>Ekta Sood, Prajit Dhar, Enrica Troiano, Rosy Southwell, Sidney K. DMello</em></li>
  <li><strong>FairI Tales: Evaluation of Fairness in Indian Contexts with a Focus on Bias and Stereotypes</strong><br><em>Janki Atul Nawale, Mohammed Safi Ur Rahman Khan, Janani D, Danish Pruthi, Mitesh M Khapra</em></li>
  <li><strong>SpeechIQ: Speech-Agentic Intelligence Quotient Across Cognitive Levels in Voice Understanding by Large Language Models</strong><br><em>Zhen Wan, Chao-Han Huck Yang, Yahan Yu, Jinchuan Tian, Sheng Li, Ke Hu, Zhehuai Chen, Shinji Watanabe, Fei Cheng, Chenhui Chu, Yu-Chiang Frank Wang, Sadao Kurohashi</em></li>
  <li><strong>Predicting Implicit Arguments in Procedural Video Instructions</strong><br><em>Anil Batra, Laura Sevilla-Lara, Marcus Rohrbach, Frank Keller</em></li>
  <li><strong>InjecGuard: Benchmarking and Mitigating Over-defense in Prompt Injection Guardrail Models</strong><br><em>Hao Li, Xiaogeng Liu, Ning Zhang, Chaowei Xiao</em></li>
  <li><strong>CLIPErase: Efficient Unlearning of Visual-Textual Associations in CLIP</strong><br><em>Tianyu Yang, Lisen Dai, Xiangqi Wang, Minhao Cheng, Yapeng Tian, Xiangliang Zhang</em></li>
  <li><strong>ViGiL3D: A Linguistically Diverse Dataset for 3D Visual Grounding</strong><br><em>Austin Wang, ZeMing Gong, Angel X Chang</em></li>
  <li><strong>The time scale of redundancy between prosody and linguistic context</strong><br><em>Tamar I Regev, Chiebuka Ohams, Shaylee Xie, Lukas Wolf, Evelina Fedorenko, Alex Warstadt, Ethan Wilcox, Tiago Pimentel</em></li>
  <li><strong>Improving Fairness of Large Language Models in Multi-document Summarization</strong><br><em>Haoyuan Li, Rui Zhang, Snigdha Chaturvedi</em></li>
  <li><strong>Basic Reading Distillation</strong><br><em>Zhi Zhou, Sirui Miao, Xiangyu Duan, Hao Yang, Min Zhang</em></li>
  <li><strong>Quantized Can Still Be Calibrated: A Unified Framework to Calibration in Quantized Large Language Models</strong><br><em>Mingyu Zhong, Guanchu Wang, Yu-Neng Chuang, Na Zou</em></li>
  <li><strong>Fine-Grained Spatio-Temporal Modeling of Reading Behavior</strong><br><em>Francesco Ignazio Re, Andreas Opedal, Glib Manaiev, Mario Giulianelli, Ryan Cotterell</em></li>
  <li><strong>More is not always better? Enhancing Many-Shot In-Context Learning with Differentiated and Reweighting Objectives</strong><br><em>Xiaoqing Zhang, Ang Lv, Yuhan Liu, Flood Sung, Wei Liu, Jian Luan, Shuo Shang, Xiuying Chen, Rui Yan</em></li>
  <li><strong>Astute RAG: Overcoming Imperfect Retrieval Augmentation and Knowledge Conflicts for Large Language Models</strong><br><em>Fei Wang, Xingchen Wan, Ruoxi Sun, Jiefeng Chen, Sercan O Arik</em></li>
  <li><strong>SubLIME: Subset Selection via Rank Correlation Prediction for Data-Efficient LLM Evaluation</strong><br><em>Gayathri Saranathan, Cong Xu, Mahammad Parwez Alam, Tarun Kumar, Martin Foltin, Soon Yee Wong, Suparna Bhattacharya</em></li>
  <li><strong>$\text{M}^3\text{GQA}$: A Multi-Entity Multi-Hop Multi-Setting Graph Question Answering Benchmark</strong><br><em>Boci Peng, Yongchao Liu, Xiaohe Bo, Jiaxin Guo, Yun Zhu, Xuanbo Fan, Chuntao Hong, Yan Zhang</em></li>
  <li><strong>LSSF: Safety Alignment for Large Language Models through Low-Rank Safety Subspace Fusion</strong><br><em>Guanghao Zhou, Panjia Qiu, Cen Chen, Hongyu Li, Jason Chu, Xin Zhang, JUN ZHOU</em></li>
  <li><strong>Should I Believe in What Medical AI Says? A Chinese Benchmark for Medication Based on Knowledge and Reasoning</strong><br><em>Yue Wu, Yangmin Huang, Qianyun Du, Lixian Lai, Zhiyang He, Jiaxue Hu, Xiaodong Tao</em></li>
  <li><strong>ETF: An Entity Tracing Framework for Hallucination Detection in Code Summaries</strong><br><em>Kishan Maharaj, Vitobha Munigala, Srikanth G. Tamilselvam, Prince Kumar, Sayandeep Sen, Palani Kodeswaran, Abhijit Mishra, Pushpak Bhattacharyya</em></li>
  <li><strong>Meta-Tool: Unleash Open-World Function Calling Capabilities of General-Purpose Large Language Models</strong><br><em>Shengqian Qin, Yakun Zhu, Linjie Mu, Shaoting Zhang, Xiaofan Zhang</em></li>
  <li><strong>Benchmarking and Improving Large Vision-Language Models for Fundamental Visual Graph Understanding and Reasoning</strong><br><em>Yingjie Zhu, Xuefeng Bai, Kehai Chen, Yang Xiang, Jun Yu, Min Zhang</em></li>
  <li><strong>ISR: Self-Refining Referring Expressions for Entity Grounding</strong><br><em>Zhuocheng Yu, Bingchan Zhao, Yifan Song, Sujian Li, ZHONGHUI HE</em></li>
  <li><strong>Activating Distributed Visual Region within LLMs for Efficient and Effective Vision-Language Training and Inference</strong><br><em>Siyuan Wang, Dianyi Wang, Chengxing Zhou, Zejun Li, Zhihao Fan, Xuanjing Huang, zhongyu wei</em></li>
  <li><strong>CCHall: A Novel Benchmark for Joint Cross-Lingual and Cross-Modal Hallucinations Detection in Large Language Models</strong><br><em>Yongheng Zhang, Xu Liu, Ruoxi Zhou, Qiguang Chen, Hao Fei, Wenpeng Lu, Libo Qin</em></li>
  <li><strong>TestNUC: Enhancing Test-Time Computing Approaches through Neighboring Unlabeled Data Consistency</strong><br><em>Henry Peng Zou, Zhengyao Gu, Yue Zhou, Yankai Chen, Weizhi Zhang, Liancheng Fang, Yibo Wang, Yangning Li, Kay Liu, Philip S. Yu</em></li>
  <li><strong>The Esethu Framework: Reimagining Sustainable Dataset Governance and Curation for Low-Resource Languages</strong><br><em>Jenalea Rajab, Anuoluwapo Aremu, Everlyn Asiko Chimoto, Graham Morrissey, Fadel Thior, Jessica Ojo, Atnafu Lambebo Tonja, Wilhelmina Nekoto, Pelonomi Moiloa, Jade Abbott, Vukosi Marivate, Benjamin Rosman</em></li>
  <li><strong>Theoretical Analysis of Hierarchical Language Recognition and Generation by Transformers without Positional Encoding</strong><br><em>Daichi Hayakawa, Issei Sato</em></li>
  <li><strong>Less is More: Explainable and Efficient ICD Code Prediction with Clinical Entities</strong><br><em>James Douglas, Yidong Gan, Ben Hachey, Jonathan K. Kummerfeld</em></li>
  <li><strong>Benchmarking LLMs and LLM-based Agents in Practical Vulnerability Detection for Code Repositories</strong><br><em>Alperen Yildiz, Sin G Teo, Yiling Lou, Yebo Feng, Chong Wang, Dinil Mon Divakaran</em></li>
  <li><strong>Multi-Modality Expansion and Retention for LLMs through Parameter Merging and Decoupling</strong><br><em>Junlin Li, Guodong DU, Jing Li, Sim Kuan Goh, Wenya Wang, Yequan Wang, Fangming Liu, Ho-Kin Tang, Saleh Alharbi, Daojing He, Min Zhang</em></li>
  <li><strong>Serial Lifelong Editing via Mixture of Knowledge Experts</strong><br><em>YuJu Cheng, Yu-Chu Yu, Kai-Po Chang, Yu-Chiang Frank Wang</em></li>
  <li><strong>Towards Efficient LLM Post Training: A Data-centric Perspective</strong><br><em>Junyu Luo, Bohan Wu, Xiao Luo, Zhiping Xiao, Yiqiao Jin, Rong-Cheng Tu, Nan Yin, Yifan Wang, Jingyang Yuan, Wei Ju, Ming Zhang</em></li>
  <li><strong>IMOL: Incomplete-Modality-Tolerant Learning for Multi-Domain Fake News Video Detection</strong><br><em>Zhi Zeng, Jiaying Wu, Minnan Luo, Herun Wan, Xiangzheng Kong, Zihan Ma, Guang Dai, Qinghua Zheng</em></li>
  <li><strong>DDxTutor: Clinical Reasoning Tutoring System with Differential Diagnosis-Based Structured Reasoning</strong><br><em>Qian Wu, Zheyao Gao, Longfei Gou, Qi Dou</em></li>
  <li><strong>SocialEval: Evaluating Social Intelligence of Large Language Models</strong><br><em>Jinfeng Zhou, Yuxuan Chen, Yihan Shi, Xuanming Zhang, Leqi Lei, Yi Feng, Zexuan Xiong, Miao Yan, Xunzhi Wang, Yaru Cao, Jianing Yin, Shuai Wang, Quanyu Dai, Zhenhua Dong, Hongning Wang, Minlie Huang</em></li>
  <li><strong>Hidden in Plain Sight: Evaluation of the Deception Detection Capabilities of LLMs in Multimodal Settings</strong><br><em>Md Messal Monem Miah, Adrita Anika, Xi Shi, Ruihong Huang</em></li>
  <li><strong>Analyzing and Mitigating Inconsistency in Discrete Speech Tokens for Neural Codec Language Models</strong><br><em>Wenrui Liu, Zhifang Guo, Jin Xu, Yuanjun Lv, Yunfei Chu, Zemin Liu, Junyang Lin</em></li>
  <li><strong>PlanningArena: A Modular Benchmark for Multidimensional Evaluation of Planning and Tool Learning</strong><br><em>Zihan Zheng, Tianle Cui, Chuwen Xie, Jiahui Pan, Qianglong Chen, Lewei He</em></li>
  <li><strong>FocusLLM: Precise Understanding of Long Context by Dynamic Condensing</strong><br><em>Zhenyu Li, Yike Zhang, Tengyu Pan, Yutao Sun, Zhichao Duan, Junjie Fang, Rong Han, Zixuan Wang, Jianyong Wang</em></li>
  <li><strong>Negative Matters: Multi-Granularity Hard-Negative Synthesis and Anchor-Token-Aware Pooling for Enhanced Text Embeddings</strong><br><em>Tengyu Pan, Zhichao Duan, Zhenyu Li, Bowen Dong, Ning Liu, Xiuxing Li, Jianyong Wang</em></li>
  <li><strong>GPT-4 as a Homework Tutor Can Improve Student Engagement and Learning Outcomes</strong><br><em>Alessandro Vanzo, Sankalan Pal Chowdhury, Mrinmaya Sachan</em></li>
  <li><strong>Diffusion Models Through a Global Lens: Are They Culturally Inclusive?</strong><br><em>Zahra Bayramli, Ayhan Suleymanzade, Na Min An, Huzama Ahmad, Eunsu Kim, Junyeong Park, James Thorne, Alice Oh</em></li>
  <li><strong>Representation-based Reward Modeling for Efficient Safety Alignment of Large Language Model</strong><br><em>Deng Qiyuan, Xuefeng Bai, Kehai Chen, Yaowei Wang, Liqiang Nie, Min Zhang</em></li>
  <li><strong>English-based acoustic models perform well in the forced-alignment of two English-Based Pacific Creoles</strong><br><em>Sam Passmore, Lila San Roque, Saurabh Nath, Keira Mullan, Kira Davey, Rosey Billington, Nick Thieberger, Danielle Barth</em></li>
  <li><strong>Subtle Errors in Reasoning: Preference Learning via Error-injected Self-editing</strong><br><em>Kaishuai Xu, Tiezheng YU, Wenjun Hou, Yi Cheng, Chak Tou Leong, Liangyou Li, Xin Jiang, Lifeng Shang, Qun Liu, Wenjie Li</em></li>
  <li><strong>Truth Knows No Language: Evaluating Truthfulness Beyond English</strong><br><em>Blanca Calvo Figueras, Eneko Sagarzazu, Julen Etxaniz, Jeremy Barnes, Pablo Gamallo, Iria de-Dios-Flores, Rodrigo Agerri</em></li>
  <li><strong>Revisiting Compositional Generalization Capability of Large Language Models Considering Instruction Following Ability</strong><br><em>Yusuke Sakai, Hidetaka Kamigaito, Taro Watanabe</em></li>
  <li><strong>Batayan: A Filipino NLP benchmark for evaluating Large Language Models</strong><br><em>Jann Railey Montalan, Jimson Paulo Layacan, David Demitri Africa, Richell Isaiah S. Flores, Michael T. Lopez II, Theresa Denise Magsajo, Anjanette Cayabyab, William Chandra Tjhi</em></li>
  <li><strong>HintsOfTruth: A Multimodal Checkworthiness Detection Dataset with Real and Synthetic Claims</strong><br><em>Michiel van der Meer, Pavel Korshunov, Sébastien Marcel, Lonneke van der Plas</em></li>
  <li><strong>CityNavAgent: Aerial Vision-and-Language Navigation with Hierarchical Semantic Planning and Global Memory</strong><br><em>Weichen Zhang, Chen Gao, Shiquan Yu, Ruiying Peng, Baining Zhao, Qian Zhang, Jinqiang Cui, Xinlei Chen, Yong Li</em></li>
  <li><strong>It’s Not a Walk in the Park! Challenges of Idiom Translation in Speech-to-text Systems</strong><br><em>Iuliia Zaitova, Badr M. Abdullah, Wei Xue, Dietrich Klakow, Bernd Möbius, Tania Avgustinova</em></li>
  <li><strong>PolyNarrative: A Multilingual, Multilabel, Multi-domain Dataset for Narrative Extraction from News Articles</strong><br><em>Nikolaos Nikolaidis, Nicolas Stefanovitch, Purificação Silvano, Dimitar Iliyanov Dimitrov, Roman Yangarber, Nuno Guimarães, Elisa Sartori, Ion Androutsopoulos, Preslav Nakov, Giovanni Da San Martino, Jakub Piskorski</em></li>
  <li><strong>Rethinking Evaluation Metrics for Grammatical Error Correction: Why Use a Different Evaluation Process than Human?</strong><br><em>Takumi Goto, Yusuke Sakai, Taro Watanabe</em></li>
  <li><strong>A Parameter-Efficient and Fine-Grained Prompt Learning for Vision-Language Models</strong><br><em>Yongbin Guo, Shuzhen Li, zhulin liu, Tong Zhang, C.L.Philip Chen</em></li>
  <li><strong>Persona Dynamics: Unveiling the Impact of Persona Traits on Agents in Text-Based Games</strong><br><em>Seungwon Lim, Seungbeen Lee, Dongjun Min, Youngjae Yu</em></li>
  <li><strong>SeedBench: A Multi-task Benchmark for Evaluating Large Language Models in Seed Science</strong><br><em>Jie Ying, Zihong Chen, Zhefan Wang, Wanli Jiang, Chenyang Wang, Zhonghang Yuan, Haoyang Su, Huanjun Kong, Fan Yang, Nanqing Dong</em></li>
  <li><strong>𝛿-Stance: A Large-Scale Real World Dataset of Stances in Legal Argumentation</strong><br><em>Ankita Gupta, Douglas Rice, Brendan O’Connor</em></li>
  <li><strong>Re$^{3}$Syn: A Dependency-Based Data Synthesis Framework for Long-Context Post-training</strong><br><em>Zhiyang Zhang, Ziqiang Liu, Huiming Wang, Renke Shan, Li Kuang, Lu Wang</em></li>
  <li><strong>Enabling Chatbots with Eyes and Ears: An Immersive Multimodal Conversation System for Dynamic Interactions</strong><br><em>Jihyoung Jang, Minwook Bae, Minji Kim, Dilek Hakkani-Tür, Hyounghun Kim</em></li>
  <li><strong>Learning Auxiliary Tasks Improves Reference-Free Hallucination Detection in Open-Domain Long-Form Generation</strong><br><em>Chengwei Qin, Wenxuan Zhou, Karthik Abinav Sankararaman, Nanshu Wang, Tengyu Xu, Alexander Radovic, Eryk Helenowski, Arya Talebzadeh, Aditya Tayade, Sinong Wang, Shafiq Joty, Han Fang, Hao Ma</em></li>
  <li><strong>Multimodal Coreference Resolution for Chinese Social Media Dialogues: Dataset and Benchmark Approach</strong><br><em>Xingyu Li, Chen Gong, Guohong Fu</em></li>
  <li><strong>TACLR: A Scalable and Efficient Retrieval-based Method for Industrial Product Attribute Value Identification</strong><br><em>Yindu Su, Huike Zou, Lin Sun, Ting Zhang, Haiyang Yang, Chen Li Yu, David Lo, qingheng zhang, Shuguang Han, jufeng chen</em></li>
  <li><strong>A Review of Theory of Mind Capabilities in Large Language Models</strong><br><em>Ruirui Chen, Weifeng Jiang, Chengwei Qin, Cheston Tan</em></li>
  <li><strong>Completing A Systematic Review in Hours instead of Months with Interactive AI Agents</strong><br><em>Rui Qiu, Shijie Chen, Yu Su, Po-Yin Yen, Han Wei Shen</em></li>
  <li><strong>CMHKF: Cross-Modality Heterogeneous Knowledge Fusion for Weakly Supervised Video Anomaly Detection</strong><br><em>Shengping Song, Yongsen Zheng, Wuchun He, Guohua Wang</em></li>
  <li><strong>CLaSp: In-Context Layer Skip for Self-Speculative Decoding</strong><br><em>Longze Chen, Renke Shan, Huiming Wang, Lu Wang, Ziqiang Liu, Run Luo, Jiawei Wang, Hamid Alinejad-Rokny, Min Yang</em></li>
  <li><strong>Teaching Text Agents to Learn Sequential Decision Making from Failure</strong><br><em>Canasai Kruengkrai, Koichiro Yoshino</em></li>
  <li><strong>The Harmonic Structure of Information Contours</strong><br><em>Eleftheria Tsipidi, Samuel Kiegeland, Franz Nowak, Tianyang Xu, Ethan Wilcox, Alex Warstadt, Ryan Cotterell, Mario Giulianelli</em></li>
  <li><strong>REAL-MM-RAG: A Real-World Multi-Modal Retrieval Benchmark</strong><br><em>navve wasserman, roi pony, Oshri Naparstek, Adi Raz Goldfarb, Eli Schwartz, Udi Barzelay, Leonid Karlinsky</em></li>
  <li><strong>Only a Little to the Left: A Theory-grounded Measure of Political Bias in Large Language Models</strong><br><em>Mats Faulborn, Indira Sen, Max Pellert, Andreas Spitz, David Garcia</em></li>
  <li><strong>LongSafety: Evaluating Long-Context Safety of Large Language Models</strong><br><em>Yida Lu, Jiale Cheng, Zhexin Zhang, Shiyao Cui, Cunxiang Wang, Xiaotao Gu, Yuxiao Dong, Jie Tang, Hongning Wang, Minlie Huang</em></li>
  <li><strong>Exploiting Contextual Knowledge in LLMs through $\mathcal{V}$-usable Information based Layer Enhancement</strong><br><em>Xiaowei Yuan, Zhao Yang, Ziyang Huang, Yequan Wang, Siqi Fan, Yiming Ju, Jun Zhao, Kang Liu</em></li>
  <li><strong>Unintended Harms of Value-Aligned LLMs: Psychological and Empirical Insights</strong><br><em>Sooyung Choi, Jaehyeok Lee, Xiaoyuan Yi, Jing Yao, Xing Xie, JinYeong Bak</em></li>
  <li><strong>Maximal Matching Matters: Preventing Representation Collapse for Robust Cross-Modal Retrieval</strong><br><em>Hani Alomari, Anushka Sivakumar, Andrew Zhang, Chris Thomas</em></li>
  <li><strong>The Noisy Path from Source to Citation: Measuring How Scholars Engage with Past Research</strong><br><em>Hong Chen, Misha Teplitskiy, David Jurgens</em></li>
  <li><strong>MAPLE: Enhancing Review Generation with Multi-Aspect Prompt LEarning in Explainable Recommendation</strong><br><em>Ching-Wen Yang, Zhi-Quan Feng, Ying-Jia Lin, Che Wei Chen, Kun-da Wu, Hao Xu, Yao Jui-Feng, Hung-Yu Kao</em></li>
  <li><strong>Separating Tongue from Thought: Activation Patching Reveals Language-Agnostic Concept Representations in Transformers</strong><br><em>Clément Dumas, Chris Wendler, Veniamin Veselovsky, Giovanni Monea, Robert West</em></li>
  <li><strong>Behavioural vs. Representational Systematicity in End-to-End Models: An Opinionated Survey</strong><br><em>Ivan Vegner, Sydelle de Souza, Valentin Forch, Martha Lewis, Leonidas A. A. Doumas</em></li>
  <li><strong>Dynamic Chunking and Selection for Reading Comprehension of Ultra-Long Context in Large Language Models</strong><br><em>Boheng Sheng, Jiacheng Yao, Meicong Zhang, Guoxiu He</em></li>
  <li><strong>DualRAG: A Dual-Process Approach to Integrate Reasoning and Retrieval for Multi-Hop Question Answering</strong><br><em>Rong Cheng, Jinyi Liu, YAN ZHENG, Fei Ni, Jiazhen Du, Hangyu Mao, Fuzheng Zhang, Bo Wang, Jianye HAO</em></li>
  <li><strong>Deliberate Reasoning for Language Models as Structure-aware Planning with Accurate World Model</strong><br><em>Siheng Xiong, Ali Payani, Yuan Yang, Faramarz Fekri</em></li>
  <li><strong>Refining Salience-Aware Sparse Fine-Tuning Strategies for Language Models</strong><br><em>Xinxin Liu, Aaron Thomas, Cheng Zhang, Jianyi Cheng, Yiren Zhao, Xitong Gao</em></li>
  <li><strong>Efficient Many-Shot In-Context Learning with Dynamic Block-Sparse Attention</strong><br><em>Emily Xiao, Chin-Jou Li, Yilin Zhang, Graham Neubig, Amanda Bertsch</em></li>
  <li><strong>ScaleBiO: Scalable Bilevel Optimization for LLM Data Reweighting</strong><br><em>Rui Pan, Dylan Zhang, Hanning Zhang, Xingyuan Pan, Minrui Xu, Jipeng Zhang, Renjie Pi, Xiaoyu Wang, Tong Zhang</em></li>
  <li><strong>BeaverTails v2: Towards Multi-Level Safety Alignment for LLMs with Human Preference</strong><br><em>Jiaming Ji, Donghai Hong, Borong Zhang, Boyuan Chen, Josef Dai, Boren Zheng, Tianyi Qiu, Jiayi Zhou, Kaile Wang, Boxun Li, Sirui Han, Yike Guo, Yaodong Yang</em></li>
  <li><strong>What Happened in LLMs Layers when Trained for Fast vs. Slow Thinking: A Gradient Perspective</strong><br><em>Ming Li, Yanhong Li, Tianyi Zhou</em></li>
  <li><strong>Beyond Text Compression: Evaluating Tokenizers Across Scales</strong><br><em>Jonas F. Lotz, António V. Lopes, Stephan Peitz, Hendra Setiawan, Leonardo Emili</em></li>
  <li><strong>WiCkeD: A Simple Method to Make Multiple Choice Benchmarks More Challenging</strong><br><em>Ahmed Elhady, Eneko Agirre, Mikel Artetxe</em></li>
  <li><strong>Emergent Abilities of Large Language Models under Continued Pre-training for Language Adaptation</strong><br><em>Ahmed Elhady, Eneko Agirre, Mikel Artetxe</em></li>
  <li><strong>R-Fairness: Assessing Fairness of Ranking in Subjective Data</strong><br><em>Lorenzo Balzotti, Donatella Firmani, Jerin George Mathew, Riccardo Torlone, Sihem Amer-Yahia</em></li>
  <li><strong>RePanda: Pandas-powered Tabular Verification and Reasoning</strong><br><em>Atoosa Chegini, Keivan Rezaei, Hamid Eghbalzadeh, Soheil Feizi</em></li>
  <li><strong>Towards Style Alignment in Cross-Cultural Translation</strong><br><em>Shreya Havaldar, Adam Stein, Eric Wong, Lyle Ungar</em></li>
  <li><strong>TiC-LM: A Web-Scale Benchmark for Time-Continual LLM Pretraining</strong><br><em>Jeffrey Li, Mohammadreza Armandpour, Seyed Iman Mirzadeh, Sachin Mehta, Vaishaal Shankar, Raviteja Vemulapalli, Samy Bengio, Oncel Tuzel, Mehrdad Farajtabar, Hadi Pouransari, Fartash Faghri</em></li>
  <li><strong>Entailed Between the Lines: Incorporating Implication into NLI</strong><br><em>Shreya Havaldar, Hamidreza Alvari, John Palowitch, Mohammad Javad Hosseini, Senaka Buthpitiya, Alex Fabrikant</em></li>
  <li><strong>Multi-Level Explanations for Generative Language Models</strong><br><em>Lucas Monteiro Paes, Dennis Wei, Hyo Jin Do, Hendrik Strobelt, Ronny Luss, Amit Dhurandhar, Manish Nagireddy, Karthikeyan Natesan Ramamurthy, Prasanna Sattigeri, Werner Geyer, Soumya Ghosh</em></li>
  <li><strong>A Multi-Agent Framework for Mitigating Dialect Biases in Privacy Policy Question-Answering Systems</strong><br><em>Đorđe Klisura, Astrid R Bernaga Torres, Anna Karen Gárate-Escamilla, Rajesh Roshan Biswal, Ke Yang, Hilal Pataci, Anthony Rios</em></li>
  <li><strong>Low-Bit Quantization Favors Undertrained LLMs: Scaling Laws for Quantized LLMs with 100T Training Tokens</strong><br><em>Xu Ouyang, Tao Ge, Thomas Hartvigsen, Zhisong Zhang, Haitao Mi, Dong Yu</em></li>
  <li><strong>Enhancing User-Controlled Text-to-Image Generation with Layout-Aware Personalization</strong><br><em>Hongliang Luo, Wei Xi</em></li>
  <li><strong>LETS-C: Leveraging Text Embedding for Time Series Classification</strong><br><em>Rachneet Kaur, Zhen Zeng, Tucker Balch, Manuela Veloso</em></li>
  <li><strong>Benchmarking Video-Language Models for Embodied Motion Cognition in Urban Open-Ended Spaces</strong><br><em>Baining Zhao, Jianjie Fang, Zichao Dai, Ziyou Wang, Jirong Zha, Weichen Zhang, Chen Gao, Yue Wang, Jinqiang Cui, Xinlei Chen, Yong Li</em></li>
  <li><strong>HELIOS: Harmonizing Early Fusion, Late Fusion, and LLM Reasoning for Multi-Granular Table-Text Retrieval</strong><br><em>Sungho Park, Joohyung Yun, Jongwuk Lee, Wook-Shin Han</em></li>
  <li><strong>ONEBench to Test Them All: Sample-Level Benchmarking Over Open-Ended Capabilities</strong><br><em>Adhiraj Ghosh, Sebastian Dziadzio, Ameya Prabhu, Vishaal Udandarao, Samuel Albanie, Matthias Bethge</em></li>
  <li><strong>La Leaderboard: A Large Language Model Leaderboard for Spanish Varieties and Languages of Spain and Latin America</strong><br><em>María Grandury, Javier Aula-Blasco, Júlia Falcão, Clémentine Fourrier, Miguel González Saiz, Gonzalo Martínez, Gonzalo Santamaria Gomez, Rodrigo Agerri, Nuria Aldama García, Luis Chiruzzo, Javier Conde, Helena Gomez Adorno, Marta Guerrero Nieto, Guido Ivetta, Natàlia López Fuertes, Flor Miriam Plaza-del-Arco, María-Teresa Martín-Valdivia, Helena Montoro Zamorano, Carmen Muñoz Sanz, Pedro Reviriego, Leire Rosado Plaza, Alejandro Vaca Serrano, Estrella Vallecillo-Rodríguez, Jorge Vallego, Irune Zubiaga</em></li>
  <li><strong>Navigating the Prompt Space: Supervision Matters in CoT When Reasoning Misleads</strong><br><em>Xiang Zhang, Juntai Cao, Chenyu You, Dujian Ding</em></li>
  <li><strong>Energy Considerations of Large Language Model Inference and Efficiency Optimizations</strong><br><em>Jared Fernandez, Clara Na, Vashisth Tiwari, Yonatan Bisk, Sasha Luccioni, Emma Strubell</em></li>
  <li><strong>Optimizing Pre-Training Data Mixtures with Mixtures of Data Expert Models</strong><br><em>Lior Belenki, Alekh Agarwal, Tianze Shi, Kristina Toutanova</em></li>
  <li><strong>BFS-Prover: Scalable Best-First Tree Search for LLM-based Automatic Theorem Proving</strong><br><em>Ran Xin, Chenguang Xi, Jie Yang, Feng Chen, Hang Wu, Xia Xiao, Yifan Sun, Shen Zheng, Ming Ding</em></li>
  <li><strong>Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation</strong><br><em>Fan Yin, Zifeng Wang, I-Hung Hsu, Jun Yan, Ke Jiang, Yanfei Chen, Jindong Gu, Long Le, Kai-Wei Chang, Chen-Yu Lee, Hamid Palangi, Tomas Pfister</em></li>
  <li><strong>Cross-Lingual Representation Alignment Through Contrastive Image-Caption Tuning</strong><br><em>Nathaniel Krasner, Nicholas Lanuzo, Antonios Anastasopoulos</em></li>
  <li><strong>Logic-Regularized Verifier Elicits Reasoning from LLMs</strong><br><em>Xinyu Wang, Changzhi Sun, Lian Cheng, Yuanbin Wu, Dell Zhang, Xuelong Li, Xiaoling Wang</em></li>
  <li><strong>Squeezed Attention: Fast Fixed Context Processing for Long Context Length LLM Applications</strong><br><em>Coleman Richard Charles Hooper, Sehoon Kim, Hiva Mohammadzadeh, Monishwaran Maheswaran, Sebastian Zhao, June Paik, Michael W. Mahoney, Kurt Keutzer, Amir Gholami</em></li>
  <li><strong>LangMark: A Multilingual Dataset for Automatic Post-Editing</strong><br><em>Diego Velazquez, Mikaela Grace, Konstantinos Karageorgos, Lawrence Carin, Aaron Schliem, Dimitrios Zaikis, Roger Wechsler</em></li>
  <li><strong>Neural Parameter Search for Slimmer Fine-Tuned Models and Better Transfer</strong><br><em>Guodong DU, Jing Li, Zitao Fang, Junlin Li, Runhua Jiang, Shuyang Yu, Yifei Guo, Yangneng Chen, Sim Kuan Goh, Ho-Kin Tang, Daojing He, Honghai LIU, Min Zhang</em></li>
  <li><strong>Merge Hijacking: Backdoor Attacks to Model Merging of Large Language Models</strong><br><em>Zenghui Yuan, Yangming Xu, Jiawen Shi, Pan Zhou, Lichao Sun</em></li>
  <li><strong>LAMB: A Training-Free Method to Enhance the Long-Context Understanding of SSMs via Attention-Guided Token Filtering</strong><br><em>Zhifan Ye, Zheng Wang, Kejing Xia, Jihoon Hong, Leshu Li, Lexington Whalen, Cheng Wan, Yonggan Fu, Yingyan Celine Lin, Souvik Kundu</em></li>
  <li><strong>Where Are We? Evaluating LLM Performance on African Languages</strong><br><em>Ife Adebara, Hawau Olamide Toyin, Nahom Tesfu Ghebremichael, AbdelRahim A. Elmadany, Muhammad Abdul-Mageed</em></li>
  <li><strong>Beyond Output Matching: Bidirectional Alignment for Enhanced In-Context Learning</strong><br><em>Chengwei Qin, Wenhan Xia, Fangkai Jiao, Chen Chen, Yuchen Hu, Bosheng Ding, Ruirui Chen, Shafiq Joty</em></li>
  <li><strong>CiteEval: Principle-Driven Citation Evaluation for Source Attribution</strong><br><em>Yumo Xu, Peng Qi, Jifan Chen, Kunlun Liu, Rujun Han, Lan Liu, Bonan Min, Vittorio Castelli, Arshit Gupta, Zhiguo Wang</em></li>
  <li><strong>HiAgent: Hierarchical Working Memory Management for Solving Long-Horizon Agentic Tasks with Large Language Models</strong><br><em>Mengkang Hu, Tianxing Chen, Qiguang Chen, Yao Mu, Wenqi Shao, Ping Luo</em></li>
  <li><strong>Counterfactual-Consistency Prompting for Relative Temporal Understanding in Large Language Models</strong><br><em>Jongho Kim, seung-won hwang</em></li>
  <li><strong>EducationQ: Evaluating LLMs’ Teaching Capabilities Through Multi-Agent Dialogue Framework</strong><br><em>Yao Shi, Rongkeng Liang, Yong Xu</em></li>
  <li><strong>KRISTEVA: Close Reading as a Novel Task for Benchmarking Interpretive Reasoning</strong><br><em>Peiqi Sui, Juan Diego Rodriguez, Philippe Laban, J. Dean Murphy, Joseph P. Dexter, Richard Jean So, Samuel Baker, Pramit Chaudhuri</em></li>
  <li><strong>Efficient Domain Continual pretraining by Mitigating the Stability Gap</strong><br><em>Yiduo Guo, Jie Fu, Huishuai Zhang, Dongyan Zhao</em></li>
  <li><strong>Palm: A Culturally Inclusive and Linguistically Diverse Dataset for Arabic LLMs</strong><br><em>Fakhraddin Alwajih, Abdellah EL MEKKI, Samar Mohamed Magdy, AbdelRahim A. Elmadany, OMER NACAR, El Moatez Billah Nagoudi, Reem Abdel-Salam, Hanin atwany, Youssef Nafea, Abdulfattah Mohammed Yahya, Rahaf Alhamouri, Hamzah A. Alsayadi, Hiba Zayed, Sara Shatnawi, Serry Sibaee, Yasir ECH-CHAMMAKHY, Walid Al-Dhabyani, Marwa Mohamed Ali, Imen JARRAYA, Ahmed Oumar El-Shangiti, Aisha Alraeesi, Mohammed Anwar AL-Ghrawi, Abdulrahman S. Al-Batati, Elgizouli Mohamed, Noha Taha Elgindi, Muhammed Saeed, Houdaifa Atou, Issam AIT YAHIA, Abdelhak Bouayad, Mohammed Machrouh, AMAL MAKOUAR, Dania Alkawi, Mukhtar Mohamed, Safaa Taher Abdelfadil, Amine Ziad Ounnoughene, Anfel ROUABHIA, Rwaa Assi, Ahmed Sorkatti, Mohamedou cheikh tourad, Anis Koubaa, Ismail Berrada, Mustafa Jarrar, Shady Shehata, Muhammad Abdul-Mageed</em></li>
  <li><strong>NewsInterview: a Dataset and a Playground to Evaluate LLMs’ Grounding Gap via Informational Interviews</strong><br><em>Alexander Spangher, Michael Lu, Sriya Kalyan, Hyundong Justin Cho, Tenghao Huang, Weiyan Shi, Jonathan May</em></li>
  <li><strong>CFBench: A Comprehensive Constraints-Following Benchmark for LLMs</strong><br><em>Tao Zhang, ChengLIn Zhu, Yanjun Shen, Wenjing Luo, Yan Zhang, Hao Liang, Tao Zhang, Fan Yang, Mingan Lin, Yujing Qiao, Weipeng Chen, Bin CUI, Wentao Zhang, Zenan Zhou</em></li>
  <li><strong>Towards Building Large Scale Datasets and State-of-the-Art Automatic Speech Translation Systems for 13 Indian Languages</strong><br><em>Ashwin Sankar, Sparsh Jain, Nikhil Narasimhan, Devilal Choudhary, Dhairya Suman, Mohammed Safi Ur Rahman Khan, Anoop Kunchukuttan, Mitesh M Khapra, Raj Dabre</em></li>
  <li><strong>CoRe-MMRAG: Cross-Source Knowledge Reconciliation for Multimodal RAG</strong><br><em>yang tian, Fan Liu, Jingyuan Zhang, V. W., Yupeng Hu, Liqiang Nie</em></li>
  <li><strong>Mapping 1,000+ Language Models via the Log-Likelihood Vector</strong><br><em>Momose Oyama, Hiroaki Yamagiwa, Yusuke Takase, Hidetoshi Shimodaira</em></li>
  <li><strong>ConsistencyChecker: Tree-based Evaluation of LLM Generalization Capabilities</strong><br><em>Zhaochen Hong, Haofei Yu, Jiaxuan You</em></li>
  <li><strong>Robust Estimation of Population-Level Effects in Repeated-Measures NLP Experimental Designs</strong><br><em>Alejandro Benito-Santos, Adrian Ghajari, Víctor Fresno</em></li>
  <li><strong>FactBench: A Dynamic Benchmark for In-the-Wild Language Model Factuality Evaluation</strong><br><em>Farima Fatahi Bayat, Lechen Zhang, Sheza Munir, Lu Wang</em></li>
  <li><strong>Training-free LLM Merging for Multi-task Learning</strong><br><em>Zichuan Fu, Xian Wu, Yejing Wang, Wanyu Wang, Shanshan Ye, Hongzhi Yin, Yi Chang, Yefeng Zheng, Xiangyu Zhao</em></li>
  <li><strong>Inferring from Logits: Exploring Best Practices for Decoding-Free Generative Candidate Selection</strong><br><em>Mingyu Derek Ma, Yanna Ding, Zijie Huang, Jianxi Gao, Yizhou Sun, Wei Wang</em></li>
  <li><strong>Comparison-based Active Preference Learning for Multi-dimensional Personalization</strong><br><em>Minhyeon Oh, Seungjoon Lee, Jungseul Ok</em></li>
  <li><strong>OpenCoder: The Open Cookbook for Top-Tier Code Large Language Models</strong><br><em>Siming Huang, Tianhao Cheng, Jason Klein Liu, Weidi Xu, JIARAN HAO, Liuyihan Song, Yang Xu, Jian Yang, Jiaheng Liu, Chenchen Zhang, Linzheng Chai, Ruifeng Yuan, Xianzhen Luo, Qiufeng Wang, YuanTao Fan, Qingfu Zhu, Zhaoxiang Zhang, Yang Gao, Jie Fu, Qian Liu, Houyi Li, Ge Zhang, Yuan Qi, Xu Yinghui, Wei Chu, Zili Wang</em></li>
  <li><strong>LlamaDuo: LLMOps Pipeline for Seamless Migration from Service LLMs to Small-Scale Local LLMs</strong><br><em>Chansung Park, Juyong Jiang, Fan Wang, Sayak Paul, Jing Tang</em></li>
  <li><strong>AmbiK: Dataset of Ambiguous Tasks in Kitchen Environment</strong><br><em>Anastasia Ivanova, Zoya Volovikova, Bakaeva Eva, Alexey Kovalev, Aleksandr Panov</em></li>
  <li><strong>SocialDuolingo: Interactive Evaluation for Cultural Competence in Language Agents</strong><br><em>Jincenzi Wu, Jianxun Lian, Dingdong WANG, Helen M. Meng</em></li>
  <li><strong>Scalable Vision Language Model Training via High Quality Data Curation</strong><br><em>Hongyuan Dong, Zijian Kang, Weijie Yin, LiangXiao, ChaoFeng, Ran Jiao</em></li>
  <li><strong>GRAM: Generative Recommendation via Semantic-aware Multi-granular Late Fusion</strong><br><em>Sunkyung Lee, Minjin Choi, Eunseong Choi, Hye-young Kim, Jongwuk Lee</em></li>
  <li><strong>Towards Economical Inference: Enabling DeepSeek’s Multi-Head Latent Attention in Any Transformer-based LLMs</strong><br><em>Tao Ji, Bin Guo, Yuanbin Wu, Qipeng Guo, shenlixing, chenzhan, Xipeng Qiu, Qi Zhang, Tao Gui</em></li>
  <li><strong>TETRIS: Optimal Draft Token Selection for Batch Speculative Decoding</strong><br><em>Zhaoxuan Wu, Zijian Zhou, Arun Verma, Alok Prakash, Daniela Rus, Bryan Kian Hsiang Low</em></li>
  <li><strong>Introducing Verification Task of Set Consistency with Set-Consistency Energy Networks</strong><br><em>Mooho Song, Hye Ryung Son, Jay-Yoon Lee</em></li>
  <li><strong>A subtle deception beyond lying: LLMs for strategic phrasing in legislation</strong><br><em>Atharvan Dogra, Krishna Pillutla, Ameet Deshpande, Ananya B. Sai, John J Nay, Tanmay Rajpurohit, Ashwin Kalyan, Balaraman Ravindran</em></li>
  <li><strong>AfroCS-xs: Creating a Compact, High-Quality, Human-Validated Code-Switched Dataset for African Languages</strong><br><em>Kayode Olaleye, Arturo Oncevay, Mathieu Sibue, Nombuyiselo Zondi, Michelle Terblanche, Sibongile Mapikitla, Richard Lastrucci, Charese Smiley, Vukosi Marivate</em></li>
  <li><strong>Just Go Parallel: Improving the Multilingual Capabilities of Large Language Models</strong><br><em>Muhammad Reza Qorib, Junyi Li, Hwee Tou Ng</em></li>
  <li><strong>Design Choices for Extending the Context Length of Visual Language Models</strong><br><em>Mukai Li, Lei Li, Shansan Gong, Qi Liu</em></li>
</ul>